From 1ec1ac8497ca886ec678af8efecff6735690e6cf Mon Sep 17 00:00:00 2001
From: Rami Rosen <rosenr@marvell.com>
Date: Thu, 12 Jan 2012 14:33:02 +0200
Subject: [PATCH 082/609] L2FW add two l2sec files

Signed-off-by: Seif Mazareeb <seif@marvell.com>
---
 .../mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.c     |  497 ++++++++++++++++++++
 .../mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.h     |  493 +++++++++++++++++++
 2 files changed, 990 insertions(+)
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.c
 create mode 100644 arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.h

diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.c
new file mode 100644
index 0000000..a6c1dec
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.c
@@ -0,0 +1,497 @@
+/* mv_eth_l2sec.c */
+
+#include "mv_eth_l2sec.h"
+
+static inline MV_STATUS mv_eth_cesa_l2fw_tx(struct eth_pbuf *pkt, struct eth_port *pp)
+{
+	struct neta_tx_desc *tx_desc;
+	u32 tx_cmd = 0;
+	struct tx_queue *txq_ctrl;
+
+	/* assigning different txq for each rx port , to avoid waiting on the
+	same txq lock when traffic on several rx ports are destined to the same
+	outgoing interface */
+	int txq = 0;
+	txq_ctrl = &pp->txq_ctrl[pp->txp * CONFIG_MV_ETH_TXQ + txq];
+	spin_lock(&txq_ctrl->queue_lock);
+
+	if (txq_ctrl->txq_count >= mv_ctrl_txdone)
+		mv_eth_txq_done(pp, txq_ctrl);
+	/* Get next descriptor for tx, single buffer, so FIRST & LAST */
+	tx_desc = mv_eth_tx_desc_get(txq_ctrl, 1);
+	if (tx_desc == NULL) {
+		/* printk("tx_desc == NULL pp->port=%d in %s\n", pp->port, ,__func__); */
+		spin_unlock(&txq_ctrl->queue_lock);
+		/* No resources: Drop */
+		pp->dev->stats.tx_dropped++;
+		return MV_DROPPED;
+	}
+	txq_ctrl->txq_count++;
+
+	tx_cmd |= NETA_TX_BM_ENABLE_MASK | NETA_TX_BM_POOL_ID_MASK(pkt->pool);
+	txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = (u32) NULL;
+	mv_eth_shadow_inc_put(txq_ctrl);
+
+	tx_desc->command = tx_cmd | NETA_TX_L4_CSUM_NOT |
+		NETA_TX_FLZ_DESC_MASK | NETA_TX_F_DESC_MASK
+		| NETA_TX_L_DESC_MASK |
+		NETA_TX_PKT_OFFSET_MASK(pkt->offset + MV_ETH_MH_SIZE);
+
+	tx_desc->dataSize    = pkt->bytes;
+	tx_desc->bufPhysAddr = pkt->physAddr;
+	mv_eth_tx_desc_flush(tx_desc);
+	mvNetaTxqPendDescAdd(pp->port, pp->txp, 0, 1);
+	spin_unlock(&txq_ctrl->queue_lock);
+	return MV_OK;
+}
+
+static inline void nfp_sec_complete_out(unsigned long data)
+
+{
+	MV_NFP_SEC_CESA_PRIV_L2FW *nfp_sec_cesa_priv = (MV_NFP_SEC_CESA_PRIV_L2FW *)data;		MV_U32            ifout;
+	MV_PKT_INFO       *pkt;
+	MV_BUF_INFO       *pBuf;
+	struct eth_port   *pp;
+	struct eth_pbuf   *pPkt;
+	int oldOfsset;
+	MV_STATUS status = MV_FAIL;
+	static int counterOfFailed = 0;
+	if (!nfp_sec_cesa_priv) {
+		printk(KERN_INFO "nfp_sec_cesa_priv is NULL in %s\n", __func__);
+		return;
+	}
+	ifout = nfp_sec_cesa_priv->ifout;
+
+	pkt = nfp_sec_cesa_priv->pPktInfo;
+	if (!pkt) {
+		printk(KERN_INFO "pPktInfo is NULL in %s\n", __func__);
+		return;
+	}
+	pBuf = pkt->pFrags;
+	if (!pBuf) {
+		printk(KERN_INFO "pBuf is NULL in %s\n", __func__);
+		return;
+	}
+	pPkt = nfp_sec_cesa_priv->pPkt;
+	if (!pPkt) {
+		printk(KERN_INFO "!pPkt) in %s\n", __func__);
+		return;
+	}
+	pPkt->bytes    = pBuf->dataSize;
+	pPkt->bytes += MV_NFP_SEC_ESP_OFFSET;
+	oldOfsset      = pPkt->offset;
+	pPkt->offset   = pPkt->offset - (sizeof(MV_ESP_HEADER) + sizeof(MV_IP_HEADER) + MV_CESA_AES_BLOCK_SIZE);
+
+	pp     = mv_eth_ports[ifout];
+
+	status = 	mv_eth_cesa_l2fw_tx(pPkt, pp);
+	if (status == MV_DROPPED)
+		counterOfFailed++;
+	 else
+		pPkt->offset = oldOfsset;
+}
+
+int l2fw_set_cesa_chan(int port, int cesaChan)
+{
+//	struct eth_port *pp;
+	printk(KERN_INFO "setting cesaChan to %d for port=%d \n", cesaChan, port);
+	if ((cesaChan != CESA_0) && (cesaChan != CESA_1))  {
+		printk(KERN_INFO "non permitted value for CESA channel \n");
+		return -EINVAL;
+	}
+//	pp = mv_eth_ports[port];
+//	if (pp)
+//		pp->cesaChan = cesaChan;
+	cesaChanPort[port] = cesaChan;
+	return 0;
+}
+
+MV_STATUS my_mvSysCesaInit(int numOfSession, int queueDepth, void *osHandle)
+{
+	MV_CESA_HAL_DATA halData;
+	MV_UNIT_WIN_INFO addrWinMap[MAX_TARGETS + 1];
+	MV_STATUS status;
+	MV_U8 chan;
+
+	status = mvCtrlAddrWinMapBuild(addrWinMap, MAX_TARGETS + 1);
+
+	if (status == MV_OK) {
+		for (chan = 0; chan < MV_CESA_CHANNELS; chan++) {
+			status = mvCesaTdmaWinInit(chan, addrWinMap);
+			if (status != MV_OK) {
+				mvOsPrintf("Error, unable to initialize CESA windows for channel(%d)\n", chan);
+				break;
+			}
+			halData.sramPhysBase[chan] = (MV_ULONG)mv_crypto_virt_base_get(chan);
+			halData.sramVirtBase[chan] = (MV_U8 *)mv_crypto_virt_base_get(chan);
+			halData.sramOffset[chan] = 0;
+		}
+
+		if (status == MV_OK) {
+		halData.ctrlModel = mvCtrlModelGet();
+		halData.ctrlRev = mvCtrlRevGet();
+			status = mvCesaHalInit(numOfSession, queueDepth,
+					osHandle, &halData);
+	}
+	}
+
+	return status;
+}
+
+void cesaStart(void)
+{
+	int bufNum, bufSize;
+	int i, j, idx;
+	MV_CESA_MBUF *pMbufSrc_0, *pMbufDst_0;
+	MV_BUF_INFO *pFragsSrc_0, *pFragsDst_0;
+	char *pBuf_0;
+
+	MV_CESA_MBUF *pMbufSrc_1, *pMbufDst_1;
+	MV_BUF_INFO *pFragsSrc_1, *pFragsDst_1;
+	char *pBuf_1;
+
+	printk(KERN_INFO "in %s\n", __func__);
+
+	cesaCmdArray_0 = 	mvOsMalloc(sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE);
+
+	if (cesaCmdArray_0 == NULL) {
+		mvOsPrintf("Can't allocate %d bytes of memory\n",
+			   (int)(sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE));
+		return;
+	}
+	memset(cesaCmdArray_0, 0, sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE);
+	/* CESA_DEF_BUF_NUM */
+	bufNum    =  1;
+	/* CESA_DEF_BUF_SIZE */
+	bufSize   = 1500;
+
+	pMbufSrc_0  = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	pFragsSrc_0 = mvOsMalloc(sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	pMbufDst_0  = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	pFragsDst_0 = mvOsMalloc(sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	if ((pMbufSrc_0 == NULL) || (pFragsSrc_0 == NULL) ||
+		(pMbufDst_0 == NULL) || (pFragsDst_0 == NULL)) {
+		mvOsPrintf(" Can't malloc Src and Dst pMbuf and pFrags structures.\n");
+		return;
+	}
+
+	memset(pMbufSrc_0,  0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	memset(pFragsSrc_0, 0, sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	memset(pMbufDst_0,  0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	memset(pFragsDst_0, 0, sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	idx = 0;
+	for (i = 0; i < CESA_DEF_REQ_SIZE; i++) {
+		pBuf_0 = mvOsIoCachedMalloc(cesaOSHandle, bufSize * bufNum * 2,
+					  &cesaBufs_0[i].bufPhysAddr, &cesaBufs_0[i].memHandle);
+		if (pBuf_0 == NULL) {
+			mvOsPrintf("testStart: Can't malloc %d bytes for pBuf\n", bufSize * bufNum * 2);
+			return;
+		}
+
+		memset(pBuf_0, 0, bufSize * bufNum * 2);
+		mvOsCacheFlush(cesaOSHandle, pBuf_0, bufSize * bufNum * 2);
+		if (pBuf_0 == NULL) {
+			mvOsPrintf("Can't allocate %d bytes for req_%d buffers\n",
+				   bufSize * bufNum * 2, i);
+			return;
+		}
+
+		cesaBufs_0[i].bufVirtPtr = (MV_U8 *) pBuf_0;
+		cesaBufs_0[i].bufSize = bufSize * bufNum * 2;
+
+		cesaCmdArray_0[i].pSrc = &pMbufSrc_0[i];
+		cesaCmdArray_0[i].pSrc->pFrags = &pFragsSrc_0[idx];
+		cesaCmdArray_0[i].pSrc->numFrags = bufNum;
+		cesaCmdArray_0[i].pSrc->mbufSize = 0;
+
+		cesaCmdArray_0[i].pDst = &pMbufDst_0[i];
+		cesaCmdArray_0[i].pDst->pFrags = &pFragsDst_0[idx];
+		cesaCmdArray_0[i].pDst->numFrags = bufNum;
+		cesaCmdArray_0[i].pDst->mbufSize = 0;
+
+		for (j = 0; j < bufNum; j++) {
+			cesaCmdArray_0[i].pSrc->pFrags[j].bufVirtPtr = (MV_U8 *) pBuf_0;
+			cesaCmdArray_0[i].pSrc->pFrags[j].bufSize = bufSize;
+			pBuf_0 += bufSize;
+			cesaCmdArray_0[i].pDst->pFrags[j].bufVirtPtr = (MV_U8 *) pBuf_0;
+
+			cesaCmdArray_0[i].pDst->pFrags[j].bufSize = bufSize;
+			pBuf_0 += bufSize;
+		}
+		idx += bufNum;
+	}
+
+	cesaMbufArray_0 = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	if (cesaMbufArray_0 == NULL) {
+		mvOsPrintf("Can't allocate %d bytes of memory\n",
+			   (int)(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE));
+		return;
+	}
+	memset(cesaMbufArray_0, 0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+
+	cesaPrivArray_0 = mvOsMalloc(sizeof(MV_NFP_SEC_CESA_PRIV_L2FW) * (CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE));
+	memset(cesaPrivArray_0, 0, sizeof(MV_NFP_SEC_CESA_PRIV_L2FW) * (CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE));
+
+	/* second engine */
+	cesaCmdArray_1 = 	mvOsMalloc(sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE);
+
+	if (cesaCmdArray_1 == NULL) {
+		mvOsPrintf("Can't allocate %d bytes of memory\n",
+			   (int)(sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE));
+		return;
+	}
+	memset(cesaCmdArray_1, 0, sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE);
+
+	/* CESA_DEF_BUF_NUM */
+	bufNum    =  1;
+	/* CESA_DEF_BUF_SIZE */
+	bufSize   = 1500;
+
+	pMbufSrc_1  = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	pFragsSrc_1 = mvOsMalloc(sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	pMbufDst_1  = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	pFragsDst_1 = mvOsMalloc(sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	if ((pMbufSrc_1 == NULL) || (pFragsSrc_1 == NULL) || (pMbufDst_1 == NULL)
+		|| (pFragsDst_1 == NULL)) {
+		mvOsPrintf(" Can't malloc Src and Dst pMbuf and pFrags structures.\n");
+		return;
+	}
+
+	memset(pMbufSrc_1,  0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	memset(pFragsSrc_1, 0, sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	memset(pMbufDst_1,  0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	memset(pFragsDst_1, 0, sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
+
+	idx = 0;
+	for (i = 0; i < CESA_DEF_REQ_SIZE; i++) {
+		pBuf_1 = mvOsIoCachedMalloc(cesaOSHandle, bufSize * bufNum * 2,
+					  &cesaBufs_1[i].bufPhysAddr, &cesaBufs_1[i].memHandle);
+		if (pBuf_1 == NULL) {
+			mvOsPrintf("testStart: Can't malloc %d bytes for pBuf\n", bufSize * bufNum * 2);
+			return;
+		}
+
+		memset(pBuf_1, 0, bufSize * bufNum * 2);
+		mvOsCacheFlush(cesaOSHandle, pBuf_1, bufSize * bufNum * 2);
+		if (pBuf_1 == NULL) {
+			mvOsPrintf("Can't allocate %d bytes for req_%d buffers\n",
+				   bufSize * bufNum * 2, i);
+			return;
+		}
+
+		cesaBufs_1[i].bufVirtPtr = (MV_U8 *) pBuf_1;
+		cesaBufs_1[i].bufSize = bufSize * bufNum * 2;
+
+		cesaCmdArray_1[i].pSrc = &pMbufSrc_1[i];
+		cesaCmdArray_1[i].pSrc->pFrags = &pFragsSrc_1[idx];
+		cesaCmdArray_1[i].pSrc->numFrags = bufNum;
+		cesaCmdArray_1[i].pSrc->mbufSize = 0;
+
+		cesaCmdArray_1[i].pDst = &pMbufDst_1[i];
+		cesaCmdArray_1[i].pDst->pFrags = &pFragsDst_1[idx];
+		cesaCmdArray_1[i].pDst->numFrags = bufNum;
+		cesaCmdArray_1[i].pDst->mbufSize = 0;
+
+		for (j = 0; j < bufNum; j++) {
+			cesaCmdArray_1[i].pSrc->pFrags[j].bufVirtPtr = (MV_U8 *) pBuf_1;
+			cesaCmdArray_1[i].pSrc->pFrags[j].bufSize = bufSize;
+			pBuf_1 += bufSize;
+			cesaCmdArray_1[i].pDst->pFrags[j].bufVirtPtr = (MV_U8 *) pBuf_1;
+
+			cesaCmdArray_1[i].pDst->pFrags[j].bufSize = bufSize;
+			pBuf_1 += bufSize;
+		}
+		idx += bufNum;
+	}
+
+	cesaMbufArray_1 = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+	if (cesaMbufArray_1 == NULL) {
+		mvOsPrintf("Can't allocate %d bytes of memory\n",
+			   (int)(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE));
+		return;
+	}
+	memset(cesaMbufArray_1, 0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+
+	cesaPrivArray_1 = mvOsMalloc(sizeof(MV_NFP_SEC_CESA_PRIV_L2FW) * (CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE));
+	memset(cesaPrivArray_1, 0, sizeof(MV_NFP_SEC_CESA_PRIV_L2FW) * (CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE));
+
+	pPktInfoNewArray_0 = mvOsMalloc(sizeof(MV_PKT_INFO) * MV_NFP_SEC_REQ_Q_SIZE);
+
+	if (!pPktInfoNewArray_0) {
+		printk(KERN_INFO "mvOsMalloc() failed in %s\n", __func__);
+		return;
+	}
+
+	pBufInfoArray_0 = mvOsMalloc(sizeof(MV_BUF_INFO) * MV_NFP_SEC_REQ_Q_SIZE);
+	if (!pBufInfoArray_0) {
+		printk(KERN_INFO "could not allocate MV_BUF_INFO in %s\n", __func__);
+		return;
+	}
+
+	pPktInfoNewArray_1 = mvOsMalloc(sizeof(MV_PKT_INFO) * MV_NFP_SEC_REQ_Q_SIZE);
+
+	if (!pPktInfoNewArray_1) {
+		printk(KERN_INFO "mvOsMalloc() failed in %s\n", __func__);
+		return;
+	}
+	pBufInfoArray_1 = mvOsMalloc(sizeof(MV_BUF_INFO) * MV_NFP_SEC_REQ_Q_SIZE);
+	if (!pBufInfoArray_0) {
+		printk(KERN_INFO "could not allocate MV_BUF_INFO in %s\n", __func__);
+		return;
+	}
+	printk(KERN_INFO "start finished in %s\n", __func__);
+}
+
+static irqreturn_t nfp_sec_interrupt_handler_0(int irq, void *arg)
+{
+	MV_CESA_RESULT  	result;
+	MV_STATUS           status;
+	MV_U8 chan = 0;
+
+    MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
+
+	while (1) {
+	/* Get Ready requests */
+
+	status = mvCesaReadyGet(chan, &result);
+	if (status != MV_OK)
+		break;
+
+	nfp_sec_complete_out((unsigned long)((MV_NFP_SEC_CESA_PRIV_L2FW *)result.pReqPrv));
+	}
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t nfp_sec_interrupt_handler_1(int irq, void *arg)
+{
+	MV_CESA_RESULT  	result;
+	MV_STATUS           status;
+	MV_U8 chan = 1;
+    MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
+	while (1) {
+	/* Get Ready requests */
+	status = mvCesaReadyGet(chan, &result);
+	if (status != MV_OK)
+		break;
+
+	nfp_sec_complete_out((unsigned long)((MV_NFP_SEC_CESA_PRIV_L2FW *)result.pReqPrv));
+	}
+
+	return IRQ_HANDLED;
+}
+
+void openCesaSession(void)
+{
+	unsigned char sha1Key[]  = {0x12, 0x34, 0x56, 0x78, 0x9a, 0xbc, 0xde, 0xf0,
+								0x24, 0x68, 0xac, 0xe0, 0x24, 0x68, 0xac, 0xe0,
+								0x13, 0x57, 0x9b, 0xdf};
+	/* sizeof(cryptoKey) should be 128 for AES-128 */
+	unsigned char cryptoKey[] = {0x01, 0x23, 0x45, 0x67, 0x89, 0xab, 0xcd, 0xef,
+									0x02, 0x46, 0x8a, 0xce, 0x13, 0x57, 0x9b, 0xdf};
+
+	int i;
+	MV_NFP_SEC_SA_ENTRY sa;
+	MV_CESA_OPEN_SESSION os;
+	unsigned short digest_size = 0;
+	memset(&sa, 0, sizeof(MV_NFP_SEC_SA_ENTRY));
+	memset(&os, 0, sizeof(MV_CESA_OPEN_SESSION));
+
+	os.operation 		= MV_CESA_MAC_THEN_CRYPTO;
+	os.cryptoAlgorithm  = MV_CESA_CRYPTO_AES;
+	os.macMode  		= MV_CESA_MAC_HMAC_SHA1;
+	digest_size 		= MV_CESA_SHA1_DIGEST_SIZE;
+	os.cryptoMode 		= MV_CESA_CRYPTO_ECB;
+	for (i = 0; i < sizeof(cryptoKey); i++)
+		os.cryptoKey[i] = cryptoKey[i];
+
+	os.cryptoKeyLength = sizeof(cryptoKey);
+
+	for (i = 0; i < sizeof(sha1Key); i++)
+		os.macKey[i] = sha1Key[i];
+	os.macKeyLength = sizeof(sha1Key);
+	os.digestSize = digest_size;
+
+	if (mvCesaSessionOpen(&os, (short *)&(sa.sid)))
+		printk(KERN_INFO "mvCesaSessionOpen failed in %s\n", __func__);
+}
+
+void l2fw_esp_set(int enableEsp)
+{
+	if (enableEsp) {
+		openCesaSession();
+		printk(KERN_INFO "calling cesaStart() in %s\n", __func__);
+		cesaStart();
+	} else
+		printk(KERN_INFO "enableEsp=%d disabling ESP in %s\n", enableEsp, __func__);
+	espEnabled = enableEsp;
+}
+
+int cesa_init(void)
+{
+	u8 chan = 0;
+	int i;
+	const char *irq_str[] = {"cesa0", "cesa1"};
+	printk(KERN_INFO "in %s\n", __func__);
+	for (i = 0; i < 2; i++)
+		spin_lock_init(&cesa_lock[i]);
+	if (mvCtrlPwrClckGet(CESA_UNIT_ID, 0) == MV_FALSE)
+		return 0;
+	if (MV_OK != my_mvSysCesaInit(1, 256, NULL)) {
+		printk(KERN_INFO "%s,%d: mvCesaInit Failed. \n", __FILE__, __LINE__);
+		return EINVAL;
+	}
+
+	/* clear and unmask Int */
+	MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
+	MV_REG_WRITE(MV_CESA_ISR_MASK_REG(chan), MV_CESA_CAUSE_ACC_DMA_MASK);
+	if (request_irq(CESA_IRQ(0), nfp_sec_interrupt_handler_0,
+							(IRQF_DISABLED) , irq_str[chan], NULL)) {
+				printk(KERN_INFO "%s,%d: cannot assign irq %x\n", __FILE__, __LINE__, CESA_IRQ(chan));
+		return EINVAL;
+	}
+
+	chan = 1;
+	MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
+	MV_REG_WRITE(MV_CESA_ISR_MASK_REG(chan), MV_CESA_CAUSE_ACC_DMA_MASK);
+
+	if (request_irq(CESA_IRQ(1), nfp_sec_interrupt_handler_1,
+							(IRQF_DISABLED) , irq_str[chan], NULL)) {
+				printk(KERN_INFO "%s,%d: cannot assign irq %x\n", __FILE__, __LINE__, CESA_IRQ(chan));
+		return EINVAL;
+		}
+
+	atomic_set(&req_count[0], 0);
+	atomic_set(&req_count[1], 0);
+	mvOsPrintf("MV_CESA_TDMA_CTRL_REG address 0 %08x\n\n", MV_CESA_TDMA_CTRL_REG(0));
+	mvOsPrintf("MV_CESA_TDMA_CTRL_REG address 1 %08x\n\n", MV_CESA_TDMA_CTRL_REG(1));
+	mvOsPrintf("MV_CESA_TDMA_CTRL_REG(0)  %08x\n",
+		MV_REG_READ(MV_CESA_TDMA_CTRL_REG(0)));
+	mvOsPrintf("MV_CESA_TDMA_CTRL_REG(1)  %08x\n",
+		MV_REG_READ(MV_CESA_TDMA_CTRL_REG(1)));
+
+	memset(&sa, 0, sizeof(MV_NFP_SEC_SA_ENTRY));
+	sa.digestSize = MV_CESA_SHA1_DIGEST_SIZE;
+	sa.ivSize = MV_CESA_AES_BLOCK_SIZE;
+	sa.spi = 3;
+
+	sa.tunProt = MV_NFP_SEC_TUNNEL;
+	sa.encap   = MV_NFP_SEC_ESP;
+	sa.seqNum  = 4;
+	sa.tunnelHdr.sIp = 0x6400A8C0;
+	sa.tunnelHdr.dIp = 0x6401A8C0;
+	sa.tunnelHdr.outIfIndex = 0;
+	sa.lifeTime = 0;
+
+	sa.secOp = MV_NFP_SEC_ENCRYPT;
+	strcpy(sa.tunnelHdr.dstMac, "aabbccddeeff");
+	strcpy(sa.tunnelHdr.srcMac, "abacadaeafaa");
+
+	return 0;
+}
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.h
new file mode 100644
index 0000000..f77e7fe
--- /dev/null
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.h
@@ -0,0 +1,493 @@
+/* l2sec/mv_eth_l2sec.h */
+
+#ifndef L2SEC_MV_ETH_L2SEC_H
+#define L2SEC_MV_ETH_L2SEC_H
+
+#include "mvOs.h"
+#include "cesa/mvCesa.h"
+
+#include "mv_neta/l2fw/mv_eth_l2fw.h"
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "mv_neta/net_dev/mv_netdev.h"
+
+/* Taken from mvNfpSec.h */
+/* IPSec defines */
+#define MV_NFP_SEC_MAX_PACKET		1540
+#define MV_NFP_SEC_ENC_BLOCK_SIZE	16
+
+#define MV_NFP_SEC_ESP_OFFSET		34
+
+/* IPSec Enumerators */
+typedef enum {
+	MV_NFP_SEC_TUNNEL = 0,
+	MV_NFP_SEC_TRANSPORT,
+} MV_NFP_SEC_PROT;
+
+typedef enum {
+	MV_NFP_SEC_ESP = 0,
+	MV_NFP_SEC_AH,
+} MV_NFP_SEC_ENCAP;
+
+
+typedef enum {
+	MV_NFP_SEC_ENCRYPT = 0,
+	MV_NFP_SEC_DECRYPT,
+} MV_NFP_SEC_OP;
+
+typedef struct _mv_nfp_sa_stats {
+	MV_U32 encrypt;
+	MV_U32 decrypt;
+	MV_U32 rejected;	/* slow path */
+	MV_U32 dropped;		/* packet drop */
+	MV_U32 bytes;
+} MV_NFP_SA_STATS;
+
+/* IPSec Structures */
+typedef struct _mv_nfp_sec_tunnel_hdr {
+	MV_U32 sIp;		/*  BE */
+	MV_U32 dIp;		/* BE */
+	/* dstMac should be 2 byte aligned */
+	MV_U8 dstMac[MV_MAC_ADDR_SIZE];	/* BE */
+	MV_U8 srcMac[MV_MAC_ADDR_SIZE];	/* BE */
+	MV_U8 outIfIndex;
+} MV_NFP_SEC_TUNNEL_HDR;
+
+typedef struct _mv_nfp_sec_sa_entry {
+	MV_U32 spi;		/* BE */
+	MV_NFP_SEC_PROT tunProt;
+	MV_NFP_SEC_ENCAP encap;
+	MV_U16 sid;
+	MV_U32 seqNum;		/* LE  */
+	MV_NFP_SEC_TUNNEL_HDR tunnelHdr;
+	MV_U32 lifeTime;
+	MV_U8 ivSize;
+	MV_U8 cipherBlockSize;
+	MV_U8 digestSize;
+	MV_NFP_SEC_OP secOp;
+	MV_NFP_SA_STATS stats;
+} MV_NFP_SEC_SA_ENTRY;
+
+typedef struct _mv_nfp_sec_cesa_priv {
+	MV_NFP_SEC_SA_ENTRY *pSaEntry;
+	MV_PKT_INFO *pPktInfo;
+	MV_U8 orgDigest[MV_CESA_MAX_DIGEST_SIZE];
+	MV_CESA_COMMAND *pCesaCmd;
+} MV_NFP_SEC_CESA_PRIV;
+
+int cesaChanPort[CONFIG_MV_ETH_PORTS_NUM];
+
+#define CESA_0    0
+#define CESA_1    1
+/* for future - handle by CPU */
+#define CESA_NONE 2
+
+#define MV_NFP_SEC_REQ_Q_SIZE 1000
+#define CESA_DEF_REQ_SIZE       (256*4)
+int counterNoResources[4]  = {0, 0, 0, 0};
+spinlock_t cesa_lock[2];
+
+extern u32 mv_crypto_virt_base_get(u8 chan);
+static MV_PKT_INFO *pPktInfoNewArray_0;
+static MV_PKT_INFO *pPktInfoNewArray_1;
+static MV_BUF_INFO *pBufInfoArray_0;
+static MV_BUF_INFO *pBufInfoArray_1;
+
+MV_BUF_INFO cesaBufs_0[CESA_DEF_REQ_SIZE];
+MV_BUF_INFO cesaBufs_1[CESA_DEF_REQ_SIZE];
+
+static int cesaPrivIndx_0 = 0;
+static int cesaPrivIndx_1 = 0;
+
+static int cesaCmdIndx_0 = 0;
+static int cesaCmdIndx_1 = 0;
+
+typedef struct _mv_nfp_sec_cesa_priv_l2fw {
+	MV_NFP_SEC_SA_ENTRY *pSaEntry;
+	MV_PKT_INFO *pPktInfo;
+	MV_U8 orgDigest[MV_CESA_MAX_DIGEST_SIZE];
+	MV_CESA_COMMAND *pCesaCmd;
+	struct eth_pbuf *pPkt;
+	int ifout;
+	int ownerId;
+	int inPort;
+} MV_NFP_SEC_CESA_PRIV_L2FW;
+
+MV_NFP_SEC_CESA_PRIV_L2FW *cesaPrivArray_0;
+MV_NFP_SEC_CESA_PRIV_L2FW *cesaPrivArray_1;
+
+void *cesaOSHandle = NULL;
+static MV_CESA_MBUF *cesaMbufArray_0;
+static MV_CESA_MBUF *cesaMbufArray_1;
+
+static MV_CESA_COMMAND *cesaCmdArray_0;
+static MV_CESA_COMMAND *cesaCmdArray_1;
+
+
+static MV_NFP_SEC_SA_ENTRY sa;
+atomic_t req_count[2];
+int l2fw_set_cesa_chan(int port, int cesaChan);
+int cesa_init(void);
+
+
+/* from mv_hal/eth/gbe/mvEthRegs.h */
+
+/* Tx descriptor bits */
+#define ETH_TX_ERROR_CODE_OFFSET            1
+#define ETH_TX_ERROR_CODE_MASK              (3<<ETH_TX_ERROR_CODE_OFFSET)
+#define ETH_TX_LATE_COLLISION_ERROR         (0<<ETH_TX_ERROR_CODE_OFFSET)
+#define ETH_TX_UNDERRUN_ERROR               (1<<ETH_TX_ERROR_CODE_OFFSET)
+#define ETH_TX_EXCESSIVE_COLLISION_ERROR    (2<<ETH_TX_ERROR_CODE_OFFSET)
+
+#define ETH_TX_LLC_SNAP_FORMAT_BIT          9
+#define ETH_TX_LLC_SNAP_FORMAT_MASK         (1<<ETH_TX_LLC_SNAP_FORMAT_BIT)
+
+#define ETH_TX_IP_FRAG_BIT                  10
+#define ETH_TX_IP_FRAG_MASK                 (1<<ETH_TX_IP_FRAG_BIT)
+#define ETH_TX_IP_FRAG                      (0<<ETH_TX_IP_FRAG_BIT)
+#define ETH_TX_IP_NO_FRAG                   (1<<ETH_TX_IP_FRAG_BIT)
+
+#define ETH_TX_IP_HEADER_LEN_OFFSET         11
+#define ETH_TX_IP_HEADER_LEN_ALL_MASK       (0xF<<ETH_TX_IP_HEADER_LEN_OFFSET)
+#define ETH_TX_IP_HEADER_LEN_MASK(len)      ((len)<<ETH_TX_IP_HEADER_LEN_OFFSET)
+
+#define ETH_TX_VLAN_TAGGED_FRAME_BIT        15
+#define ETH_TX_VLAN_TAGGED_FRAME_MASK       (1<<ETH_TX_VLAN_TAGGED_FRAME_BIT)
+
+#define ETH_TX_L4_TYPE_BIT                  16
+#define ETH_TX_L4_TCP_TYPE                  (0<<ETH_TX_L4_TYPE_BIT)
+#define ETH_TX_L4_UDP_TYPE                  (1<<ETH_TX_L4_TYPE_BIT)
+
+#define ETH_TX_GENERATE_L4_CHKSUM_BIT       17
+#define ETH_TX_GENERATE_L4_CHKSUM_MASK      (1<<ETH_TX_GENERATE_L4_CHKSUM_BIT)
+
+#define ETH_TX_GENERATE_IP_CHKSUM_BIT       18
+#define ETH_TX_GENERATE_IP_CHKSUM_MASK      (1<<ETH_TX_GENERATE_IP_CHKSUM_BIT)
+
+#define ETH_TX_ZERO_PADDING_BIT             19
+#define ETH_TX_ZERO_PADDING_MASK            (1<<ETH_TX_ZERO_PADDING_BIT)
+
+#define ETH_TX_LAST_DESC_BIT                20
+#define ETH_TX_LAST_DESC_MASK               (1<<ETH_TX_LAST_DESC_BIT)
+
+#define ETH_TX_FIRST_DESC_BIT               21
+#define ETH_TX_FIRST_DESC_MASK              (1<<ETH_TX_FIRST_DESC_BIT)
+
+#define ETH_TX_GENERATE_CRC_BIT             22
+#define ETH_TX_GENERATE_CRC_MASK            (1<<ETH_TX_GENERATE_CRC_BIT)
+
+#define ETH_TX_ENABLE_INTERRUPT_BIT         23
+#define ETH_TX_ENABLE_INTERRUPT_MASK        (1<<ETH_TX_ENABLE_INTERRUPT_BIT)
+
+#define ETH_TX_AUTO_MODE_BIT                30
+#define ETH_TX_AUTO_MODE_MASK               (1<<ETH_TX_AUTO_MODE_BIT)
+
+
+inline MV_VOID mvNfpSecBuildIPTunnel(MV_PKT_INFO *pPktInfo, MV_NFP_SEC_SA_ENTRY *pSAEntry)
+{
+	MV_IP_HEADER *pIpHdr, *pIntIpHdr;
+	MV_U16 newIpTotalLength;
+
+	newIpTotalLength = pPktInfo->pFrags[0].dataSize - sizeof(MV_802_3_HEADER);
+
+	pIpHdr = (MV_IP_HEADER *) (pPktInfo->pFrags[0].bufVirtPtr + sizeof(MV_802_3_HEADER));
+	pIntIpHdr = (MV_IP_HEADER *) ((MV_U8 *) (pIpHdr) + sizeof(MV_IP_HEADER) + sizeof(MV_ESP_HEADER) +
+				      pSAEntry->ivSize);
+
+	/* TBD - review below settings in RFC */
+	pIpHdr->version = 0x45;
+	pIpHdr->tos = 0;
+	pIpHdr->checksum = 0;
+	pIpHdr->totalLength = MV_16BIT_BE(newIpTotalLength);
+	pIpHdr->identifier = 0;
+	pIpHdr->fragmentCtrl = 0;
+	pIpHdr->ttl = pIntIpHdr->ttl - 1;
+	pIpHdr->protocol = MV_IP_PROTO_ESP;
+	pIpHdr->srcIP = pSAEntry->tunnelHdr.sIp;
+	pIpHdr->dstIP = pSAEntry->tunnelHdr.dIp;
+
+	pPktInfo->status = ETH_TX_IP_NO_FRAG | ETH_TX_GENERATE_IP_CHKSUM_MASK | (0x5 << ETH_TX_IP_HEADER_LEN_OFFSET);
+
+	return;
+}
+
+
+/* Append sequence number and spi, save some space for IV */
+inline MV_VOID mvNfpSecBuildEspHdr(MV_PKT_INFO *pPktInfo, MV_NFP_SEC_SA_ENTRY *pSAEntry)
+{
+	MV_ESP_HEADER *pEspHdr;
+
+	pEspHdr = (MV_ESP_HEADER *) (pPktInfo->pFrags[0].bufVirtPtr + sizeof(MV_802_3_HEADER) + sizeof(MV_IP_HEADER));
+	pEspHdr->spi = pSAEntry->spi;
+	pSAEntry->seqNum = (pSAEntry->seqNum++);
+	pEspHdr->seqNum = MV_32BIT_BE(pSAEntry->seqNum);
+}
+
+inline MV_VOID mvNfpSecBuildMac(MV_PKT_INFO *pPktInfo, MV_NFP_SEC_SA_ENTRY *pSAEntry)
+{
+	MV_802_3_HEADER *pMacHdr;
+
+	pMacHdr = (MV_802_3_HEADER *) ((MV_U8 *) (pPktInfo->pFrags[0].bufVirtPtr));
+	memcpy(pMacHdr, &pSAEntry->tunnelHdr.dstMac, 12);
+	pMacHdr->typeOrLen = 0x08;	/* stands for IP protocol code 16bit swapped */
+	return;
+}
+
+
+inline MV_STATUS mvSecEspProcess_0(struct eth_pbuf *pPkt, MV_PKT_INFO *pPktInfo,
+							MV_NFP_SEC_SA_ENTRY *pSAEntry, struct eth_port *newpp,
+							MV_U8 channel, int inPort)
+{
+	MV_CESA_COMMAND	*pCesaCmd;
+	MV_CESA_MBUF *pCesaMbuf;
+	MV_NFP_SEC_CESA_PRIV_L2FW *pCesaPriv;
+	MV_STATUS status;
+	MV_IP_HEADER *pIpHdr;
+	MV_BUF_INFO  *pBuf;
+
+	pCesaCmd  = &cesaCmdArray_0[cesaCmdIndx_0];
+	pCesaMbuf = &cesaMbufArray_0[cesaCmdIndx_0];
+	cesaCmdIndx_0++;
+
+	cesaCmdIndx_0 %= CESA_DEF_REQ_SIZE;
+	pCesaPriv = &cesaPrivArray_0[cesaPrivIndx_0++];
+
+	cesaPrivIndx_0 = cesaPrivIndx_0%(CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE);
+
+	pCesaPriv->pPktInfo = pPktInfo;
+	pCesaPriv->pSaEntry = pSAEntry;
+	pCesaPriv->pCesaCmd = pCesaCmd;
+
+	pCesaPriv->pPkt   = pPkt;
+	pCesaPriv->ifout  = newpp->port;
+	pCesaPriv->inPort = inPort;
+	/*
+	 *  Fix, encrypt/decrypt the IP payload only, --BK 20091027
+	 */
+	pBuf = pPktInfo->pFrags;
+	pIpHdr = (MV_IP_HEADER *)(pBuf->bufVirtPtr + sizeof(MV_802_3_HEADER));
+	pBuf->dataSize = MV_16BIT_BE(pIpHdr->totalLength) + sizeof(MV_802_3_HEADER);
+	/* after next command, pBuf->bufVirtPtr will point to ESP */
+	pBuf->bufVirtPtr += MV_NFP_SEC_ESP_OFFSET;
+	pBuf->bufPhysAddr += MV_NFP_SEC_ESP_OFFSET;
+	pBuf->dataSize -= MV_NFP_SEC_ESP_OFFSET;
+
+	pBuf->bufAddrShift -= MV_NFP_SEC_ESP_OFFSET;
+	pCesaMbuf->pFrags = pPktInfo->pFrags;
+	pCesaMbuf->numFrags = 1;
+	pCesaMbuf->mbufSize = pBuf->dataSize;
+
+	pCesaMbuf->pFrags->bufSize = pBuf->dataSize;
+
+	pCesaCmd->pReqPrv = (MV_VOID *)pCesaPriv;
+	pCesaCmd->sessionId = pSAEntry->sid;
+	pCesaCmd->pSrc = pCesaMbuf;
+	pCesaCmd->pDst = pCesaMbuf;
+	pCesaCmd->skipFlush = MV_TRUE;
+
+	/* Assume ESP */
+	pCesaCmd->cryptoOffset = sizeof(MV_ESP_HEADER) + pSAEntry->ivSize;
+	pCesaCmd->cryptoLength =  pBuf->dataSize - (sizeof(MV_ESP_HEADER)
+				  + pSAEntry->ivSize + pSAEntry->digestSize);
+	pCesaCmd->ivFromUser = 0; /* relevant for encode only */
+	pCesaCmd->ivOffset = sizeof(MV_ESP_HEADER);
+	pCesaCmd->macOffset = 0;
+	pCesaCmd->macLength = pBuf->dataSize - pSAEntry->digestSize;
+	if ((pCesaCmd->digestOffset != 0) && ((pCesaCmd->digestOffset%4)))  {
+		printk(KERN_INFO "pBuf->dataSize=%d pSAEntry->digestSize=%d in %s\n",
+			pBuf->dataSize, pSAEntry->digestSize, __func__);
+		printk(KERN_INFO "pCesaCmd->digestOffset=%d in %s\n",
+			pCesaCmd->digestOffset, __func__);
+	}
+	pCesaCmd->digestOffset = pBuf->dataSize - pSAEntry->digestSize ;
+
+	disable_irq(CESA_IRQ(channel));
+
+	status = mvCesaAction(channel, pCesaCmd);
+	enable_irq(CESA_IRQ(channel));
+	if (status != MV_OK) {
+		pSAEntry->stats.rejected++;
+		mvOsPrintf("%s: mvCesaAction failed %d\n", __func__, status);
+	}
+	return status;
+}
+
+inline MV_STATUS mvSecEspProcess_1(struct eth_pbuf *pPkt, MV_PKT_INFO *pPktInfo,
+						  MV_NFP_SEC_SA_ENTRY *pSAEntry, struct eth_port *newpp,
+						  MV_U8 channel, int inPort)
+
+{
+	MV_CESA_COMMAND	*pCesaCmd;
+	MV_CESA_MBUF *pCesaMbuf;
+	MV_NFP_SEC_CESA_PRIV_L2FW *pCesaPriv;
+	MV_STATUS status;
+	MV_IP_HEADER *pIpHdr;
+	MV_BUF_INFO  *pBuf;
+	pCesaCmd  = &cesaCmdArray_1[cesaCmdIndx_1];
+	pCesaMbuf = &cesaMbufArray_1[cesaCmdIndx_1];
+	cesaCmdIndx_1++;
+	cesaCmdIndx_1 %= CESA_DEF_REQ_SIZE;
+	pCesaPriv = &cesaPrivArray_1[cesaPrivIndx_1++];
+	cesaPrivIndx_1 = cesaPrivIndx_1%(CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE);
+
+	pCesaPriv->pPktInfo = pPktInfo;
+	pCesaPriv->pSaEntry = pSAEntry;
+	pCesaPriv->pCesaCmd = pCesaCmd;
+
+	pCesaPriv->pPkt   = pPkt;
+	pCesaPriv->ifout  = newpp->port;
+	pCesaPriv->inPort = inPort;
+	/*
+	 *  Fix, encrypt/decrypt the IP payload only, --BK 20091027
+	 */
+	pBuf = pPktInfo->pFrags;
+	pIpHdr = (MV_IP_HEADER *)(pBuf->bufVirtPtr + sizeof(MV_802_3_HEADER));
+	pBuf->dataSize = MV_16BIT_BE(pIpHdr->totalLength) + sizeof(MV_802_3_HEADER);
+	/* after next command, pBuf->bufVirtPtr will point to ESP */
+	pBuf->bufVirtPtr += MV_NFP_SEC_ESP_OFFSET;
+	pBuf->bufPhysAddr += MV_NFP_SEC_ESP_OFFSET;
+	pBuf->dataSize -= MV_NFP_SEC_ESP_OFFSET;
+	pBuf->bufAddrShift -= MV_NFP_SEC_ESP_OFFSET;
+	pCesaMbuf->pFrags = pPktInfo->pFrags;
+	pCesaMbuf->numFrags = 1;
+	pCesaMbuf->mbufSize = pBuf->dataSize;
+	pCesaMbuf->pFrags->bufSize = pBuf->dataSize;
+
+	pCesaCmd->pReqPrv = (MV_VOID *)pCesaPriv;
+	pCesaCmd->sessionId = pSAEntry->sid;
+	pCesaCmd->pSrc = pCesaMbuf;
+	pCesaCmd->pDst = pCesaMbuf;
+	pCesaCmd->skipFlush = MV_TRUE;
+
+	/* Assume ESP */
+	pCesaCmd->cryptoOffset = sizeof(MV_ESP_HEADER) + pSAEntry->ivSize;
+	pCesaCmd->cryptoLength =  pBuf->dataSize - (sizeof(MV_ESP_HEADER)
+				  + pSAEntry->ivSize + pSAEntry->digestSize);
+	pCesaCmd->ivFromUser = 0; /* relevant for encode only */
+	pCesaCmd->ivOffset = sizeof(MV_ESP_HEADER);
+	pCesaCmd->macOffset = 0;
+	pCesaCmd->macLength = pBuf->dataSize - pSAEntry->digestSize;
+	if ((pCesaCmd->digestOffset != 0) && ((pCesaCmd->digestOffset%4)))  {
+		printk(KERN_INFO "pBuf->dataSize=%d pSAEntry->digestSize=%d in %s\n",
+			pBuf->dataSize, pSAEntry->digestSize, __func__);
+		printk(KERN_INFO "pCesaCmd->digestOffset=%d in %s\n",
+			pCesaCmd->digestOffset, __func__);
+	}
+	pCesaCmd->digestOffset = pBuf->dataSize - pSAEntry->digestSize ;
+
+	disable_irq(CESA_IRQ(channel));
+
+	status = mvCesaAction(channel, pCesaCmd);
+	enable_irq(CESA_IRQ(channel));
+	if (status != MV_OK) {
+		pSAEntry->stats.rejected++;
+		mvOsPrintf("%s: mvCesaAction failed %d\n", __func__, status);
+	}
+
+	return status;
+}
+
+inline MV_STATUS mvSecOutgoing(struct eth_pbuf *pkt, MV_PKT_INFO *pPktInfo,
+						MV_NFP_SEC_SA_ENTRY *pSAEntry, struct eth_port *new_pp,
+						int inPort, MV_U8 chan)
+{
+	MV_U8 *pTmp;
+	MV_U32 cryptoSize, encBlockMod, dSize;
+	MV_BUF_INFO *pBuf = pPktInfo->pFrags;
+	/* CESA Q is full drop. */
+	if (cesaReqResources[chan] <= 1) {
+		counterNoResources[inPort]++;
+		return MV_DROPPED;
+	}
+	cryptoSize = pBuf->dataSize - sizeof(MV_802_3_HEADER);
+
+	/* Align buffer address to beginning of new packet - TBD handle VLAN tag, LLC */
+	dSize = pSAEntry->ivSize + sizeof(MV_ESP_HEADER) + sizeof(MV_IP_HEADER);
+	pBuf->bufVirtPtr -= dSize;
+	pBuf->bufPhysAddr -= dSize;
+	pBuf->dataSize += dSize;
+	pBuf->bufAddrShift += dSize;
+
+	encBlockMod = (cryptoSize % MV_NFP_SEC_ENC_BLOCK_SIZE);
+	/* leave space for padLen + Protocol */
+	if (encBlockMod > 14) {
+		encBlockMod =  MV_NFP_SEC_ENC_BLOCK_SIZE - encBlockMod;
+		encBlockMod += MV_NFP_SEC_ENC_BLOCK_SIZE;
+	} else
+		encBlockMod =  MV_NFP_SEC_ENC_BLOCK_SIZE - encBlockMod;
+	/* expected frame size */
+	dSize = pBuf->dataSize + encBlockMod + pSAEntry->digestSize;
+
+	pBuf->dataSize += encBlockMod;
+	pTmp = pBuf->bufVirtPtr + pBuf->dataSize;
+	memset(pTmp - encBlockMod, 0, encBlockMod - 2);
+	*((MV_U8 *)(pTmp-2)) = (MV_U8)(encBlockMod-2);
+	*((MV_U8 *)(pTmp-1)) = (MV_U8)4;
+
+	pBuf->dataSize += pSAEntry->digestSize;
+
+	mvNfpSecBuildEspHdr(pPktInfo, pSAEntry);
+	mvNfpSecBuildIPTunnel(pPktInfo, pSAEntry);
+	mvNfpSecBuildMac(pPktInfo, pSAEntry);
+
+	/* flush & invalidate new MAC, IP, & ESP headers + old ip*/
+	dSize = pBuf->bufAddrShift + sizeof(MV_IP_HEADER) + sizeof(MV_802_3_HEADER);
+
+	if (chan == 0)
+	  return mvSecEspProcess_0(pkt, pPktInfo, pSAEntry, new_pp, chan, inPort);
+	else
+	  return mvSecEspProcess_1(pkt, pPktInfo, pSAEntry, new_pp, chan, inPort);
+}
+
+inline MV_STATUS handleEsp(struct eth_pbuf *pkt, struct neta_rx_desc *rx_desc,
+							struct eth_port  *new_pp, int inPort)
+{
+	MV_STATUS res;
+	int chan = 	cesaChanPort[inPort];
+
+	spin_lock(&cesa_lock[chan]);
+
+	if (chan == 0) {
+		pBufInfoArray_0[cesaCmdIndx_0].bufAddrShift = 0;
+		pBufInfoArray_0[cesaCmdIndx_0].dataSize    = pkt->bytes;
+
+		pBufInfoArray_0[cesaCmdIndx_0].bufSize     = pkt->bytes;
+		pBufInfoArray_0[cesaCmdIndx_0].bufVirtPtr  = pkt->pBuf + pkt->offset + MV_ETH_MH_SIZE;
+
+		pBufInfoArray_0[cesaCmdIndx_0].bufPhysAddr = mvOsIoVirtToPhy(NULL, pkt->pBuf + pkt->offset + MV_ETH_MH_SIZE);
+		pBufInfoArray_0[cesaCmdIndx_0].memHandle   = 0;
+
+		pPktInfoNewArray_0[cesaCmdIndx_0].pFrags = &pBufInfoArray_0[cesaCmdIndx_0];
+		pPktInfoNewArray_0[cesaCmdIndx_0].numFrags = 1;
+	} else {
+		pBufInfoArray_1[cesaCmdIndx_1].bufAddrShift = 0;
+		pBufInfoArray_1[cesaCmdIndx_1].dataSize    = pkt->bytes;
+
+		pBufInfoArray_1[cesaCmdIndx_1].bufSize     = pkt->bytes;
+		pBufInfoArray_1[cesaCmdIndx_1].bufVirtPtr  = pkt->pBuf + pkt->offset + MV_ETH_MH_SIZE;
+
+		pBufInfoArray_1[cesaCmdIndx_1].bufPhysAddr = mvOsIoVirtToPhy(NULL, pkt->pBuf + pkt->offset + MV_ETH_MH_SIZE);
+		pBufInfoArray_1[cesaCmdIndx_1].memHandle   = 0;
+
+		pPktInfoNewArray_1[cesaCmdIndx_1].pFrags = &pBufInfoArray_1[cesaCmdIndx_1];
+		pPktInfoNewArray_1[cesaCmdIndx_1].numFrags = 1;
+	}
+
+	if (chan == 0)
+		res = mvSecOutgoing(pkt, &pPktInfoNewArray_0[cesaCmdIndx_0], &sa, new_pp, inPort, chan);
+	else
+		res = mvSecOutgoing(pkt, &pPktInfoNewArray_1[cesaCmdIndx_1], &sa, new_pp, inPort, chan);
+
+	spin_unlock(&cesa_lock[chan]);
+	return res;
+}
+
+void l2fw_stats(void)
+{
+	int i;
+	for (i = 0; i < 4; i++) {
+		mvOsPrintf("number of Cesa No Resources error is port[%d]=%d \n", i, counterNoResources[i]);
+		counterNoResources[i] = 0;
+	}
+}
+
+#endif
-- 
1.7.9.5

