From ff00e684034051f50d540f26ac2be9066a060953 Mon Sep 17 00:00:00 2001
From: Uri Eliyahu <uriel@marvell.com>
Date: Wed, 16 Jan 2013 17:05:40 +0200
Subject: [PATCH 511/609] NETA L2FW IPSEC support

Change-Id: I4dd06a51fbaa81a45bbaf1ea98fcc857c5c328c9
Signed-off-by: Uri Eliyahu <uriel@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/956
Reviewed-by: Dmitri Epshtein <dima@marvell.com>
Reviewed-by: Tawfik Bayouk <tawfik@marvell.com>
Tested-by: Tawfik Bayouk <tawfik@marvell.com>
Signed-off-by: Seif Mazareeb <seif@marvell.com>
---
 .../arm/plat-armada/mv_drivers_lsp/mv_cesa/Kconfig |   56 +-
 .../mv_drivers_lsp/mv_neta/l2fw/l2fw_sysfs.c       |  156 ++--
 .../mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.c      |  443 +++++------
 .../mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.h      |   34 +-
 .../mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.c     |  780 ++++++++++++--------
 .../mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.h     |  492 ++----------
 7 files changed, 843 insertions(+), 1119 deletions(-)

diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/Kconfig b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/Kconfig
index b7b204b..d48683f 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/Kconfig
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_cesa/Kconfig
@@ -22,6 +22,37 @@ config MV_CESA_CHANNELS
 	---help---
 	Select the number of CESA channels to be used for crypto operations acceleration.
 
+
+choice
+        prompt "CESA Mode"
+        depends on MV_CESA
+        default MV_CESA_OCF_ARMADA
+
+config	MV_CESA_OCF_ARMADA
+	bool "Support for Marvell CESA OCF driver"
+	depends on OCF_OCF
+	select MV_CESA_OCF
+	---help---
+	Choosing this option will enable you to use the Marvell Cryptographic Engine and
+	Security Accelerator, under the OCF package.
+
+config  MV_CESA_TEST_ARMADA
+	bool "Support for Marvell CESA test driver"
+	depends on MV_CESA_TOOL_ARMADA
+	select MV_CESA_TEST
+	---help---
+	Choosing this option will enable you to use the Marvell Cryptographic Engine and
+	Security Accelerator, with the mv_cesa_tool in test mode.
+
+config  MV_CESA_L2FW_ARMADA
+	bool "Support for Marvell L2fw demo driver"
+	depends on MV_ETH_L2SEC
+	select MV_CESA_L2FW
+	---help---
+	Choosing this option will enable you to use the Marvell Cryptographic Engine and
+	Security Accelerator, with the l2fw demo.
+endchoice
+
 choice
 	prompt "CESA Features"
 	depends on MV_CESA
@@ -48,29 +79,6 @@ config MV_CESA_INT_PER_PACKET
 
 endchoice
 
-choice 
-        prompt "CESA Mode"
-        depends on MV_CESA
-        default MV_CESA_OCF_ARMADA
-
-config	MV_CESA_OCF_ARMADA
-	bool "Support for Marvell CESA OCF driver"
-	depends on OCF_OCF
-	select MV_CESA_OCF
-	---help---
-	Choosing this option will enable you to use the Marvell Cryptographic Engine and
-	Security Accelerator, under the OCF package.
-
-config  MV_CESA_TEST_ARMADA
-	bool "Support for Marvell CESA test driver"
-	depends on MV_CESA_TOOL_ARMADA 
-	select MV_CESA_TEST
-	---help---
-	Choosing this option will enable you to use the Marvell Cryptographic Engine and
-	Security Accelerator, with the mv_cesa_tool in test mode.
-
-endchoice
-
 config	MV_CESA_OCF
 	depends on MV_CESA_OCF_ARMADA
 	tristate
@@ -83,7 +91,5 @@ config  MV_CESA_TOOL
 	depends on MV_CESA_TOOL_ARMADA
 	tristate
 
-
 endmenu
 
-
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/l2fw_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/l2fw_sysfs.c
index cddfac5..d628937 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/l2fw_sysfs.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/l2fw_sysfs.c
@@ -34,24 +34,33 @@ disclaimer.
 
 #include "mvTypes.h"
 #include "mv_eth_l2fw.h"
-#include "linux/inet.h"
-
 #ifdef CONFIG_MV_ETH_L2SEC
-extern int l2fw_set_cesa_chan(int port, int cesaChan);
+#include "mv_eth_l2sec.h"
 #endif
+#include "linux/inet.h"
+
 
 static ssize_t l2fw_help(char *buf)
 {
 	int off = 0;
-	off += sprintf(buf+off, "help\n");
-	off += sprintf(buf+off, "echo mode rxp txp > l2fw - set l2f <rxp>->");
-	off += sprintf(buf+off, "<txp><mode> 0-dis,1-as_is,2-swap,3-copy\n");
-	off += sprintf(buf+off, "echo threshold > l2fw_xor: set threshold\n");
+
+	off += sprintf(buf+off, "cat rules_dump                        - display L2fw rules DB\n");
+	off += sprintf(buf+off, "cat ports_dump                        - display L2fw ports DB\n");
+	off += sprintf(buf+off, "cat stats                             - show debug information\n");
+
+	/* inputs in decimal */
+	off += sprintf(buf+off, "echo rxp txp mode    > l2fw           - set l2fw <rxp> --> <txp,mode> 0-dis,1-as_is,2-swap,3-copy,4-ipsec, inputs in decimal\n");
+	off += sprintf(buf+off, "echo rxp thresh      > l2fw_xor       - set for port <rxp> xor threshold , input in decimal\n");
+	off += sprintf(buf+off, "echo rxp en          > lookup         - set for port <rxp> if hash lookup is enable <en=0> or disable <en=1>\n");
+	off += sprintf(buf+off, "echo 1               > flush          - flush L2fw rules DB\n");
+
+	/* inputs in hex */
+	off += sprintf(buf+off, "echo srcIp dstIp txp > l2fw_add_ip    - set rule, srcIp and DstIp in ip address format\n");
 #ifdef CONFIG_MV_ETH_L2SEC
-	off += sprintf(buf+off, "echo 1 > esp   - enable ESP\n");
+	off += sprintf(buf+off, "echo p chan          > cesa_chan      - set cesa channel <chan> for port <p>.\n");
+
 #endif
-	off += sprintf(buf+off, "cat dump - display L2fw rules DB\n");
-	off += sprintf(buf+off, "echo 1 > flush - flush L2fw rules DB\n");
+
 	return off;
 }
 
@@ -67,32 +76,16 @@ static ssize_t l2fw_show(struct device *dev,
 	if (!strcmp(name, "help")) {
 	    off = l2fw_help(buf);
 		return off;
-	}
-	if (!strcmp(name, "dump")) {
-		l2fw_dump();
+	} else if (!strcmp(name, "rules_dump")) {
+		l2fw_rules_dump();
 		return off;
-	}
-	if (!strcmp(name, "numHashEntries")) {
-		l2fw_show_numHashEntries();
-		return off;
-	}
-#ifdef CONFIG_MV_ETH_L2SEC
-	if (!strcmp(name, "esp")) {
-		l2fw_esp_show();
+	} else if (!strcmp(name, "ports_dump")) {
+		l2fw_ports_dump();
 		return off;
-	}
-#endif
-	if (!strcmp(name, "help")) {
-	    off = l2fw_help(buf);
-		return off;
-	}
-
-#ifdef CONFIG_MV_ETH_L2SEC
-	if (!strcmp(name, "stats")) {
+	} else if (!strcmp(name, "stats")) {
 	    l2fw_stats();
 		return off;
 	}
-#endif
 
 	return off;
 }
@@ -107,26 +100,18 @@ static ssize_t l2fw_hex_store(struct device *dev, struct device_attribute *attr,
 	unsigned int    addr1, addr2;
 	int port;
 	unsigned long   flags;
-#ifdef CONFIG_MV_ETH_L2SEC
-	int             enableEsp;
-#endif
+
 	if (!capable(CAP_NET_ADMIN))
 		return -EPERM;
 	err = addr1 = addr2 = port = 0;
 
 	local_irq_save(flags);
-	if (!strcmp(name, "l2fw_add")) {
-		sscanf(buf, "%x %x %d", &addr1, &addr2, &port);
-		l2fw_add(addr1, addr2, port);
-	} else if (!strcmp(name, "l2fw_add_ip")) {
-		l2fw_add_ip(buf);
-#ifdef CONFIG_MV_ETH_L2SEC
-	} else if (!strcmp(name, "esp")) {
-		sscanf(buf, "%d", &enableEsp);
-		l2fw_esp_set(enableEsp);
-#endif
-	} else if (!strcmp(name, "flush")) {
+
+	if (!strcmp(name, "flush")) {
 		l2fw_flush();
+	} else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
 	}
 
 	local_irq_restore(flags);
@@ -134,31 +119,72 @@ static ssize_t l2fw_hex_store(struct device *dev, struct device_attribute *attr,
 	return err ? -EINVAL : len;
 }
 
+static ssize_t l2fw_ip_store(struct device *dev,
+			 struct device_attribute *attr, const char *buf, size_t len)
+{
+	const char *name = attr->attr.name;
+
+	unsigned int err = 0;
+	unsigned int srcIp = 0, dstIp = 0;
+	unsigned char * sipArr = (unsigned char *)&srcIp;
+	unsigned char * dipArr = (unsigned char *)&dstIp;
+	int port;
+	unsigned long flags;
+
+	if (!capable(CAP_NET_ADMIN))
+		return -EPERM;
+
+	sscanf(buf, "%hhu.%hhu.%hhu.%hhu %hhu.%hhu.%hhu.%hhu %d",
+		sipArr, sipArr+1, sipArr+2, sipArr+3,
+		dipArr, dipArr+1, dipArr+2, dipArr+3, &port);
+
+	printk(KERN_INFO "0x%x->0x%x in %s\n", srcIp, dstIp, __func__);
+	local_irq_save(flags);
+
+	if (!strcmp(name, "l2fw_add_ip"))
+		l2fw_add(srcIp, dstIp, port);
+	else {
+		err = 1;
+		printk(KERN_ERR "%s: illegal operation <%s>\n", __func__, attr->attr.name);
+	}
+
+	local_irq_restore(flags);
+
+	if (err)
+		printk(KERN_ERR "%s: <%s>, error %d\n", __func__, attr->attr.name, err);
+
+	return err ? -EINVAL : len;
+}
+
+
+
 static ssize_t l2fw_store(struct device *dev,
 				   struct device_attribute *attr, const char *buf, size_t len)
 {
 	const char	*name = attr->attr.name;
 	int             err;
 
-	unsigned int    p, txp, txq, v;
+	unsigned int    a, b, c;
 	unsigned long   flags;
 
 	if (!capable(CAP_NET_ADMIN))
 		return -EPERM;
 
-	err = p = txp = txq = v = 0;
-	sscanf(buf, "%d %d %d %d", &p, &txp, &txq, &v);
+	err = a = b = c = 0;
+	sscanf(buf, "%d %d %d", &a, &b, &c);
 
 	local_irq_save(flags);
 
 	if (!strcmp(name, "l2fw_xor"))
-		l2fw_xor(p);
+		l2fw_xor(a, b);
+	else if (!strcmp(name, "lookup"))
+		l2fw_lookupEn(a, b);
 
 	else if (!strcmp(name, "l2fw"))
-		l2fw(p, txp, txq);
+		l2fw(c, a, b);
 #ifdef CONFIG_MV_ETH_L2SEC
 	else if (!strcmp(name, "cesa_chan"))
-		err = l2fw_set_cesa_chan(p, txp);
+		err = mv_l2sec_set_cesa_chan(a, b);
 #endif
 	local_irq_restore(flags);
 
@@ -170,35 +196,35 @@ static ssize_t l2fw_store(struct device *dev,
 }
 
 
-static DEVICE_ATTR(l2fw,			S_IWUSR, l2fw_show, l2fw_store);
+static DEVICE_ATTR(l2fw,		S_IWUSR, l2fw_show, l2fw_store);
 static DEVICE_ATTR(l2fw_xor,		S_IWUSR, l2fw_show, l2fw_store);
-static DEVICE_ATTR(l2fw_add,		S_IWUSR, l2fw_show, l2fw_hex_store);
-static DEVICE_ATTR(l2fw_add_ip,		S_IWUSR, l2fw_show, l2fw_hex_store);
-static DEVICE_ATTR(help,			S_IRUSR, l2fw_show,  NULL);
-static DEVICE_ATTR(dump,			S_IRUSR, l2fw_show,  NULL);
-static DEVICE_ATTR(numHashEntries,	S_IRUSR, l2fw_show,  NULL);
+static DEVICE_ATTR(lookup,		S_IWUSR, l2fw_show, l2fw_store);
+static DEVICE_ATTR(l2fw_add_ip,		S_IWUSR, l2fw_show, l2fw_ip_store);
+static DEVICE_ATTR(help,		S_IRUSR, l2fw_show,  NULL);
+static DEVICE_ATTR(rules_dump,		S_IRUSR, l2fw_show,  NULL);
+static DEVICE_ATTR(ports_dump,		S_IRUSR, l2fw_show,  NULL);
+static DEVICE_ATTR(flush,		S_IWUSR, NULL,	l2fw_hex_store);
+static DEVICE_ATTR(stats,		S_IRUSR, l2fw_show, NULL);
+
 #ifdef CONFIG_MV_ETH_L2SEC
-static DEVICE_ATTR(stats,			S_IRUSR, l2fw_show, NULL);
-static DEVICE_ATTR(esp,				S_IWUSR, l2fw_show,  l2fw_hex_store);
 static DEVICE_ATTR(cesa_chan,		S_IWUSR, NULL,  l2fw_store);
 #endif
-static DEVICE_ATTR(flush,			S_IWUSR, NULL,  	 l2fw_hex_store);
+
 
 
 static struct attribute *l2fw_attrs[] = {
 	&dev_attr_l2fw.attr,
 	&dev_attr_l2fw_xor.attr,
-	&dev_attr_l2fw_add.attr,
+	&dev_attr_lookup.attr,
 	&dev_attr_l2fw_add_ip.attr,
 	&dev_attr_help.attr,
-	&dev_attr_dump.attr,
+	&dev_attr_rules_dump.attr,
+	&dev_attr_ports_dump.attr,
 	&dev_attr_flush.attr,
-#ifdef CONFIG_MV_ETH_L2SEC
-	&dev_attr_esp.attr,
 	&dev_attr_stats.attr,
+#ifdef CONFIG_MV_ETH_L2SEC
 	&dev_attr_cesa_chan.attr,
 #endif
-	&dev_attr_numHashEntries.attr,
 	NULL
 };
 
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.c
index 4439578..12ae1cb 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.c
@@ -28,6 +28,7 @@ disclaimer.
 
 #include <linux/ctype.h>
 #include <linux/module.h>
+#include  <linux/interrupt.h>
 
 #include "xor/mvXor.h"
 #include "xor/mvXorRegs.h"
@@ -38,17 +39,17 @@ disclaimer.
 #include "mv_neta/net_dev/mv_netdev.h"
 #include "gbe/mvNeta.h"
 #include "gbe/mvNetaRegs.h"
-
-#include "mv_eth_l2fw.h"
+#include "mvDebug.h"
+#include "mv_eth_l2sec.h"
 #include "ctrlEnv/mvCtrlEnvLib.h"
+#include "gbe/mvNeta.h"
 
 #ifdef CONFIG_MV_ETH_L2SEC
-extern int cesa_init(void);
-extern MV_STATUS handleEsp(struct eth_pbuf *pkt, struct neta_rx_desc *rx_desc,
-							struct eth_port  *new_pp, int inPort);
+#include "mv_eth_l2sec.h"
 #endif
+extern spinlock_t l2sec_lock;
 
-int espEnabled = 0;
+static int numHashEntries;
 
 struct eth_pbuf *mv_eth_pool_get(struct bm_pool *pool);
 
@@ -56,11 +57,10 @@ static int mv_eth_ports_l2fw_num;
 
 static L2FW_RULE **l2fw_hash = NULL;
 
-#define	L2FW_HASH_MASK   (L2FW_HASH_SIZE - 1)
-
 static MV_U32 l2fw_jhash_iv;
 
-static int numHashEntries;
+static MV_XOR_DESC *eth_xor_desc = NULL;
+static MV_LONG      eth_xor_desc_phys_addr;
 
 struct eth_port_l2fw **mv_eth_ports_l2fw;
 static inline int       mv_eth_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq);
@@ -68,56 +68,6 @@ static inline MV_STATUS mv_eth_l2fw_tx(struct eth_pbuf *pkt, struct eth_port *pp
 					   int withXor, struct neta_rx_desc *rx_desc);
 
 
-void printBufVirtPtr(MV_BUF_INFO *pBuf)
-{
-	int i;
-	if (pBuf->bufVirtPtr == NULL) {
-		printk(KERN_INFO "pBuf->bufVirtPt==NULL in %s\n", __func__);
-		return;
-	}
-	for (i = 0; i < 40; i++) {
-		printk(KERN_INFO "KERN_INFO [%d]=%x ", i, pBuf->bufVirtPtr[i]);
-		if (!(i%10) && i > 1)
-			printk(KERN_INFO "\n");
-	}
-	printk(KERN_INFO "\n****************** %s\n", __func__);
-
-}
-void printBufInfo(MV_BUF_INFO *pbuf)
-{
-	printk(KERN_INFO "bufSize=%d\n"      , pbuf->bufSize);
-	printk(KERN_INFO "dataSize=%d\n"     , pbuf->dataSize);
-	printk(KERN_INFO "memHandle=%d\n"    , pbuf->memHandle);
-	printk(KERN_INFO "bufAddrShift=%d\n" , pbuf->bufAddrShift);
-	printk(KERN_INFO "*****************************************\n\n");
-
-}
-
-
-static s32 atoi(char *psz_buf)
-{
-	char *pch = psz_buf;
-	s32 base = 0;
-	unsigned long res;
-	int ret_val;
-
-	while (isspace(*pch))
-			pch++;
-
-	if (*pch == '-' || *pch == '+') {
-			base = 10;
-			pch++;
-	} else if (*pch && tolower(pch[strlen(pch) - 1]) == 'h') {
-			base = 16;
-	}
-
-	ret_val = strict_strtoul(pch, base, &res);
-
-	return ret_val ? : res;
-}
-
-
-
 static L2FW_RULE *l2fw_lookup(MV_U32 srcIP, MV_U32 dstIP)
 {
 	MV_U32 hash;
@@ -126,6 +76,7 @@ static L2FW_RULE *l2fw_lookup(MV_U32 srcIP, MV_U32 dstIP)
 	hash = mv_jhash_3words(srcIP, dstIP, (MV_U32) 0, l2fw_jhash_iv);
 	hash &= L2FW_HASH_MASK;
 	rule = l2fw_hash[hash];
+
 #ifdef CONFIG_MV_ETH_L2FW_DEBUG
 	if (rule)
 		printk(KERN_INFO "rule is not NULL in %s\n", __func__);
@@ -138,6 +89,7 @@ static L2FW_RULE *l2fw_lookup(MV_U32 srcIP, MV_U32 dstIP)
 
 		rule = rule->next;
 	}
+
 	return NULL;
 }
 
@@ -159,7 +111,7 @@ void l2fw_flush(void)
 }
 
 
-void l2fw_dump(void)
+void l2fw_rules_dump(void)
 {
 	MV_U32 i = 0;
 	L2FW_RULE *currRule;
@@ -174,7 +126,7 @@ void l2fw_dump(void)
 		dstIP = (MV_U8 *)&(currRule->dstIP);
 
 		while (currRule != NULL) {
-			mvOsPrintf("%u.%u.%u.%u->%u.%u.%u.%u    out port=%d (hash=%x)\n",
+			mvOsPrintf("%u.%u.%u.%u->%u.%u.%u.%u     out port=%d (hash=%x)\n",
 				MV_IPQUAD(srcIP), MV_IPQUAD(dstIP),
 				currRule->port, i);
 			currRule = currRule->next;
@@ -183,6 +135,22 @@ void l2fw_dump(void)
 
 }
 
+void l2fw_ports_dump(void)
+{
+	MV_U32 rx_port = 0;
+	struct eth_port_l2fw *ppl2fw;
+
+	mvOsPrintf("\nPrinting L2fw ports Database: \n");
+	mvOsPrintf("*******************************\n");
+
+	for (rx_port = 0; rx_port < mv_eth_ports_l2fw_num; rx_port++) {
+		ppl2fw = mv_eth_ports_l2fw[rx_port];
+		mvOsPrintf("rx_port=%d cmd = %d tx_port=%d lookup=%d xor_threshold = %d\n",
+				rx_port, ppl2fw->cmd, ppl2fw->txPort, ppl2fw->lookupEn, ppl2fw->xorThreshold);
+
+	}
+}
+
 
 MV_STATUS l2fw_add(MV_U32 srcIP, MV_U32 dstIP, int port)
 {
@@ -206,102 +174,9 @@ MV_STATUS l2fw_add(MV_U32 srcIP, MV_U32 dstIP, int port)
 #endif
 
 	l2fw_rule = l2fw_lookup(srcIP, dstIP);
-	if (l2fw_rule)
-		return MV_OK;
-
-	l2fw_rule = (L2FW_RULE *)mvOsMalloc(sizeof(L2FW_RULE));
-	if (!l2fw_rule) {
-		mvOsPrintf("%s: OOM\n", __func__);
-		return MV_FAIL;
-	}
-#ifdef CONFIG_MV_ETH_L2FW_DEBUG
-	mvOsPrintf("adding a rule to l2fw hash in %s\n", __func__);
-#endif
-	l2fw_rule->srcIP = srcIP;
-	l2fw_rule->dstIP = dstIP;
-	l2fw_rule->port = port;
-
-	l2fw_rule->next = l2fw_hash[hash];
-	l2fw_hash[hash] = l2fw_rule;
-	numHashEntries++;
-    return MV_OK;
-}
-
-MV_STATUS l2fw_add_ip(const char *buf)
-{
-	char *addr1, *addr2;
-	L2FW_RULE *l2fw_rule;
-	MV_U32 srcIP;
-	MV_U32 dstIP;
-	MV_U8	  *srcIPchr, *dstIPchr;
-	char dest1[15];
-	char dest2[15];
-	char *portStr;
-	int offset1, offset2, port;
-	MV_U32 hash    = 0;
-	if (numHashEntries == L2FW_HASH_SIZE) {
-		printk(KERN_INFO "cannot add entry, hash table is full, there are %d entires \n", L2FW_HASH_SIZE);
-		return MV_ERROR;
-	}
-
-	memset(dest1,   0, sizeof(dest1));
-	memset(dest2,   0, sizeof(dest2));
-
-	addr1 = strchr(buf, ',');
-	addr2 =	strchr(addr1+1, ',');
-	offset1 = addr1-buf;
-	offset2 = addr2-addr1;
-	if (!addr1) {
-			printk(KERN_INFO "first separating comma (',') missing in input in %s\n", __func__);
-			return MV_FAIL;
-	}
-	if (!addr2) {
-			printk(KERN_INFO "second separating comma (',') missing in input in %s\n", __func__);
-			return MV_FAIL;
-	}
-
-	strncpy(dest1, buf, addr1-buf);
-	srcIP = in_aton(dest1);
-	strncpy(dest2, buf+offset1+1, addr2-addr1-1);
-	dstIP = in_aton(dest2);
-	srcIPchr = (MV_U8 *)&(srcIP);
-	dstIPchr = (MV_U8 *)&(dstIP);
-	portStr = addr2+1;
-	if (*portStr == 'D') {
-		L2FW_RULE *l2fw_rule_to_del, *prev;
-		hash = mv_jhash_3words(srcIP, dstIP, (MV_U32) 0, l2fw_jhash_iv);
-		hash &= L2FW_HASH_MASK;
-		l2fw_rule_to_del = l2fw_hash[hash];
-		prev = NULL;
-
-		while (l2fw_rule_to_del) {
-		if ((l2fw_rule_to_del->srcIP == srcIP) &&
-			(l2fw_rule_to_del->dstIP == dstIP)) {
-			if (prev)
-				prev->next = l2fw_rule_to_del->next;
-			else
-				l2fw_hash[hash] = l2fw_rule_to_del->next;
-			mvOsPrintf("%u.%u.%u.%u->%u.%u.%u.%u deleted\n", MV_IPQUAD(srcIPchr), MV_IPQUAD(dstIPchr));
-			mvOsFree(l2fw_rule_to_del);
-			numHashEntries--;
-			return MV_OK;
-		}
-
-		prev = l2fw_rule_to_del;
-		l2fw_rule_to_del = l2fw_rule_to_del->next;
-	}
-		mvOsPrintf("%u.%u.%u.%u->%u.%u.%u.%u : entry not found\n", MV_IPQUAD(srcIPchr), MV_IPQUAD(dstIPchr));
-		return MV_NOT_FOUND;
-	}
-
-	port = atoi(portStr);
-	hash = mv_jhash_3words(srcIP, dstIP, (MV_U32) 0, l2fw_jhash_iv);
-	hash &= L2FW_HASH_MASK;
-
-	l2fw_rule = l2fw_lookup(srcIP, dstIP);
 	if (l2fw_rule) {
-		mvOsPrintf("%u.%u.%u.%u->%u.%u.%u.%u : entry already exist\n",
-				MV_IPQUAD(srcIPchr), MV_IPQUAD(dstIPchr));
+		/* overwite port */
+		l2fw_rule->port = port;
 		return MV_OK;
 	}
 
@@ -321,16 +196,8 @@ MV_STATUS l2fw_add_ip(const char *buf)
 	l2fw_hash[hash] = l2fw_rule;
 	numHashEntries++;
     return MV_OK;
-
 }
 
-void l2fw_esp_show(void)
-{
-	if (espEnabled)
-		printk(KERN_INFO "ESP is enabled in %s\n", __func__);
-	else
-		printk(KERN_INFO "ESP is not enabled in %s\n", __func__);
-}
 
 #ifdef CONFIG_MV_INCLUDE_XOR
 static void dump_xor(void)
@@ -362,25 +229,11 @@ static void dump_xor(void)
 #endif
 
 
-/* L2fw defines */
-#define L2FW_DISABLE				0
-#define TX_AS_IS					1
-#define SWAP_MAC					2
-#define COPY_AND_SWAP		        3
-
-#define XOR_CAUSE_DONE_MASK(chan) ((BIT0|BIT1) << (chan * 16))
-
-static int         l2fw_xor_threshold = 200;
-static MV_XOR_DESC *eth_xor_desc = NULL;
-static MV_LONG      eth_xor_desc_phys_addr;
-
-
 static int mv_eth_poll_l2fw(struct napi_struct *napi, int budget)
 {
 	int rx_done = 0;
 	MV_U32 causeRxTx;
 	struct eth_port *pp = MV_ETH_PRIV(napi->dev);
-	read_lock(&pp->rwlock);
 
 	STAT_INFO(pp->stats.poll[smp_processor_id()]++);
 
@@ -450,19 +303,23 @@ static int mv_eth_poll_l2fw(struct napi_struct *napi, int budget)
 	}
 	pp->cpu_config[smp_processor_id()]->causeRxTx = causeRxTx;
 
-	read_unlock(&pp->rwlock);
-
 	return rx_done;
 }
 
 
-void mv_eth_set_l2fw(int cmd, int rx_port, int out_tx_port)
+void mv_eth_set_l2fw(struct eth_port_l2fw *ppl2fw, int cmd, int rx_port, int tx_port)
 {
 	struct eth_port *pp;
 	struct net_device *dev;
 	int group;
 
-	pp     = mv_eth_ports[rx_port];
+#ifndef CONFIG_MV_ETH_L2SEC
+	if (cmd == CMD_L2FW_CESA) {
+		mvOsPrintf("Invalid command (%d) - Ipsec is not defined (%s)\n", cmd, __func__);
+		return;
+	}
+#endif
+	pp = mv_eth_ports[rx_port];
 	if (!pp) {
 		mvOsPrintf("pp is NULL in setting L2FW (%s)\n", __func__);
 		return;
@@ -470,7 +327,7 @@ void mv_eth_set_l2fw(int cmd, int rx_port, int out_tx_port)
 
 	dev = pp->dev;
 	if (dev == NULL) {
-		mvOsPrintf("device is NULL in in setting L2FW (%s)\n", __func__);
+		mvOsPrintf("device is NULL in setting L2FW (%s)\n", __func__);
 		return;
 	}
 	if (!test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags))) {
@@ -479,37 +336,41 @@ void mv_eth_set_l2fw(int cmd, int rx_port, int out_tx_port)
 		return;
 	}
 
-	/* when disabling l2fw, and then ifdown/up, we should
-	   enable MV_ETH_F_CONNECT_LINUX_BIT bit so that the port will be started ok.
-	   TBD: remember last state */
+	if (cmd == ppl2fw->cmd) {
+		ppl2fw->txPort = tx_port;
+		return;
+	}
+
+	if ((cmd != CMD_L2FW_DISABLE) && (ppl2fw->cmd != CMD_L2FW_DISABLE) && (ppl2fw->cmd != CMD_L2FW_LAST)) {
+		ppl2fw->txPort = tx_port;
+		ppl2fw->cmd	= cmd;
+		return;
+	}
 
-	if (cmd == L2FW_DISABLE)
-		set_bit(MV_ETH_F_CONNECT_LINUX_BIT, &(pp->flags));
-	else
-		clear_bit(MV_ETH_F_CONNECT_LINUX_BIT, &(pp->flags));
+	/*TODO disconnect from linux in case that command != 0, connact back if cmd == 0
+	 use netif_carrier_on/netif_carrier_off
+	 netif_tx_stop_all_queues/netif_tx_wake_all_queues
+	*/
+
+	ppl2fw->txPort = tx_port;
+	ppl2fw->cmd	= cmd;
 
 	for (group = 0; group < CONFIG_MV_ETH_NAPI_GROUPS; group++) {
-		if (cmd == L2FW_DISABLE) {
-			if (test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags)))
-				napi_disable(pp->napiGroup[group]);
-			netif_napi_del(pp->napiGroup[group]);
-			netif_napi_add(dev, pp->napiGroup[group], mv_eth_poll,
-				pp->weight);
-			if (test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags)))
-				napi_enable(pp->napiGroup[group]);
-		} else {
-			if (test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags)))
-				napi_disable(pp->napiGroup[group]);
-			netif_napi_del(pp->napiGroup[group]);
-			printk(KERN_INFO "pp->weight=%d in %s\n", pp->weight, __func__);
-			netif_napi_add(dev, pp->napiGroup[group], mv_eth_poll_l2fw,
-				pp->weight);
-			if (test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags)))
-				napi_enable(pp->napiGroup[group]);
-			}
+		if (test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags)))
+			napi_disable(pp->napiGroup[group]);
+
+		netif_napi_del(pp->napiGroup[group]);
+
+		if (cmd == CMD_L2FW_DISABLE)
+			netif_napi_add(dev, pp->napiGroup[group], mv_eth_poll, pp->weight);
+		else
+			netif_napi_add(dev, pp->napiGroup[group], mv_eth_poll_l2fw, pp->weight);
+
+		if (test_bit(MV_ETH_F_STARTED_BIT, &(pp->flags)))
+			napi_enable(pp->napiGroup[group]);
 	}
-}
 
+}
 
 static inline struct eth_pbuf *l2fw_swap_mac(struct eth_pbuf *pRxPktInfo)
 {
@@ -531,13 +392,14 @@ static inline void l2fw_copy_mac(struct eth_pbuf *pRxPktInfo,
 					 struct eth_pbuf *pTxPktInfo)
 	{
 	/* copy 30 bytes (start after MH header) */
-    /* 12 for SA + DA */
+	/* 12 for SA + DA */
 	/* 18 for the rest */
 	MV_U16 *pSrc;
 	MV_U16 *pDst;
 	int i;
 	pSrc = (MV_U16 *)(pRxPktInfo->pBuf + pRxPktInfo->offset + MV_ETH_MH_SIZE);
 	pDst = (MV_U16 *)(pTxPktInfo->pBuf + pTxPktInfo->offset + MV_ETH_MH_SIZE);
+
 	/* swap mac SA and DA */
 	for (i = 0; i < 3; i++) {
 		pDst[i]   = pSrc[i+3];
@@ -625,7 +487,7 @@ struct eth_pbuf *eth_l2fw_copy_packet_withXor(struct eth_pbuf *pRxPktInfo)
 	l2fw_copy_mac(pRxPktInfo, pTxPktInfo);
 	mvOsCacheLineFlush(NULL, pTxPktInfo->pBuf + pTxPktInfo->offset);
 
-    /* Update TxPktInfo */
+	/* Update TxPktInfo */
 	pTxPktInfo->bytes = pRxPktInfo->bytes;
 	return pTxPktInfo;
 }
@@ -646,6 +508,7 @@ void setXorDesc(void)
 
     MV_REG_WRITE(XOR_NEXT_DESC_PTR_REG(1, XOR_CHAN(0)), eth_xor_desc_phys_addr);
 	dump_xor();
+	/* TODO mask xor intterupts*/
 }
 #endif
 
@@ -671,22 +534,66 @@ static inline int xorReady(void)
 void l2fw(int cmd, int rx_port, int tx_port)
 {
 	struct eth_port_l2fw *ppl2fw;
+	int max_port = CONFIG_MV_ETH_PORTS_NUM - 1;
 
-	mv_eth_ports_l2fw_num = mvCtrlEthMaxPortGet();
 	ppl2fw = mv_eth_ports_l2fw[rx_port];
-	mvOsPrintf("cmd=%d rx_port=%d tx_port=%d in %s \n",
-				cmd, rx_port, tx_port, __func__);
-	ppl2fw->txPort = tx_port;
-	ppl2fw->cmd	= cmd;
-	mv_eth_set_l2fw(cmd, rx_port, tx_port);
+
+	if ((cmd < CMD_L2FW_DISABLE) || (cmd > CMD_L2FW_LAST)) {
+		mvOsPrintf("Error: invalid command %d\n", cmd);
+		return;
+	}
+
+	if ((rx_port > max_port) || (rx_port < 0)) {
+		mvOsPrintf("Error: invalid rx port %d\n", rx_port);
+		return;
+	}
+
+	if ((tx_port > max_port) || (tx_port < 0)) {
+		mvOsPrintf("Error: invalid tx port %d\n", tx_port);
+		return;
+	}
+
+	mvOsPrintf("cmd=%d rx_port=%d tx_port=%d in %s \n", cmd, rx_port, tx_port, __func__);
+
+	mv_eth_set_l2fw(ppl2fw, cmd, rx_port, tx_port);
 }
 
-void l2fw_xor(int threshold)
+void l2fw_xor(int rx_port, int threshold)
 {
-	mvOsPrintf("setting threshold to %d in %s\n", threshold, __func__);
-	l2fw_xor_threshold = threshold;
+	int max_port = CONFIG_MV_ETH_PORTS_NUM - 1;
+
+	if (rx_port > max_port) {
+		mvOsPrintf("Error: invalid rx port %d\n", rx_port);
+		return;
+	}
+
+	mvOsPrintf("setting port %d threshold to %d in %s\n", rx_port, threshold, __func__);
+	mv_eth_ports_l2fw[rx_port]->xorThreshold = threshold;
 }
 
+void l2fw_lookupEn(int rx_port, int enable)
+{
+	int max_port = CONFIG_MV_ETH_PORTS_NUM - 1;
+
+	if (rx_port > max_port) {
+		mvOsPrintf("Error: invalid rx port %d\n", rx_port);
+		return;
+	}
+	mvOsPrintf("setting port %d lookup mode to %s in %s\n", rx_port, (enable == 1) ? "enable" : "disable", __func__);
+	mv_eth_ports_l2fw[rx_port]->lookupEn = enable;
+}
+
+void l2fw_stats(void)
+{
+	int i;
+	for (i = 0; i < CONFIG_MV_ETH_PORTS_NUM; i++) {
+		mvOsPrintf("number of errors in port[%d]=%d\n", i, mv_eth_ports_l2fw[i]->statErr);
+		mvOsPrintf("number of drops  in port[%d]=%d\n", i, mv_eth_ports_l2fw[i]->statDrop);
+	}
+#ifdef CONFIG_MV_ETH_L2SEC
+	mv_l2sec_stats();
+#endif
+}
 
 static inline MV_STATUS mv_eth_l2fw_tx(struct eth_pbuf *pkt, struct eth_port *pp, int withXor,
 									   struct neta_rx_desc *rx_desc)
@@ -700,7 +607,7 @@ static inline MV_STATUS mv_eth_l2fw_tx(struct eth_pbuf *pkt, struct eth_port *pp
 	same txq lock when traffic on several rx ports are destined to the same
 	outgoing interface */
 	int txq = pp->cpu_config[smp_processor_id()]->txq;
-	read_lock(&pp->rwlock);
+
 	txq_ctrl = &pp->txq_ctrl[pp->txp * CONFIG_MV_ETH_TXQ + txq];
 
 	mv_eth_lock(txq_ctrl, flags);
@@ -713,7 +620,7 @@ static inline MV_STATUS mv_eth_l2fw_tx(struct eth_pbuf *pkt, struct eth_port *pp
 
 		mv_eth_unlock(txq_ctrl, flags);
 
-		read_unlock(&pp->rwlock);
+		/*read_unlock(&pp->rwlock);*/
 		/* No resources: Drop */
 		pp->dev->stats.tx_dropped++;
 		if (withXor)
@@ -722,8 +629,13 @@ static inline MV_STATUS mv_eth_l2fw_tx(struct eth_pbuf *pkt, struct eth_port *pp
 	}
 	txq_ctrl->txq_count++;
 
+#ifdef CONFIG_MV_ETH_BM_CPU
 	tx_cmd |= NETA_TX_BM_ENABLE_MASK | NETA_TX_BM_POOL_ID_MASK(pkt->pool);
 	txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = (u32) NULL;
+#else
+	txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = (u32) pkt;
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
 	mv_eth_shadow_inc_put(txq_ctrl);
 
 	tx_desc->command = tx_cmd | NETA_TX_L4_CSUM_NOT |
@@ -742,7 +654,7 @@ static inline MV_STATUS mv_eth_l2fw_tx(struct eth_pbuf *pkt, struct eth_port *pp
 
 			mv_eth_unlock(txq_ctrl, flags);
 
-			read_unlock(&pp->rwlock);
+			/*read_unlock(&pp->rwlock);*/
 			return MV_DROPPED;
 		}
 	}
@@ -750,8 +662,6 @@ static inline MV_STATUS mv_eth_l2fw_tx(struct eth_pbuf *pkt, struct eth_port *pp
 
 	mv_eth_unlock(txq_ctrl, flags);
 
-	read_unlock(&pp->rwlock);
-
 	return MV_OK;
 }
 
@@ -838,48 +748,40 @@ static inline int mv_eth_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq)
 			srcIP = (MV_U8 *)&(pIph->srcIP);
 			dstIP = (MV_U8 *)&(pIph->dstIP);
 			printk(KERN_INFO "%u.%u.%u.%u->%u.%u.%u.%u in %s\n", MV_IPQUAD(srcIP), MV_IPQUAD(dstIP), __func__);
+			printk(KERN_INFO "0x%x->0x%x in %s\n", pIph->srcIP, pIph->dstIP, __func__);
 		} else
 			printk(KERN_INFO "pIph is NULL in %s\n", __func__);
 #endif
-		if (espEnabled)
-			new_pp  = mv_eth_ports[ppl2fw->txPort];
-		else {
-			 l2fw_rule = l2fw_lookup(pIph->srcIP, pIph->dstIP);
 
-			 if (!l2fw_rule) {
+		if (ppl2fw->lookupEn) {
+			l2fw_rule = l2fw_lookup(pIph->srcIP, pIph->dstIP);
+
+			if (!l2fw_rule) {
+
 #ifdef CONFIG_MV_ETH_L2FW_DEBUG
 				printk(KERN_INFO "l2fw_lookup() failed in %s\n", __func__);
 #endif
-				mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
-				continue;
-			 }
 
-#ifdef CONFIG_MV_ETH_L2FW_DEBUG
-				printk(KERN_INFO "l2fw_lookup() is ok l2fw_rule->port=%d in %s\n", l2fw_rule->port, __func__);
-#endif
-			new_pp  = mv_eth_ports[l2fw_rule->port];
-			}
+				new_pp  = mv_eth_ports[ppl2fw->txPort];
+			} else
+				new_pp  = mv_eth_ports[l2fw_rule->port];
+		} else
+			new_pp  = mv_eth_ports[ppl2fw->txPort];
 
 		switch (ppl2fw->cmd) {
-		case TX_AS_IS:
-#ifdef CONFIG_MV_ETH_L2SEC
-					if (espEnabled) {
-						status = handleEsp(pkt, rx_desc, new_pp, pp->port);
-					}
-				else
-#endif
-					status = mv_eth_l2fw_tx(pkt, new_pp, 0, rx_desc);
+		case CMD_L2FW_AS_IS:
+				status = mv_eth_l2fw_tx(pkt, new_pp, 0, rx_desc);
 				break;
 
-		case SWAP_MAC:
+		case CMD_L2FW_SWAP_MAC:
 				mvOsCacheLineInv(NULL, pkt->pBuf + pkt->offset);
 				l2fw_swap_mac(pkt);
 				mvOsCacheLineFlush(NULL, pkt->pBuf+pkt->offset);
 				status = mv_eth_l2fw_tx(pkt, new_pp, 0, rx_desc);
 				break;
 
-		case COPY_AND_SWAP:
-				if (pkt->bytes >= l2fw_xor_threshold) {
+		case CMD_L2FW_COPY_SWAP:
+				if (pkt->bytes >= ppl2fw->xorThreshold) {
 					newpkt = eth_l2fw_copy_packet_withXor(pkt);
 					if (newpkt)
 						status = mv_eth_l2fw_tx(newpkt, new_pp, 1, rx_desc);
@@ -892,25 +794,49 @@ static inline int mv_eth_l2fw_rx(struct eth_port *pp, int rx_todo, int rxq)
 						else
 							status = MV_ERROR;
 				}
-		}
+				break;
+#ifdef CONFIG_MV_ETH_L2SEC
+		case CMD_L2FW_CESA:
+				status = mv_l2sec_handle_esp(pkt, rx_desc, new_pp, pp->port);
+				break;
+#endif
+		default:
+				printk(KERN_INFO "WARNING:in %s invalid mode %d for rx port %d \n", __func__, ppl2fw->cmd, pp->port);
+				mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
+		} /*of switch*/
+
 		if (status == MV_OK) {
-			mvOsCacheLineInv(NULL, rx_desc);
+			if (mv_eth_pool_bm(pool)) {
+				/* BM - no refill */
+				mvOsCacheLineInv(NULL, rx_desc);
+			} else {
+				if (mv_eth_refill(pp, rxq, NULL, pool, rx_desc)) {
+					printk(KERN_ERR "%s: Linux processing - Can't refill\n", __func__);
+					pp->rxq_ctrl[rxq].missed++;
+				}
+			}
 			/* we do not need the pkt , we do not do anything with it*/
-			if  ((ppl2fw->cmd	== COPY_AND_SWAP) && !(espEnabled))
+			if  (ppl2fw->cmd == CMD_L2FW_COPY_SWAP)
 				mv_eth_pool_put(pool, pkt);
+
 			continue;
+
 		} else if (status == MV_DROPPED) {
+			ppl2fw->statDrop++;
 			mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
-			if ((ppl2fw->cmd	== COPY_AND_SWAP) && !(espEnabled))
+			if (ppl2fw->cmd == CMD_L2FW_COPY_SWAP)
 				mv_eth_pool_put(pool, newpkt);
 
 			continue;
+
 		} else if (status == MV_ERROR) {
-			printk(KERN_INFO "MV_ERROR in %s\n", __func__);
+			ppl2fw->statErr++;
 			mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
 		}
 
+
 	} /* of while */
+
 	/* Update RxQ management counters */
 	mvOsCacheIoSync();
 
@@ -927,6 +853,7 @@ int __devinit mv_l2fw_init(void)
 	MV_U32 regVal;
 	mv_eth_ports_l2fw_num = mvCtrlEthMaxPortGet();
 	mvOsPrintf("in %s: mv_eth_ports_l2fw_num=%d\n", __func__, mv_eth_ports_l2fw_num);
+
 	size = mv_eth_ports_l2fw_num * sizeof(struct eth_port_l2fw *);
 	mv_eth_ports_l2fw = mvOsMalloc(size);
 	if (!mv_eth_ports_l2fw)
@@ -937,8 +864,12 @@ int __devinit mv_l2fw_init(void)
 			mvOsMalloc(sizeof(struct eth_port_l2fw));
 		if (!mv_eth_ports_l2fw[port])
 			goto oom1;
-		mv_eth_ports_l2fw[port]->cmd    = L2FW_DISABLE;
+		mv_eth_ports_l2fw[port]->cmd    = CMD_L2FW_LAST/*CMD_L2FW_DISABLE*/;
 		mv_eth_ports_l2fw[port]->txPort = -1;
+		mv_eth_ports_l2fw[port]->lookupEn = 0;
+		mv_eth_ports_l2fw[port]->xorThreshold = XOR_THRESHOLD_DEF;
+		mv_eth_ports_l2fw[port]->statErr = 0;
+		mv_eth_ports_l2fw[port]->statDrop = 0;
 	}
 
 	bytes = sizeof(L2FW_RULE *) * L2FW_HASH_SIZE;
@@ -955,7 +886,7 @@ int __devinit mv_l2fw_init(void)
 	mvOsPrintf("L2FW hash init %d entries, %d bytes\n", L2FW_HASH_SIZE, bytes);
 	regVal = 0;
 #ifdef CONFIG_MV_ETH_L2SEC
-	cesa_init();
+	mv_l2sec_cesa_init();
 #endif
 
 #ifdef CONFIG_MV_INCLUDE_XOR
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.h
index f2836ce..a7136ab 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2fw.h
@@ -33,11 +33,27 @@ disclaimer.
 #include "mv_neta/net_dev/mv_netdev.h"
 
 #define	L2FW_HASH_SIZE   (1 << 17)
-extern int espEnabled;
+#define	L2FW_HASH_MASK   (L2FW_HASH_SIZE - 1)
+
+/* L2fw defines */
+#define CMD_L2FW_DISABLE			0
+#define CMD_L2FW_AS_IS				1
+#define CMD_L2FW_SWAP_MAC			2
+#define CMD_L2FW_COPY_SWAP		       	3
+#define CMD_L2FW_CESA				4
+#define CMD_L2FW_LAST				5
+
+#define XOR_CAUSE_DONE_MASK(chan) ((BIT0|BIT1) << (chan * 16))
+#define XOR_THRESHOLD_DEF			2000;
 
 struct eth_port_l2fw {
 	int cmd;
+	int lookupEn;
+	int xorThreshold;
 	int txPort;
+	/* stats */
+	int statErr;
+	int statDrop;
 };
 
 typedef struct l2fw_rule {
@@ -47,20 +63,14 @@ typedef struct l2fw_rule {
 	struct l2fw_rule *next;
 } L2FW_RULE;
 
-
+MV_STATUS l2fw_add(MV_U32 srcIP, MV_U32 dstIP, int port);
 
 void l2fw(int cmd, int rx_port, int tx_port);
-void l2fw_xor(int threshold);
-MV_STATUS l2fw_add(MV_U32 srcIP, MV_U32 dstIP, int port);
-MV_STATUS l2fw_add_ip(const char *buf);
-void l2fw_esp_show(void);
-void l2fw_esp_set(int enableEsp);
+void l2fw_xor(int rx_port, int threshold);
+void l2fw_lookupEn(int rx_port, int enable);
 void l2fw_flush(void);
-void l2fw_dump(void);
-void l2fw_show_numHashEntries(void);
+void l2fw_rules_dump(void);
+void l2fw_ports_dump(void);
 void l2fw_stats(void);
-void l2fw_mode_show(void);
-void l2fw_mode(int mode);
-
 
 #endif
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.c
index 09148eb..6134495 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.c
@@ -26,14 +26,81 @@ DISCLAIMED.  The GPL License provides additional details about this warranty
 disclaimer.
 *******************************************************************************/
 
+#include "mvOs.h"
+#include  <linux/interrupt.h>
+#include "ctrlEnv/mvCtrlEnvLib.h"
+#include "mv_neta/net_dev/mv_netdev.h"
 #include "mv_eth_l2sec.h"
+#include "mv_eth_l2fw.h"
+#include "mvDebug.h"
+#include "gbe/mvNetaRegs.h"
+#include <linux/spinlock.h>
 
-static inline MV_STATUS mv_eth_cesa_l2fw_tx(struct eth_pbuf *pkt, struct eth_port *pp)
+static struct tasklet_struct l2sec_tasklet;
+static MV_L2FW_SEC_CESA_PRIV *req_array[MV_L2FW_SEC_REQ_Q_SIZE];
+unsigned int req_empty = 0;
+unsigned int req_ready = 0;
+atomic_t req_count;
+spinlock_t cesa_lock[CESA_CHAN];
+
+extern u32 mv_crypto_virt_base_get(u8 chan);
+
+static int cesaChanPort[CONFIG_MV_ETH_PORTS_NUM];
+
+static MV_BUF_INFO *pBufInfoArray[CESA_CHAN];
+
+static int cesaPrivIndx[CESA_CHAN];
+static int cesaCmdIndx[CESA_CHAN];
+int cesaFullResBuf[CESA_CHAN];
+
+MV_L2FW_SEC_CESA_PRIV *cesaPrivArray[CESA_CHAN];
+MV_CESA_COMMAND *cesaCmdArray[CESA_CHAN];
+static MV_CESA_MBUF *cesaMbufArray[CESA_CHAN];
+void *cesaOSHandle = NULL;
+
+
+static MV_L2FW_SEC_SA_ENTRY sa;
+
+
+#define MALLOC_AND_CLEAR(_ptr_, _size_) {\
+	(_ptr_) = mvOsMalloc(_size_);\
+	if ((_ptr_) == NULL) {\
+		mvOsPrintf("Can't allocate %d bytes of memory\n", (_size_));\
+		return;\
+	 } \
+	memset((_ptr_), 0, (_size_));\
+}
+
+
+void mv_l2sec_stats()
+{
+	int chan;
+	for (chan = 0; chan < CESA_CHAN; chan++)
+		printk(KERN_INFO "number of l2sec channel %d full result buffer events = %d\n", chan, cesaFullResBuf[chan]);
+}
+
+void printEspHdr(MV_ESP_HEADER *pEspHdr)
+{
+	printk(KERN_INFO "pEspHdr->spi=%d in %s\n"  , pEspHdr->spi, __func__);
+	printk(KERN_INFO "pEspHdr->seqNum=%d in %s\n", pEspHdr->seqNum, __func__);
+}
+
+void printIpHdr(MV_IP_HEADER *pIpHdr)
+{
+	MV_U8	  *srcIP, *dstIP;
+
+	srcIP = (MV_U8 *)&(pIpHdr->srcIP);
+	dstIP = (MV_U8 *)&(pIpHdr->dstIP);
+	printk(KERN_INFO "%u.%u.%u.%u->%u.%u.%u.%u in %s\n", MV_IPQUAD(srcIP), MV_IPQUAD(dstIP), __func__);
+	printk(KERN_INFO "MV_16BIT_BE(pIpHdr->totalLength)=%d  in %s\n", MV_16BIT_BE(pIpHdr->totalLength), __func__);
+	printk(KERN_INFO "pIpHdr->protocol=%d \n", pIpHdr->protocol);
+}
+
+static inline MV_STATUS mv_eth_l2sec_tx(struct eth_pbuf *pkt, struct eth_port *pp)
 {
 	struct neta_tx_desc *tx_desc;
-	u32 tx_cmd = 0;
 	struct tx_queue *txq_ctrl;
-	unsigned long flags = 0;
+	int l3_status;
 
 	/* assigning different txq for each rx port , to avoid waiting on the
 	same txq lock when traffic on several rx ports are destined to the same
@@ -41,107 +108,103 @@ static inline MV_STATUS mv_eth_cesa_l2fw_tx(struct eth_pbuf *pkt, struct eth_por
 	int txq = 0;
 	txq_ctrl = &pp->txq_ctrl[pp->txp * CONFIG_MV_ETH_TXQ + txq];
 
-	mv_eth_lock(txq_ctrl, flags);
-
 	if (txq_ctrl->txq_count >= mv_ctrl_txdone)
 		mv_eth_txq_done(pp, txq_ctrl);
+
 	/* Get next descriptor for tx, single buffer, so FIRST & LAST */
 	tx_desc = mv_eth_tx_desc_get(txq_ctrl, 1);
-	if (tx_desc == NULL) {
-		/* printk("tx_desc == NULL pp->port=%d in %s\n", pp->port, ,__func__); */
-
-		mv_eth_unlock(txq_ctrl, flags);
 
+	if (tx_desc == NULL) {
 		/* No resources: Drop */
 		pp->dev->stats.tx_dropped++;
 		return MV_DROPPED;
 	}
 	txq_ctrl->txq_count++;
 
+#ifdef CONFIG_MV_ETH_BM_CPU
 	tx_cmd |= NETA_TX_BM_ENABLE_MASK | NETA_TX_BM_POOL_ID_MASK(pkt->pool);
 	txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = (u32) NULL;
+#else
+	txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = (u32) pkt;
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
 	mv_eth_shadow_inc_put(txq_ctrl);
+	l3_status = (0xE << NETA_TX_L3_OFFSET_OFFS) | NETA_TX_IP_CSUM_MASK | (0x5 << NETA_TX_IP_HLEN_OFFS);
 
-	tx_desc->command = tx_cmd | NETA_TX_L4_CSUM_NOT |
-		NETA_TX_FLZ_DESC_MASK | NETA_TX_F_DESC_MASK
-		| NETA_TX_L_DESC_MASK |
-		NETA_TX_PKT_OFFSET_MASK(pkt->offset + MV_ETH_MH_SIZE);
+	tx_desc->command = l3_status | NETA_TX_L4_CSUM_NOT | NETA_TX_FLZ_DESC_MASK | NETA_TX_F_DESC_MASK
+				| NETA_TX_L_DESC_MASK | NETA_TX_PKT_OFFSET_MASK(pkt->offset + MV_ETH_MH_SIZE);
 
 	tx_desc->dataSize    = pkt->bytes;
 	tx_desc->bufPhysAddr = pkt->physAddr;
 	mv_eth_tx_desc_flush(tx_desc);
 	mvNetaTxqPendDescAdd(pp->port, pp->txp, 0, 1);
 
-	mv_eth_unlock(txq_ctrl, flags);
-
 	return MV_OK;
 }
 
-static inline void nfp_sec_complete_out(unsigned long data)
+static inline void mv_l2sec_complete_out(unsigned long data)
 
 {
-	MV_NFP_SEC_CESA_PRIV_L2FW *nfp_sec_cesa_priv = (MV_NFP_SEC_CESA_PRIV_L2FW *)data;		MV_U32            ifout;
-	MV_PKT_INFO       *pkt;
+	MV_L2FW_SEC_CESA_PRIV *sec_cesa_priv = (MV_L2FW_SEC_CESA_PRIV *)data;
+	MV_U32            ifout;
 	MV_BUF_INFO       *pBuf;
 	struct eth_port   *pp;
 	struct eth_pbuf   *pPkt;
 	int oldOfsset;
 	MV_STATUS status = MV_FAIL;
 	static int counterOfFailed = 0;
-	if (!nfp_sec_cesa_priv) {
-		printk(KERN_INFO "nfp_sec_cesa_priv is NULL in %s\n", __func__);
-		return;
-	}
-	ifout = nfp_sec_cesa_priv->ifout;
 
-	pkt = nfp_sec_cesa_priv->pPktInfo;
-	if (!pkt) {
-		printk(KERN_INFO "pPktInfo is NULL in %s\n", __func__);
+	if (!sec_cesa_priv) {
+		printk(KERN_INFO "sec_cesa_priv is NULL in %s\n", __func__);
 		return;
 	}
-	pBuf = pkt->pFrags;
+	ifout = sec_cesa_priv->ifout;
+
+	pBuf = sec_cesa_priv->pBufInfo;
 	if (!pBuf) {
 		printk(KERN_INFO "pBuf is NULL in %s\n", __func__);
 		return;
 	}
-	pPkt = nfp_sec_cesa_priv->pPkt;
+	pPkt = sec_cesa_priv->pPkt;
 	if (!pPkt) {
 		printk(KERN_INFO "!pPkt) in %s\n", __func__);
 		return;
 	}
 	pPkt->bytes    = pBuf->dataSize;
-	pPkt->bytes += MV_NFP_SEC_ESP_OFFSET;
+	pPkt->bytes   += MV_L2FW_SEC_ESP_OFFSET;
 	oldOfsset      = pPkt->offset;
 	pPkt->offset   = pPkt->offset - (sizeof(MV_ESP_HEADER) + sizeof(MV_IP_HEADER) + MV_CESA_AES_BLOCK_SIZE);
 
 	pp     = mv_eth_ports[ifout];
 
-	status = 	mv_eth_cesa_l2fw_tx(pPkt, pp);
-	if (status == MV_DROPPED)
+	status = mv_eth_l2sec_tx(pPkt, pp);
+
+	pPkt->offset = oldOfsset;
+
+	if (status == MV_DROPPED) {
+		struct bm_pool *pool = &mv_eth_pool[pPkt->pool];
 		counterOfFailed++;
-	 else
-		pPkt->offset = oldOfsset;
+		mv_eth_pool_put(pool, pPkt);
+	 }
 }
 
-int l2fw_set_cesa_chan(int port, int cesaChan)
+int mv_l2sec_set_cesa_chan(int port, int cesaChan)
 {
-	/*struct eth_port *pp;*/
-	printk(KERN_INFO "setting cesaChan to %d for port=%d \n", cesaChan, port);
-	if ((cesaChan != CESA_0) && (cesaChan != CESA_1))  {
+	if (cesaChan > (MV_CESA_CHANNELS - 1)) {
 		printk(KERN_INFO "non permitted value for CESA channel \n");
 		return -EINVAL;
 	}
-/*
-	pp = mv_eth_ports[port];
-	if (pp)
-		pp->cesaChan = cesaChan;
-*/
+
+	printk(KERN_INFO "setting cesaChan to %d for port=%d \n", cesaChan, port);
+
 	cesaChanPort[port] = cesaChan;
+
 	return 0;
 }
 
 MV_STATUS my_mvSysCesaInit(int numOfSession, int queueDepth, void *osHandle)
 {
+
 	MV_CESA_HAL_DATA halData;
 	MV_UNIT_WIN_INFO addrWinMap[MAX_TARGETS + 1];
 	MV_STATUS status;
@@ -166,262 +229,156 @@ MV_STATUS my_mvSysCesaInit(int numOfSession, int queueDepth, void *osHandle)
 		halData.ctrlRev = mvCtrlRevGet();
 			status = mvCesaHalInit(numOfSession, queueDepth,
 					osHandle, &halData);
-	}
+		}
 	}
 
 	return status;
+
 }
 
-void cesaStart(void)
+void mv_l2sec_cesa_start(void)
 {
-	int bufNum, bufSize;
-	int i, j, idx;
-	MV_CESA_MBUF *pMbufSrc_0, *pMbufDst_0;
-	MV_BUF_INFO *pFragsSrc_0, *pFragsDst_0;
-	char *pBuf_0;
-
-	MV_CESA_MBUF *pMbufSrc_1, *pMbufDst_1;
-	MV_BUF_INFO *pFragsSrc_1, *pFragsDst_1;
-	char *pBuf_1;
-
-	printk(KERN_INFO "in %s\n", __func__);
-
-	cesaCmdArray_0 = 	mvOsMalloc(sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE);
-
-	if (cesaCmdArray_0 == NULL) {
-		mvOsPrintf("Can't allocate %d bytes of memory\n",
-			   (int)(sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE));
-		return;
-	}
-	memset(cesaCmdArray_0, 0, sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE);
-	/* CESA_DEF_BUF_NUM */
-	bufNum    =  1;
-	/* CESA_DEF_BUF_SIZE */
-	bufSize   = 1500;
-
-	pMbufSrc_0  = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
-	pFragsSrc_0 = mvOsMalloc(sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
-
-	pMbufDst_0  = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
-	pFragsDst_0 = mvOsMalloc(sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
-
-	if ((pMbufSrc_0 == NULL) || (pFragsSrc_0 == NULL) ||
-		(pMbufDst_0 == NULL) || (pFragsDst_0 == NULL)) {
-		mvOsPrintf(" Can't malloc Src and Dst pMbuf and pFrags structures.\n");
-		return;
-	}
-
-	memset(pMbufSrc_0,  0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
-	memset(pFragsSrc_0, 0, sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
-
-	memset(pMbufDst_0,  0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
-	memset(pFragsDst_0, 0, sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
-
-	idx = 0;
-	for (i = 0; i < CESA_DEF_REQ_SIZE; i++) {
-		pBuf_0 = mvOsIoCachedMalloc(cesaOSHandle, bufSize * bufNum * 2,
-					  &cesaBufs_0[i].bufPhysAddr, &cesaBufs_0[i].memHandle);
-		if (pBuf_0 == NULL) {
-			mvOsPrintf("testStart: Can't malloc %d bytes for pBuf\n", bufSize * bufNum * 2);
-			return;
-		}
-
-		memset(pBuf_0, 0, bufSize * bufNum * 2);
-		mvOsCacheFlush(cesaOSHandle, pBuf_0, bufSize * bufNum * 2);
-		if (pBuf_0 == NULL) {
-			mvOsPrintf("Can't allocate %d bytes for req_%d buffers\n",
-				   bufSize * bufNum * 2, i);
-			return;
-		}
-
-		cesaBufs_0[i].bufVirtPtr = (MV_U8 *) pBuf_0;
-		cesaBufs_0[i].bufSize = bufSize * bufNum * 2;
-
-		cesaCmdArray_0[i].pSrc = &pMbufSrc_0[i];
-		cesaCmdArray_0[i].pSrc->pFrags = &pFragsSrc_0[idx];
-		cesaCmdArray_0[i].pSrc->numFrags = bufNum;
-		cesaCmdArray_0[i].pSrc->mbufSize = 0;
-
-		cesaCmdArray_0[i].pDst = &pMbufDst_0[i];
-		cesaCmdArray_0[i].pDst->pFrags = &pFragsDst_0[idx];
-		cesaCmdArray_0[i].pDst->numFrags = bufNum;
-		cesaCmdArray_0[i].pDst->mbufSize = 0;
-
-		for (j = 0; j < bufNum; j++) {
-			cesaCmdArray_0[i].pSrc->pFrags[j].bufVirtPtr = (MV_U8 *) pBuf_0;
-			cesaCmdArray_0[i].pSrc->pFrags[j].bufSize = bufSize;
-			pBuf_0 += bufSize;
-			cesaCmdArray_0[i].pDst->pFrags[j].bufVirtPtr = (MV_U8 *) pBuf_0;
-
-			cesaCmdArray_0[i].pDst->pFrags[j].bufSize = bufSize;
-			pBuf_0 += bufSize;
-		}
-		idx += bufNum;
-	}
-
-	cesaMbufArray_0 = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
-	if (cesaMbufArray_0 == NULL) {
-		mvOsPrintf("Can't allocate %d bytes of memory\n",
-			   (int)(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE));
-		return;
-	}
-	memset(cesaMbufArray_0, 0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
-
-	cesaPrivArray_0 = mvOsMalloc(sizeof(MV_NFP_SEC_CESA_PRIV_L2FW) * (CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE));
-	memset(cesaPrivArray_0, 0, sizeof(MV_NFP_SEC_CESA_PRIV_L2FW) * (CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE));
-
-	/* second engine */
-	cesaCmdArray_1 = 	mvOsMalloc(sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE);
 
-	if (cesaCmdArray_1 == NULL) {
-		mvOsPrintf("Can't allocate %d bytes of memory\n",
-			   (int)(sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE));
-		return;
-	}
-	memset(cesaCmdArray_1, 0, sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE);
-
-	/* CESA_DEF_BUF_NUM */
-	bufNum    =  1;
-	/* CESA_DEF_BUF_SIZE */
-	bufSize   = 1500;
-
-	pMbufSrc_1  = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
-	pFragsSrc_1 = mvOsMalloc(sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
-
-	pMbufDst_1  = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
-	pFragsDst_1 = mvOsMalloc(sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
-
-	if ((pMbufSrc_1 == NULL) || (pFragsSrc_1 == NULL) || (pMbufDst_1 == NULL)
-		|| (pFragsDst_1 == NULL)) {
-		mvOsPrintf(" Can't malloc Src and Dst pMbuf and pFrags structures.\n");
-		return;
-	}
-
-	memset(pMbufSrc_1,  0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
-	memset(pFragsSrc_1, 0, sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
-
-	memset(pMbufDst_1,  0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
-	memset(pFragsDst_1, 0, sizeof(MV_BUF_INFO) * bufNum * CESA_DEF_REQ_SIZE);
-
-	idx = 0;
-	for (i = 0; i < CESA_DEF_REQ_SIZE; i++) {
-		pBuf_1 = mvOsIoCachedMalloc(cesaOSHandle, bufSize * bufNum * 2,
-					  &cesaBufs_1[i].bufPhysAddr, &cesaBufs_1[i].memHandle);
-		if (pBuf_1 == NULL) {
-			mvOsPrintf("testStart: Can't malloc %d bytes for pBuf\n", bufSize * bufNum * 2);
-			return;
-		}
+	MV_CESA_MBUF *pMbufSrc[CESA_CHAN], *pMbufDst[CESA_CHAN];
+	MV_BUF_INFO *pCesaBufs[CESA_CHAN], *pFragsSrc[CESA_CHAN], *pFragsDst[CESA_CHAN];
+	MV_CESA_COMMAND *cesaCmdArrTmp;
+	MV_BUF_INFO *pCesaBufsTmp;
+	int chan;
+	int i, j, idx;
+	char *pBuf;
+
+	for (chan = 0; chan < CESA_CHAN; chan++) {
+		MALLOC_AND_CLEAR(cesaCmdArray[chan], sizeof(MV_CESA_COMMAND) * CESA_DEF_REQ_SIZE);
+		MALLOC_AND_CLEAR(pMbufSrc[chan], sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+		MALLOC_AND_CLEAR(pFragsSrc[chan], sizeof(MV_BUF_INFO) * L2SEC_CESA_BUF_NUM * CESA_DEF_REQ_SIZE);
+		MALLOC_AND_CLEAR(pMbufDst[chan], sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+		MALLOC_AND_CLEAR(pFragsDst[chan], sizeof(MV_BUF_INFO) * L2SEC_CESA_BUF_NUM * CESA_DEF_REQ_SIZE);
+		MALLOC_AND_CLEAR(pCesaBufs[chan], sizeof(MV_BUF_INFO) * L2SEC_CESA_BUF_NUM * CESA_DEF_REQ_SIZE);
+
+		idx = 0;
+		pCesaBufsTmp = pCesaBufs[chan];
+		cesaCmdArrTmp = cesaCmdArray[chan];
+
+		for (i = 0; i < CESA_DEF_REQ_SIZE; i++) {
+			pBuf = mvOsIoCachedMalloc(cesaOSHandle, L2SEC_CESA_BUF_SIZE * L2SEC_CESA_BUF_NUM * 2,
+					  &pCesaBufsTmp[i].bufPhysAddr, &pCesaBufsTmp[i].memHandle);
+			if (pBuf == NULL) {
+				mvOsPrintf("testStart: Can't malloc %d bytes for pBuf\n", L2SEC_CESA_BUF_SIZE * L2SEC_CESA_BUF_NUM * 2);
+				return;
+			}
 
-		memset(pBuf_1, 0, bufSize * bufNum * 2);
-		mvOsCacheFlush(cesaOSHandle, pBuf_1, bufSize * bufNum * 2);
-		if (pBuf_1 == NULL) {
-			mvOsPrintf("Can't allocate %d bytes for req_%d buffers\n",
-				   bufSize * bufNum * 2, i);
-			return;
-		}
+			memset(pBuf, 0, L2SEC_CESA_BUF_SIZE * L2SEC_CESA_BUF_NUM * 2);
+			mvOsCacheFlush(cesaOSHandle, pBuf, L2SEC_CESA_BUF_SIZE * L2SEC_CESA_BUF_NUM * 2);
+			if (pBuf == NULL) {
+				mvOsPrintf("Can't allocate %d bytes for req_%d buffers\n",
+						L2SEC_CESA_BUF_SIZE * L2SEC_CESA_BUF_NUM * 2, i);
+				return;
+			}
 
-		cesaBufs_1[i].bufVirtPtr = (MV_U8 *) pBuf_1;
-		cesaBufs_1[i].bufSize = bufSize * bufNum * 2;
+			pCesaBufsTmp[i].bufVirtPtr = (MV_U8 *) pBuf;
+			pCesaBufsTmp[i].bufSize = L2SEC_CESA_BUF_SIZE * L2SEC_CESA_BUF_NUM * 2;
 
-		cesaCmdArray_1[i].pSrc = &pMbufSrc_1[i];
-		cesaCmdArray_1[i].pSrc->pFrags = &pFragsSrc_1[idx];
-		cesaCmdArray_1[i].pSrc->numFrags = bufNum;
-		cesaCmdArray_1[i].pSrc->mbufSize = 0;
+			cesaCmdArrTmp[i].pSrc = &pMbufSrc[chan][i];
+			cesaCmdArrTmp[i].pSrc->pFrags = &pFragsSrc[chan][idx];
+			cesaCmdArrTmp[i].pSrc->numFrags = L2SEC_CESA_BUF_NUM;
+			cesaCmdArrTmp[i].pSrc->mbufSize = 0;
 
-		cesaCmdArray_1[i].pDst = &pMbufDst_1[i];
-		cesaCmdArray_1[i].pDst->pFrags = &pFragsDst_1[idx];
-		cesaCmdArray_1[i].pDst->numFrags = bufNum;
-		cesaCmdArray_1[i].pDst->mbufSize = 0;
+			cesaCmdArrTmp[i].pDst = &pMbufDst[chan][i];
+			cesaCmdArrTmp[i].pDst->pFrags = &pFragsDst[chan][idx];
+			cesaCmdArrTmp[i].pDst->numFrags = L2SEC_CESA_BUF_NUM;
+			cesaCmdArrTmp[i].pDst->mbufSize = 0;
 
-		for (j = 0; j < bufNum; j++) {
-			cesaCmdArray_1[i].pSrc->pFrags[j].bufVirtPtr = (MV_U8 *) pBuf_1;
-			cesaCmdArray_1[i].pSrc->pFrags[j].bufSize = bufSize;
-			pBuf_1 += bufSize;
-			cesaCmdArray_1[i].pDst->pFrags[j].bufVirtPtr = (MV_U8 *) pBuf_1;
+			for (j = 0; j < L2SEC_CESA_BUF_NUM; j++) {
+				cesaCmdArrTmp[i].pSrc->pFrags[j].bufVirtPtr = (MV_U8 *) pBuf;
+				cesaCmdArrTmp[i].pSrc->pFrags[j].bufSize = L2SEC_CESA_BUF_SIZE;
+				pBuf += L2SEC_CESA_BUF_SIZE;
+				cesaCmdArrTmp[i].pDst->pFrags[j].bufVirtPtr = (MV_U8 *) pBuf;
 
-			cesaCmdArray_1[i].pDst->pFrags[j].bufSize = bufSize;
-			pBuf_1 += bufSize;
+				cesaCmdArrTmp[i].pDst->pFrags[j].bufSize = L2SEC_CESA_BUF_SIZE;
+				pBuf += L2SEC_CESA_BUF_SIZE;
+			}
+		idx += L2SEC_CESA_BUF_NUM;
 		}
-		idx += bufNum;
-	}
 
-	cesaMbufArray_1 = mvOsMalloc(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
-	if (cesaMbufArray_1 == NULL) {
-		mvOsPrintf("Can't allocate %d bytes of memory\n",
-			   (int)(sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE));
-		return;
-	}
-	memset(cesaMbufArray_1, 0, sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
-
-	cesaPrivArray_1 = mvOsMalloc(sizeof(MV_NFP_SEC_CESA_PRIV_L2FW) * (CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE));
-	memset(cesaPrivArray_1, 0, sizeof(MV_NFP_SEC_CESA_PRIV_L2FW) * (CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE));
+		MALLOC_AND_CLEAR(cesaMbufArray[chan], sizeof(MV_CESA_MBUF) * CESA_DEF_REQ_SIZE);
+		MALLOC_AND_CLEAR(pBufInfoArray[chan], sizeof(MV_BUF_INFO) * MV_L2FW_SEC_REQ_Q_SIZE);
+		MALLOC_AND_CLEAR(cesaPrivArray[chan],
+				sizeof(MV_L2FW_SEC_CESA_PRIV) * (CESA_DEF_REQ_SIZE + MV_L2FW_SEC_REQ_Q_SIZE));
 
-	pPktInfoNewArray_0 = mvOsMalloc(sizeof(MV_PKT_INFO) * MV_NFP_SEC_REQ_Q_SIZE);
+	} /*for chan*/
 
-	if (!pPktInfoNewArray_0) {
-		printk(KERN_INFO "mvOsMalloc() failed in %s\n", __func__);
-		return;
-	}
+	printk(KERN_INFO "start finished in %s\n", __func__);
+}
 
-	pBufInfoArray_0 = mvOsMalloc(sizeof(MV_BUF_INFO) * MV_NFP_SEC_REQ_Q_SIZE);
-	if (!pBufInfoArray_0) {
-		printk(KERN_INFO "could not allocate MV_BUF_INFO in %s\n", __func__);
-		return;
-	}
+/*
+ * nfp sec Interrupt handler routine.
+ */
 
-	pPktInfoNewArray_1 = mvOsMalloc(sizeof(MV_PKT_INFO) * MV_NFP_SEC_REQ_Q_SIZE);
 
-	if (!pPktInfoNewArray_1) {
-		printk(KERN_INFO "mvOsMalloc() failed in %s\n", __func__);
-		return;
-	}
-	pBufInfoArray_1 = mvOsMalloc(sizeof(MV_BUF_INFO) * MV_NFP_SEC_REQ_Q_SIZE);
-	if (!pBufInfoArray_0) {
-		printk(KERN_INFO "could not allocate MV_BUF_INFO in %s\n", __func__);
-		return;
-	}
-	printk(KERN_INFO "start finished in %s\n", __func__);
-}
 
-static irqreturn_t nfp_sec_interrupt_handler_0(int irq, void *arg)
+static irqreturn_t
+mv_l2sec_interrupt_handler(int irq, void *arg)
 {
 	MV_CESA_RESULT  	result;
-	MV_STATUS           status;
-	MV_U8 chan = 0;
+	MV_STATUS               status;
+	int chan;
 
-    MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
+	chan = (irq == CESA_IRQ(0)) ? 0 : 1;
 
+	/* clear interrupts */
+	MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
+#ifndef CONFIG_MV_CESA_INT_PER_PACKET
 	while (1) {
+#endif
 	/* Get Ready requests */
-
 	status = mvCesaReadyGet(chan, &result);
-	if (status != MV_OK)
-		break;
+	if (status != MV_OK) {
+#ifdef CONFIG_MV_CESA_INT_PER_PACKET
+		printk(KERN_ERR "ERROR: Ready get return %d\n", status);
+		return IRQ_HANDLED;
+#else
+			break;
+#endif
+	}
+	/* handle result */
+	if (atomic_read(&req_count) > (MV_L2FW_SEC_REQ_Q_SIZE - 4)) {
+		/*must take sure that no tx_done will happen on the same time.. */
+		MV_L2FW_SEC_CESA_PRIV *req_priv = (MV_L2FW_SEC_CESA_PRIV *)result.pReqPrv;
+		struct eth_pbuf *pPkt = req_priv->pPkt;
+		struct bm_pool *pool = &mv_eth_pool[pPkt->pool];
+		printk(KERN_ERR "Error: Q request is full - TBD test.\n");
+		mv_eth_pool_put(pool, pPkt);
+		cesaFullResBuf[chan]++;
+		return IRQ_HANDLED;
+	}
 
-	nfp_sec_complete_out((unsigned long)((MV_NFP_SEC_CESA_PRIV_L2FW *)result.pReqPrv));
+	req_array[req_empty] = (MV_L2FW_SEC_CESA_PRIV *)result.pReqPrv;
+	req_empty = (req_empty + 1) % MV_L2FW_SEC_REQ_Q_SIZE;
+	atomic_inc(&req_count);
+#ifndef CONFIG_MV_CESA_INT_PER_PACKET
 	}
+#endif
+	tasklet_hi_schedule(&l2sec_tasklet);
+
 	return IRQ_HANDLED;
 }
 
-static irqreturn_t nfp_sec_interrupt_handler_1(int irq, void *arg)
+void mv_l2sec_req_handler(unsigned long dummy)
 {
-	MV_CESA_RESULT  	result;
-	MV_STATUS           status;
-	MV_U8 chan = 1;
-    MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
-	while (1) {
-	/* Get Ready requests */
-	status = mvCesaReadyGet(chan, &result);
-	if (status != MV_OK)
-		break;
+	int req_count_init = atomic_read(&req_count);
+	int counter = req_count_init;
 
-	nfp_sec_complete_out((unsigned long)((MV_NFP_SEC_CESA_PRIV_L2FW *)result.pReqPrv));
+	while (counter != 0) {
+		mv_l2sec_complete_out((unsigned long)req_array[req_ready]);
+		req_ready = (req_ready + 1) % MV_L2FW_SEC_REQ_Q_SIZE;
+		counter--;
 	}
+	atomic_sub(req_count_init, &req_count);
 
-	return IRQ_HANDLED;
 }
 
-void openCesaSession(void)
+
+void mv_l2sec_open_cesa_session(void)
 {
 	unsigned char sha1Key[]  = {0x12, 0x34, 0x56, 0x78, 0x9a, 0xbc, 0xde, 0xf0,
 								0x24, 0x68, 0xac, 0xe0, 0x24, 0x68, 0xac, 0xe0,
@@ -431,17 +388,17 @@ void openCesaSession(void)
 									0x02, 0x46, 0x8a, 0xce, 0x13, 0x57, 0x9b, 0xdf};
 
 	int i;
-	MV_NFP_SEC_SA_ENTRY sa;
+	MV_L2FW_SEC_SA_ENTRY sa;
 	MV_CESA_OPEN_SESSION os;
 	unsigned short digest_size = 0;
-	memset(&sa, 0, sizeof(MV_NFP_SEC_SA_ENTRY));
+	memset(&sa, 0, sizeof(MV_L2FW_SEC_SA_ENTRY));
 	memset(&os, 0, sizeof(MV_CESA_OPEN_SESSION));
 
 	os.operation 		= MV_CESA_MAC_THEN_CRYPTO;
 	os.cryptoAlgorithm  = MV_CESA_CRYPTO_AES;
 	os.macMode  		= MV_CESA_MAC_HMAC_SHA1;
 	digest_size 		= MV_CESA_SHA1_DIGEST_SIZE;
-	os.cryptoMode 		= MV_CESA_CRYPTO_ECB;
+	os.cryptoMode 		= MV_CESA_CRYPTO_CBC;
 	for (i = 0; i < sizeof(cryptoKey); i++)
 		os.cryptoKey[i] = cryptoKey[i];
 
@@ -456,76 +413,267 @@ void openCesaSession(void)
 		printk(KERN_INFO "mvCesaSessionOpen failed in %s\n", __func__);
 }
 
-void l2fw_esp_set(int enableEsp)
+static void mv_l2sec_casa_param_init(void)
 {
-	if (enableEsp) {
-		openCesaSession();
-		printk(KERN_INFO "calling cesaStart() in %s\n", __func__);
-		cesaStart();
-	} else
-		printk(KERN_INFO "enableEsp=%d disabling ESP in %s\n", enableEsp, __func__);
-	espEnabled = enableEsp;
+	const u8 da_addr[] = {0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff};
+	const u8 sa_addr[] = {0xab, 0xac, 0xad, 0xae, 0xaf, 0xaa};
+
+	memset(&sa, 0, sizeof(MV_L2FW_SEC_SA_ENTRY));
+	sa.digestSize = MV_CESA_SHA1_DIGEST_SIZE;
+	sa.ivSize = MV_CESA_AES_BLOCK_SIZE;
+	sa.spi = 3;
+
+	sa.tunProt = MV_L2FW_SEC_TUNNEL;
+	sa.encap   = MV_L2FW_SEC_ESP;
+	sa.seqNum  = 4;
+	sa.tunnelHdr.sIp = 0x6400A8C0;
+	sa.tunnelHdr.dIp = 0x6401A8C0;
+	sa.tunnelHdr.outIfIndex = 0;
+	sa.lifeTime = 0;
+
+	sa.secOp = MV_L2FW_SEC_ENCRYPT;
+	memcpy(sa.tunnelHdr.dstMac, da_addr, 6);
+	memcpy(sa.tunnelHdr.srcMac, sa_addr, 6);
+
 }
 
-int cesa_init(void)
+int mv_l2sec_cesa_init(void)
 {
-	u8 chan = 0;
-	int i;
-	const char *irq_str[] = {"cesa0", "cesa1"};
-	printk(KERN_INFO "in %s\n", __func__);
-	for (i = 0; i < 2; i++)
-		spin_lock_init(&cesa_lock[i]);
+	int chan;
+	printk(KERN_INFO "%s: start.\n", __func__);
 	if (mvCtrlPwrClckGet(CESA_UNIT_ID, 0) == MV_FALSE)
 		return 0;
+
 	if (MV_OK != my_mvSysCesaInit(1, 256, NULL)) {
-		printk(KERN_INFO "%s,%d: mvCesaInit Failed. \n", __FILE__, __LINE__);
+		printk(KERN_INFO "%s: cesa init failed. \n", __func__);
 		return EINVAL;
 	}
 
-	/* clear and unmask Int */
-	MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
-	MV_REG_WRITE(MV_CESA_ISR_MASK_REG(chan), MV_CESA_CAUSE_ACC_DMA_MASK);
-	if (request_irq(CESA_IRQ(0), nfp_sec_interrupt_handler_0,
-							(IRQF_DISABLED) , irq_str[chan], NULL)) {
-				printk(KERN_INFO "%s,%d: cannot assign irq %x\n", __FILE__, __LINE__, CESA_IRQ(chan));
-		return EINVAL;
+	for (chan = 0 ; chan < CESA_CHAN; chan++) {
+		/* clear and unmask channel 0 interrupt */
+		MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
+		MV_REG_WRITE(MV_CESA_ISR_MASK_REG(chan), MV_CESA_CAUSE_ACC_DMA_MASK);
+
+		/* register channel 0 interrupt */
+		if (request_irq(CESA_IRQ(chan), mv_l2sec_interrupt_handler, (IRQF_DISABLED), "cesa", NULL)) {
+			printk(KERN_INFO "%s: cannot assign irq %x\n", __func__, CESA_IRQ(chan));
+			return EINVAL;
+		}
+
+		cesaChanPort[chan] = 0;
+		cesaPrivIndx[chan] = 0;
+		cesaCmdIndx[chan] = 0;
+		cesaFullResBuf[chan] = 0;
+		spin_lock_init(&cesa_lock[chan]);
 	}
 
-	chan = 1;
-	MV_REG_WRITE(MV_CESA_ISR_CAUSE_REG(chan), 0);
-	MV_REG_WRITE(MV_CESA_ISR_MASK_REG(chan), MV_CESA_CAUSE_ACC_DMA_MASK);
+	tasklet_init(&l2sec_tasklet, mv_l2sec_req_handler, (unsigned long) 0);
+	atomic_set(&req_count, 0);
 
-	if (request_irq(CESA_IRQ(1), nfp_sec_interrupt_handler_1,
-							(IRQF_DISABLED) , irq_str[chan], NULL)) {
-				printk(KERN_INFO "%s,%d: cannot assign irq %x\n", __FILE__, __LINE__, CESA_IRQ(chan));
-		return EINVAL;
-		}
+	mv_l2sec_casa_param_init();
+	mv_l2sec_open_cesa_session();
+	mv_l2sec_cesa_start();
+	printk(KERN_INFO "%s: done.\n", __func__);
 
-	atomic_set(&req_count[0], 0);
-	atomic_set(&req_count[1], 0);
-	mvOsPrintf("MV_CESA_TDMA_CTRL_REG address 0 %08x\n\n", MV_CESA_TDMA_CTRL_REG(0));
-	mvOsPrintf("MV_CESA_TDMA_CTRL_REG address 1 %08x\n\n", MV_CESA_TDMA_CTRL_REG(1));
-	mvOsPrintf("MV_CESA_TDMA_CTRL_REG(0)  %08x\n",
-		MV_REG_READ(MV_CESA_TDMA_CTRL_REG(0)));
-	mvOsPrintf("MV_CESA_TDMA_CTRL_REG(1)  %08x\n",
-		MV_REG_READ(MV_CESA_TDMA_CTRL_REG(1)));
+	return 0;
+}
 
-	memset(&sa, 0, sizeof(MV_NFP_SEC_SA_ENTRY));
-	sa.digestSize = MV_CESA_SHA1_DIGEST_SIZE;
-	sa.ivSize = MV_CESA_AES_BLOCK_SIZE;
-	sa.spi = 3;
 
-	sa.tunProt = MV_NFP_SEC_TUNNEL;
-	sa.encap   = MV_NFP_SEC_ESP;
-	sa.seqNum  = 4;
-	sa.tunnelHdr.sIp = 0x6400A8C0;
-	sa.tunnelHdr.dIp = 0x6401A8C0;
-	sa.tunnelHdr.outIfIndex = 0;
-	sa.lifeTime = 0;
+void mv_l2sec_build_tunnel(MV_BUF_INFO *pBuf, MV_L2FW_SEC_SA_ENTRY *pSAEntry)
+{
+	MV_IP_HEADER *pIpHdr, *pIntIpHdr;
+	MV_U16 newIpTotalLength;
+
+	newIpTotalLength = pBuf->dataSize - sizeof(MV_802_3_HEADER);
+	pIpHdr = (MV_IP_HEADER *) (pBuf->bufVirtPtr + sizeof(MV_802_3_HEADER));
+
+	pIntIpHdr = (MV_IP_HEADER *) ((MV_U8 *) (pIpHdr) + sizeof(MV_IP_HEADER) + sizeof(MV_ESP_HEADER) +
+				      pSAEntry->ivSize);
+
+	/* TBD - review below settings in RFC */
+	pIpHdr->version = 0x45;
+	pIpHdr->tos = 0;
+	pIpHdr->checksum = 0;
+	pIpHdr->totalLength = MV_16BIT_BE(newIpTotalLength);
+	pIpHdr->identifier = 0;
+	pIpHdr->fragmentCtrl = 0;
+	pIpHdr->ttl = pIntIpHdr->ttl - 1;
+	pIpHdr->protocol = MV_IP_PROTO_ESP;
+	pIpHdr->srcIP = pSAEntry->tunnelHdr.sIp;
+	pIpHdr->dstIP = pSAEntry->tunnelHdr.dIp;
+
+	return;
+}
 
-	sa.secOp = MV_NFP_SEC_ENCRYPT;
-	strcpy(sa.tunnelHdr.dstMac, "aabbccddeeff");
-	strcpy(sa.tunnelHdr.srcMac, "abacadaeafaa");
 
-	return 0;
+/* Append sequence number and spi, save some space for IV */
+void mv_l2sec_build_esp_hdr(MV_BUF_INFO *pBuf, MV_L2FW_SEC_SA_ENTRY *pSAEntry)
+{
+	MV_ESP_HEADER *pEspHdr;
+
+	pEspHdr = (MV_ESP_HEADER *) (pBuf->bufVirtPtr + sizeof(MV_802_3_HEADER) + sizeof(MV_IP_HEADER));
+	pEspHdr->spi = pSAEntry->spi;
+	pSAEntry->seqNum++;
+	pEspHdr->seqNum = MV_32BIT_BE(pSAEntry->seqNum);
+}
+
+void mv_l2sec_build_mac(MV_BUF_INFO *pBuf, MV_L2FW_SEC_SA_ENTRY *pSAEntry)
+{
+	MV_802_3_HEADER *pMacHdr;
+	pMacHdr = (MV_802_3_HEADER *) ((MV_U8 *) (pBuf->bufVirtPtr));
+
+	memcpy(pMacHdr, &pSAEntry->tunnelHdr.dstMac, 12);
+	pMacHdr->typeOrLen = 0x08;/* stands for IP protocol code 16bit swapped */
+	return;
+}
+
+
+MV_STATUS mv_l2sec_esp_process(struct eth_pbuf *pPkt, MV_BUF_INFO *pBuf, MV_L2FW_SEC_SA_ENTRY *pSAEntry,
+				struct eth_port *newpp, int channel, int inPort)
+{
+	MV_CESA_COMMAND	*pCesaCmd;
+	MV_CESA_MBUF *pCesaMbuf;
+	MV_L2FW_SEC_CESA_PRIV *pCesaPriv;
+	MV_STATUS status;
+	MV_IP_HEADER *pIpHdr;
+	int cmdIndx = cesaCmdIndx[channel];
+	int privIndx = cesaPrivIndx[channel];
+
+	pCesaCmd  = &cesaCmdArray[channel][cmdIndx];
+	pCesaMbuf = &cesaMbufArray[channel][cmdIndx];
+
+	cmdIndx = (cmdIndx + 1) % CESA_DEF_REQ_SIZE;
+	cesaCmdIndx[channel] = cmdIndx;
+
+	pCesaPriv = &cesaPrivArray[channel][privIndx];
+
+	privIndx = (privIndx + 1) % (CESA_DEF_REQ_SIZE + MV_L2FW_SEC_REQ_Q_SIZE);
+	cesaPrivIndx[channel] = privIndx;
+
+	pCesaPriv->pBufInfo = pBuf;
+	pCesaPriv->pSaEntry = pSAEntry;
+	pCesaPriv->pCesaCmd = pCesaCmd;
+
+	pCesaPriv->pPkt   = pPkt;
+	pCesaPriv->ifout  = newpp->port;
+	pCesaPriv->inPort = inPort;
+	/*
+	 *  Fix, encrypt/decrypt the IP payload only, --BK 20091027
+	 */
+	pIpHdr = (MV_IP_HEADER *)(pBuf->bufVirtPtr + sizeof(MV_802_3_HEADER));
+	pBuf->dataSize = MV_16BIT_BE(pIpHdr->totalLength) + sizeof(MV_802_3_HEADER);
+
+	/* after next command, pBuf->bufVirtPtr will point to ESP */
+	pBuf->bufVirtPtr += MV_L2FW_SEC_ESP_OFFSET;
+	pBuf->bufPhysAddr += MV_L2FW_SEC_ESP_OFFSET;
+	pBuf->dataSize -= MV_L2FW_SEC_ESP_OFFSET;
+
+	pBuf->bufAddrShift -= MV_L2FW_SEC_ESP_OFFSET;
+	pCesaMbuf->pFrags = pBuf;
+	pCesaMbuf->numFrags = 1;
+	pCesaMbuf->mbufSize = pBuf->dataSize;
+
+	pCesaMbuf->pFrags->bufSize = pBuf->dataSize;
+
+	pCesaCmd->pReqPrv = (void *)pCesaPriv;
+	pCesaCmd->sessionId = pSAEntry->sid;
+	pCesaCmd->pSrc = pCesaMbuf;
+	pCesaCmd->pDst = pCesaMbuf;
+	pCesaCmd->skipFlush = MV_TRUE;
+
+	/* Assume ESP */
+	pCesaCmd->cryptoOffset = sizeof(MV_ESP_HEADER) + pSAEntry->ivSize;
+	pCesaCmd->cryptoLength =  pBuf->dataSize - (sizeof(MV_ESP_HEADER)
+				  + pSAEntry->ivSize + pSAEntry->digestSize);
+	pCesaCmd->ivFromUser = 0; /* relevant for encode only */
+	pCesaCmd->ivOffset = sizeof(MV_ESP_HEADER);
+	pCesaCmd->macOffset = 0;
+	pCesaCmd->macLength = pBuf->dataSize - pSAEntry->digestSize;
+
+
+	if ((pCesaCmd->digestOffset != 0) && ((pCesaCmd->digestOffset%4)))  {
+		printk(KERN_INFO "pBuf->dataSize=%d pSAEntry->digestSize=%d in %s\n",
+			pBuf->dataSize, pSAEntry->digestSize, __func__);
+		printk(KERN_INFO "pCesaCmd->digestOffset=%d in %s\n",
+			pCesaCmd->digestOffset, __func__);
+	}
+
+	pCesaCmd->digestOffset = pBuf->dataSize - pSAEntry->digestSize ;
+
+	disable_irq(CESA_IRQ(channel));
+	status = mvCesaAction(channel, pCesaCmd);
+	enable_irq(CESA_IRQ(channel));
+
+
+	if (status != MV_OK) {
+		pSAEntry->stats.rejected++;
+		mvOsPrintf("%s: mvCesaAction failed %d\n", __func__, status);
+	}
+	return status;
+}
+
+MV_STATUS mv_l2sec_out_going(struct eth_pbuf *pkt, MV_BUF_INFO *pBuf, MV_L2FW_SEC_SA_ENTRY *pSAEntry,
+			struct eth_port *new_pp, int inPort, int chan)
+{
+	MV_U8 *pTmp;
+	MV_U32 cryptoSize, encBlockMod, dSize;
+	/* CESA Q is full drop. */
+	if (cesaReqResources[chan] <= 1)
+		return MV_DROPPED;
+
+	cryptoSize = pBuf->dataSize - sizeof(MV_802_3_HEADER);
+
+	/* Align buffer address to beginning of new packet - TBD handle VLAN tag, LLC */
+	dSize = pSAEntry->ivSize + sizeof(MV_ESP_HEADER) + sizeof(MV_IP_HEADER);
+	pBuf->bufVirtPtr -= dSize;
+	pBuf->bufPhysAddr -= dSize;
+	pBuf->dataSize += dSize;
+	pBuf->bufAddrShift += dSize;
+
+	encBlockMod = (cryptoSize % MV_L2FW_SEC_ENC_BLOCK_SIZE);
+	/* leave space for padLen + Protocol */
+	if (encBlockMod > 14) {
+		encBlockMod =  MV_L2FW_SEC_ENC_BLOCK_SIZE - encBlockMod;
+		encBlockMod += MV_L2FW_SEC_ENC_BLOCK_SIZE;
+	} else
+		encBlockMod =  MV_L2FW_SEC_ENC_BLOCK_SIZE - encBlockMod;
+
+	pBuf->dataSize += encBlockMod;
+
+	pTmp = pBuf->bufVirtPtr + pBuf->dataSize;
+	memset(pTmp - encBlockMod, 0, encBlockMod - 2);
+	*((MV_U8 *)(pTmp-2)) = (MV_U8)(encBlockMod-2);
+	*((MV_U8 *)(pTmp-1)) = (MV_U8)4;
+
+	pBuf->dataSize += pSAEntry->digestSize;
+
+	mv_l2sec_build_esp_hdr(pBuf, pSAEntry);
+	mv_l2sec_build_tunnel(pBuf, pSAEntry);
+	mv_l2sec_build_mac(pBuf, pSAEntry);
+
+	return mv_l2sec_esp_process(pkt, pBuf, pSAEntry, new_pp, chan, inPort);
+}
+
+MV_STATUS mv_l2sec_handle_esp(struct eth_pbuf *pkt, struct neta_rx_desc *rx_desc, struct eth_port  *new_pp, int inPort)
+{
+	MV_STATUS res;
+	int chan = cesaChanPort[inPort];
+	MV_BUF_INFO *pBufInfoArr = pBufInfoArray[chan];
+	int cmdIndx = cesaCmdIndx[chan];
+	spin_lock(&cesa_lock[chan]);
+
+	pBufInfoArr[cmdIndx].bufAddrShift = 0;
+	pBufInfoArr[cmdIndx].dataSize    = pkt->bytes;
+
+	pBufInfoArr[cmdIndx].bufSize     = pkt->bytes;
+	pBufInfoArr[cmdIndx].bufVirtPtr  = pkt->pBuf + pkt->offset + MV_ETH_MH_SIZE;
+
+	pBufInfoArr[cmdIndx].bufPhysAddr = mvOsIoVirtToPhy(NULL, pBufInfoArr[cmdIndx].bufVirtPtr);
+	pBufInfoArr[cmdIndx].memHandle   = 0;
+
+	res = mv_l2sec_out_going(pkt, &pBufInfoArr[cmdIndx], &sa, new_pp, inPort, chan);
+
+	spin_unlock(&cesa_lock[chan]);
+	return res;
 }
+
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.h
index 81b0ec2..3f6c265 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/l2fw/mv_eth_l2sec.h
@@ -28,493 +28,95 @@ disclaimer.
 
 #ifndef L2SEC_MV_ETH_L2SEC_H
 #define L2SEC_MV_ETH_L2SEC_H
-
-#include "mvOs.h"
-#include  <linux/interrupt.h>
 #include "cesa/mvCesa.h"
 
-#include "mv_neta/l2fw/mv_eth_l2fw.h"
-#include "ctrlEnv/mvCtrlEnvLib.h"
-#include "mv_neta/net_dev/mv_netdev.h"
-
-/* Taken from mvNfpSec.h */
 /* IPSec defines */
-#define MV_NFP_SEC_MAX_PACKET		1540
-#define MV_NFP_SEC_ENC_BLOCK_SIZE	16
+#define MV_L2FW_SEC_MAX_PACKET		1540
+#define MV_L2FW_SEC_ENC_BLOCK_SIZE	16
+#define MV_L2FW_SEC_ESP_OFFSET		34
+
+#define L2SEC_CESA_BUF_NUM	1	/* CESA_DEF_BUF_NUM */
+#define L2SEC_CESA_BUF_SIZE  1500	/* CESA_DEF_BUF_SIZE */
 
-#define MV_NFP_SEC_ESP_OFFSET		34
 
 /* IPSec Enumerators */
 typedef enum {
-	MV_NFP_SEC_TUNNEL = 0,
-	MV_NFP_SEC_TRANSPORT,
-} MV_NFP_SEC_PROT;
+	MV_L2FW_SEC_TUNNEL = 0,
+	MV_L2FW_SEC_TRANSPORT,
+} MV_L2FW_SEC_PROT;
 
 typedef enum {
-	MV_NFP_SEC_ESP = 0,
-	MV_NFP_SEC_AH,
-} MV_NFP_SEC_ENCAP;
+	MV_L2FW_SEC_ESP = 0,
+	MV_L2FW_SEC_AH,
+} MV_L2FW_SEC_ENCAP;
 
 
 typedef enum {
-	MV_NFP_SEC_ENCRYPT = 0,
-	MV_NFP_SEC_DECRYPT,
-} MV_NFP_SEC_OP;
+	MV_L2FW_SEC_ENCRYPT = 0,
+	MV_L2FW_SEC_DECRYPT,
+} MV_L2FW_SEC_OP;
 
-typedef struct _mv_nfp_sa_stats {
+typedef struct mv_l2fw_sa_stats {
 	MV_U32 encrypt;
 	MV_U32 decrypt;
 	MV_U32 rejected;	/* slow path */
 	MV_U32 dropped;		/* packet drop */
 	MV_U32 bytes;
-} MV_NFP_SA_STATS;
+} MV_L2FW_SA_STATS;
 
 /* IPSec Structures */
-typedef struct _mv_nfp_sec_tunnel_hdr {
-	MV_U32 sIp;		/*  BE */
-	MV_U32 dIp;		/* BE */
+typedef struct mv_l2fw_sec_tunnel_hdr {
+	MV_U32 sIp;			/* BE */
+	MV_U32 dIp;			/* BE */
 	/* dstMac should be 2 byte aligned */
 	MV_U8 dstMac[MV_MAC_ADDR_SIZE];	/* BE */
 	MV_U8 srcMac[MV_MAC_ADDR_SIZE];	/* BE */
 	MV_U8 outIfIndex;
-} MV_NFP_SEC_TUNNEL_HDR;
+} MV_L2FW_SEC_TUNNEL_HDR;
 
-typedef struct _mv_nfp_sec_sa_entry {
-	MV_U32 spi;		/* BE */
-	MV_NFP_SEC_PROT tunProt;
-	MV_NFP_SEC_ENCAP encap;
+typedef struct mv_l2fw_sec_sa_entry {
+	MV_U32 spi;			/* BE */
+	MV_L2FW_SEC_PROT tunProt;
+	MV_L2FW_SEC_ENCAP encap;
 	MV_U16 sid;
-	MV_U32 seqNum;		/* LE  */
-	MV_NFP_SEC_TUNNEL_HDR tunnelHdr;
+	MV_U32 seqNum;			/* LE  */
+	MV_L2FW_SEC_TUNNEL_HDR tunnelHdr;
 	MV_U32 lifeTime;
 	MV_U8 ivSize;
 	MV_U8 cipherBlockSize;
 	MV_U8 digestSize;
-	MV_NFP_SEC_OP secOp;
-	MV_NFP_SA_STATS stats;
-} MV_NFP_SEC_SA_ENTRY;
-
-typedef struct _mv_nfp_sec_cesa_priv {
-	MV_NFP_SEC_SA_ENTRY *pSaEntry;
-	MV_PKT_INFO *pPktInfo;
-	MV_U8 orgDigest[MV_CESA_MAX_DIGEST_SIZE];
-	MV_CESA_COMMAND *pCesaCmd;
-} MV_NFP_SEC_CESA_PRIV;
+	MV_L2FW_SEC_OP secOp;
+	MV_L2FW_SA_STATS stats;
+} MV_L2FW_SEC_SA_ENTRY;
 
-int cesaChanPort[CONFIG_MV_ETH_PORTS_NUM];
 
 #define CESA_0    0
 #define CESA_1    1
-/* for future - handle by CPU */
-#define CESA_NONE 2
 
-#define MV_NFP_SEC_REQ_Q_SIZE 1000
-#define CESA_DEF_REQ_SIZE       (256*4)
-int counterNoResources[4]  = {0, 0, 0, 0};
-spinlock_t cesa_lock[2];
-
-extern u32 mv_crypto_virt_base_get(u8 chan);
-static MV_PKT_INFO *pPktInfoNewArray_0;
-static MV_PKT_INFO *pPktInfoNewArray_1;
-static MV_BUF_INFO *pBufInfoArray_0;
-static MV_BUF_INFO *pBufInfoArray_1;
-
-MV_BUF_INFO cesaBufs_0[CESA_DEF_REQ_SIZE];
-MV_BUF_INFO cesaBufs_1[CESA_DEF_REQ_SIZE];
+/* define number of channels */
+#ifdef CONFIG_ARMADA_XP
+#define CESA_CHAN 2
+#else
+#define CESA_CHAN 1
+#endif
 
-static int cesaPrivIndx_0 = 0;
-static int cesaPrivIndx_1 = 0;
 
-static int cesaCmdIndx_0 = 0;
-static int cesaCmdIndx_1 = 0;
+#define MV_L2FW_SEC_REQ_Q_SIZE   1000
+#define CESA_DEF_REQ_SIZE       (256*4)
 
-typedef struct _mv_nfp_sec_cesa_priv_l2fw {
-	MV_NFP_SEC_SA_ENTRY *pSaEntry;
-	MV_PKT_INFO *pPktInfo;
+typedef struct mv_l2fw_sec_cesa_priv {
+	MV_L2FW_SEC_SA_ENTRY *pSaEntry;
+	MV_BUF_INFO *pBufInfo;
 	MV_U8 orgDigest[MV_CESA_MAX_DIGEST_SIZE];
 	MV_CESA_COMMAND *pCesaCmd;
 	struct eth_pbuf *pPkt;
 	int ifout;
 	int ownerId;
 	int inPort;
-} MV_NFP_SEC_CESA_PRIV_L2FW;
-
-MV_NFP_SEC_CESA_PRIV_L2FW *cesaPrivArray_0;
-MV_NFP_SEC_CESA_PRIV_L2FW *cesaPrivArray_1;
-
-void *cesaOSHandle = NULL;
-static MV_CESA_MBUF *cesaMbufArray_0;
-static MV_CESA_MBUF *cesaMbufArray_1;
-
-static MV_CESA_COMMAND *cesaCmdArray_0;
-static MV_CESA_COMMAND *cesaCmdArray_1;
-
-
-static MV_NFP_SEC_SA_ENTRY sa;
-atomic_t req_count[2];
-int l2fw_set_cesa_chan(int port, int cesaChan);
-int cesa_init(void);
-
-
-/* from mv_hal/eth/gbe/mvEthRegs.h */
-
-/* Tx descriptor bits */
-#define ETH_TX_ERROR_CODE_OFFSET            1
-#define ETH_TX_ERROR_CODE_MASK              (3<<ETH_TX_ERROR_CODE_OFFSET)
-#define ETH_TX_LATE_COLLISION_ERROR         (0<<ETH_TX_ERROR_CODE_OFFSET)
-#define ETH_TX_UNDERRUN_ERROR               (1<<ETH_TX_ERROR_CODE_OFFSET)
-#define ETH_TX_EXCESSIVE_COLLISION_ERROR    (2<<ETH_TX_ERROR_CODE_OFFSET)
-
-#define ETH_TX_LLC_SNAP_FORMAT_BIT          9
-#define ETH_TX_LLC_SNAP_FORMAT_MASK         (1<<ETH_TX_LLC_SNAP_FORMAT_BIT)
-
-#define ETH_TX_IP_FRAG_BIT                  10
-#define ETH_TX_IP_FRAG_MASK                 (1<<ETH_TX_IP_FRAG_BIT)
-#define ETH_TX_IP_FRAG                      (0<<ETH_TX_IP_FRAG_BIT)
-#define ETH_TX_IP_NO_FRAG                   (1<<ETH_TX_IP_FRAG_BIT)
-
-#define ETH_TX_IP_HEADER_LEN_OFFSET         11
-#define ETH_TX_IP_HEADER_LEN_ALL_MASK       (0xF<<ETH_TX_IP_HEADER_LEN_OFFSET)
-#define ETH_TX_IP_HEADER_LEN_MASK(len)      ((len)<<ETH_TX_IP_HEADER_LEN_OFFSET)
-
-#define ETH_TX_VLAN_TAGGED_FRAME_BIT        15
-#define ETH_TX_VLAN_TAGGED_FRAME_MASK       (1<<ETH_TX_VLAN_TAGGED_FRAME_BIT)
-
-#define ETH_TX_L4_TYPE_BIT                  16
-#define ETH_TX_L4_TCP_TYPE                  (0<<ETH_TX_L4_TYPE_BIT)
-#define ETH_TX_L4_UDP_TYPE                  (1<<ETH_TX_L4_TYPE_BIT)
-
-#define ETH_TX_GENERATE_L4_CHKSUM_BIT       17
-#define ETH_TX_GENERATE_L4_CHKSUM_MASK      (1<<ETH_TX_GENERATE_L4_CHKSUM_BIT)
-
-#define ETH_TX_GENERATE_IP_CHKSUM_BIT       18
-#define ETH_TX_GENERATE_IP_CHKSUM_MASK      (1<<ETH_TX_GENERATE_IP_CHKSUM_BIT)
-
-#define ETH_TX_ZERO_PADDING_BIT             19
-#define ETH_TX_ZERO_PADDING_MASK            (1<<ETH_TX_ZERO_PADDING_BIT)
-
-#define ETH_TX_LAST_DESC_BIT                20
-#define ETH_TX_LAST_DESC_MASK               (1<<ETH_TX_LAST_DESC_BIT)
-
-#define ETH_TX_FIRST_DESC_BIT               21
-#define ETH_TX_FIRST_DESC_MASK              (1<<ETH_TX_FIRST_DESC_BIT)
-
-#define ETH_TX_GENERATE_CRC_BIT             22
-#define ETH_TX_GENERATE_CRC_MASK            (1<<ETH_TX_GENERATE_CRC_BIT)
-
-#define ETH_TX_ENABLE_INTERRUPT_BIT         23
-#define ETH_TX_ENABLE_INTERRUPT_MASK        (1<<ETH_TX_ENABLE_INTERRUPT_BIT)
-
-#define ETH_TX_AUTO_MODE_BIT                30
-#define ETH_TX_AUTO_MODE_MASK               (1<<ETH_TX_AUTO_MODE_BIT)
-
-
-inline MV_VOID mvNfpSecBuildIPTunnel(MV_PKT_INFO *pPktInfo, MV_NFP_SEC_SA_ENTRY *pSAEntry)
-{
-	MV_IP_HEADER *pIpHdr, *pIntIpHdr;
-	MV_U16 newIpTotalLength;
-
-	newIpTotalLength = pPktInfo->pFrags[0].dataSize - sizeof(MV_802_3_HEADER);
-
-	pIpHdr = (MV_IP_HEADER *) (pPktInfo->pFrags[0].bufVirtPtr + sizeof(MV_802_3_HEADER));
-	pIntIpHdr = (MV_IP_HEADER *) ((MV_U8 *) (pIpHdr) + sizeof(MV_IP_HEADER) + sizeof(MV_ESP_HEADER) +
-				      pSAEntry->ivSize);
-
-	/* TBD - review below settings in RFC */
-	pIpHdr->version = 0x45;
-	pIpHdr->tos = 0;
-	pIpHdr->checksum = 0;
-	pIpHdr->totalLength = MV_16BIT_BE(newIpTotalLength);
-	pIpHdr->identifier = 0;
-	pIpHdr->fragmentCtrl = 0;
-	pIpHdr->ttl = pIntIpHdr->ttl - 1;
-	pIpHdr->protocol = MV_IP_PROTO_ESP;
-	pIpHdr->srcIP = pSAEntry->tunnelHdr.sIp;
-	pIpHdr->dstIP = pSAEntry->tunnelHdr.dIp;
-
-	pPktInfo->status = ETH_TX_IP_NO_FRAG | ETH_TX_GENERATE_IP_CHKSUM_MASK | (0x5 << ETH_TX_IP_HEADER_LEN_OFFSET);
-
-	return;
-}
-
-
-/* Append sequence number and spi, save some space for IV */
-inline MV_VOID mvNfpSecBuildEspHdr(MV_PKT_INFO *pPktInfo, MV_NFP_SEC_SA_ENTRY *pSAEntry)
-{
-	MV_ESP_HEADER *pEspHdr;
-
-	pEspHdr = (MV_ESP_HEADER *) (pPktInfo->pFrags[0].bufVirtPtr + sizeof(MV_802_3_HEADER) + sizeof(MV_IP_HEADER));
-	pEspHdr->spi = pSAEntry->spi;
-	pSAEntry->seqNum = (pSAEntry->seqNum++);
-	pEspHdr->seqNum = MV_32BIT_BE(pSAEntry->seqNum);
-}
-
-inline MV_VOID mvNfpSecBuildMac(MV_PKT_INFO *pPktInfo, MV_NFP_SEC_SA_ENTRY *pSAEntry)
-{
-	MV_802_3_HEADER *pMacHdr;
-
-	pMacHdr = (MV_802_3_HEADER *) ((MV_U8 *) (pPktInfo->pFrags[0].bufVirtPtr));
-	memcpy(pMacHdr, &pSAEntry->tunnelHdr.dstMac, 12);
-	pMacHdr->typeOrLen = 0x08;	/* stands for IP protocol code 16bit swapped */
-	return;
-}
+} MV_L2FW_SEC_CESA_PRIV;
 
-
-inline MV_STATUS mvSecEspProcess_0(struct eth_pbuf *pPkt, MV_PKT_INFO *pPktInfo,
-							MV_NFP_SEC_SA_ENTRY *pSAEntry, struct eth_port *newpp,
-							MV_U8 channel, int inPort)
-{
-	MV_CESA_COMMAND	*pCesaCmd;
-	MV_CESA_MBUF *pCesaMbuf;
-	MV_NFP_SEC_CESA_PRIV_L2FW *pCesaPriv;
-	MV_STATUS status;
-	MV_IP_HEADER *pIpHdr;
-	MV_BUF_INFO  *pBuf;
-
-	pCesaCmd  = &cesaCmdArray_0[cesaCmdIndx_0];
-	pCesaMbuf = &cesaMbufArray_0[cesaCmdIndx_0];
-	cesaCmdIndx_0++;
-
-	cesaCmdIndx_0 %= CESA_DEF_REQ_SIZE;
-	pCesaPriv = &cesaPrivArray_0[cesaPrivIndx_0++];
-
-	cesaPrivIndx_0 = cesaPrivIndx_0%(CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE);
-
-	pCesaPriv->pPktInfo = pPktInfo;
-	pCesaPriv->pSaEntry = pSAEntry;
-	pCesaPriv->pCesaCmd = pCesaCmd;
-
-	pCesaPriv->pPkt   = pPkt;
-	pCesaPriv->ifout  = newpp->port;
-	pCesaPriv->inPort = inPort;
-	/*
-	 *  Fix, encrypt/decrypt the IP payload only, --BK 20091027
-	 */
-	pBuf = pPktInfo->pFrags;
-	pIpHdr = (MV_IP_HEADER *)(pBuf->bufVirtPtr + sizeof(MV_802_3_HEADER));
-	pBuf->dataSize = MV_16BIT_BE(pIpHdr->totalLength) + sizeof(MV_802_3_HEADER);
-	/* after next command, pBuf->bufVirtPtr will point to ESP */
-	pBuf->bufVirtPtr += MV_NFP_SEC_ESP_OFFSET;
-	pBuf->bufPhysAddr += MV_NFP_SEC_ESP_OFFSET;
-	pBuf->dataSize -= MV_NFP_SEC_ESP_OFFSET;
-
-	pBuf->bufAddrShift -= MV_NFP_SEC_ESP_OFFSET;
-	pCesaMbuf->pFrags = pPktInfo->pFrags;
-	pCesaMbuf->numFrags = 1;
-	pCesaMbuf->mbufSize = pBuf->dataSize;
-
-	pCesaMbuf->pFrags->bufSize = pBuf->dataSize;
-
-	pCesaCmd->pReqPrv = (MV_VOID *)pCesaPriv;
-	pCesaCmd->sessionId = pSAEntry->sid;
-	pCesaCmd->pSrc = pCesaMbuf;
-	pCesaCmd->pDst = pCesaMbuf;
-	pCesaCmd->skipFlush = MV_TRUE;
-
-	/* Assume ESP */
-	pCesaCmd->cryptoOffset = sizeof(MV_ESP_HEADER) + pSAEntry->ivSize;
-	pCesaCmd->cryptoLength =  pBuf->dataSize - (sizeof(MV_ESP_HEADER)
-				  + pSAEntry->ivSize + pSAEntry->digestSize);
-	pCesaCmd->ivFromUser = 0; /* relevant for encode only */
-	pCesaCmd->ivOffset = sizeof(MV_ESP_HEADER);
-	pCesaCmd->macOffset = 0;
-	pCesaCmd->macLength = pBuf->dataSize - pSAEntry->digestSize;
-	if ((pCesaCmd->digestOffset != 0) && ((pCesaCmd->digestOffset%4)))  {
-		printk(KERN_INFO "pBuf->dataSize=%d pSAEntry->digestSize=%d in %s\n",
-			pBuf->dataSize, pSAEntry->digestSize, __func__);
-		printk(KERN_INFO "pCesaCmd->digestOffset=%d in %s\n",
-			pCesaCmd->digestOffset, __func__);
-	}
-	pCesaCmd->digestOffset = pBuf->dataSize - pSAEntry->digestSize ;
-
-	disable_irq(CESA_IRQ(channel));
-
-	status = mvCesaAction(channel, pCesaCmd);
-	enable_irq(CESA_IRQ(channel));
-	if (status != MV_OK) {
-		pSAEntry->stats.rejected++;
-		mvOsPrintf("%s: mvCesaAction failed %d\n", __func__, status);
-	}
-	return status;
-}
-
-inline MV_STATUS mvSecEspProcess_1(struct eth_pbuf *pPkt, MV_PKT_INFO *pPktInfo,
-						  MV_NFP_SEC_SA_ENTRY *pSAEntry, struct eth_port *newpp,
-						  MV_U8 channel, int inPort)
-
-{
-	MV_CESA_COMMAND	*pCesaCmd;
-	MV_CESA_MBUF *pCesaMbuf;
-	MV_NFP_SEC_CESA_PRIV_L2FW *pCesaPriv;
-	MV_STATUS status;
-	MV_IP_HEADER *pIpHdr;
-	MV_BUF_INFO  *pBuf;
-	pCesaCmd  = &cesaCmdArray_1[cesaCmdIndx_1];
-	pCesaMbuf = &cesaMbufArray_1[cesaCmdIndx_1];
-	cesaCmdIndx_1++;
-	cesaCmdIndx_1 %= CESA_DEF_REQ_SIZE;
-	pCesaPriv = &cesaPrivArray_1[cesaPrivIndx_1++];
-	cesaPrivIndx_1 = cesaPrivIndx_1%(CESA_DEF_REQ_SIZE + MV_NFP_SEC_REQ_Q_SIZE);
-
-	pCesaPriv->pPktInfo = pPktInfo;
-	pCesaPriv->pSaEntry = pSAEntry;
-	pCesaPriv->pCesaCmd = pCesaCmd;
-
-	pCesaPriv->pPkt   = pPkt;
-	pCesaPriv->ifout  = newpp->port;
-	pCesaPriv->inPort = inPort;
-	/*
-	 *  Fix, encrypt/decrypt the IP payload only, --BK 20091027
-	 */
-	pBuf = pPktInfo->pFrags;
-	pIpHdr = (MV_IP_HEADER *)(pBuf->bufVirtPtr + sizeof(MV_802_3_HEADER));
-	pBuf->dataSize = MV_16BIT_BE(pIpHdr->totalLength) + sizeof(MV_802_3_HEADER);
-	/* after next command, pBuf->bufVirtPtr will point to ESP */
-	pBuf->bufVirtPtr += MV_NFP_SEC_ESP_OFFSET;
-	pBuf->bufPhysAddr += MV_NFP_SEC_ESP_OFFSET;
-	pBuf->dataSize -= MV_NFP_SEC_ESP_OFFSET;
-	pBuf->bufAddrShift -= MV_NFP_SEC_ESP_OFFSET;
-	pCesaMbuf->pFrags = pPktInfo->pFrags;
-	pCesaMbuf->numFrags = 1;
-	pCesaMbuf->mbufSize = pBuf->dataSize;
-	pCesaMbuf->pFrags->bufSize = pBuf->dataSize;
-
-	pCesaCmd->pReqPrv = (MV_VOID *)pCesaPriv;
-	pCesaCmd->sessionId = pSAEntry->sid;
-	pCesaCmd->pSrc = pCesaMbuf;
-	pCesaCmd->pDst = pCesaMbuf;
-	pCesaCmd->skipFlush = MV_TRUE;
-
-	/* Assume ESP */
-	pCesaCmd->cryptoOffset = sizeof(MV_ESP_HEADER) + pSAEntry->ivSize;
-	pCesaCmd->cryptoLength =  pBuf->dataSize - (sizeof(MV_ESP_HEADER)
-				  + pSAEntry->ivSize + pSAEntry->digestSize);
-	pCesaCmd->ivFromUser = 0; /* relevant for encode only */
-	pCesaCmd->ivOffset = sizeof(MV_ESP_HEADER);
-	pCesaCmd->macOffset = 0;
-	pCesaCmd->macLength = pBuf->dataSize - pSAEntry->digestSize;
-	if ((pCesaCmd->digestOffset != 0) && ((pCesaCmd->digestOffset%4)))  {
-		printk(KERN_INFO "pBuf->dataSize=%d pSAEntry->digestSize=%d in %s\n",
-			pBuf->dataSize, pSAEntry->digestSize, __func__);
-		printk(KERN_INFO "pCesaCmd->digestOffset=%d in %s\n",
-			pCesaCmd->digestOffset, __func__);
-	}
-	pCesaCmd->digestOffset = pBuf->dataSize - pSAEntry->digestSize ;
-
-	disable_irq(CESA_IRQ(channel));
-
-	status = mvCesaAction(channel, pCesaCmd);
-	enable_irq(CESA_IRQ(channel));
-	if (status != MV_OK) {
-		pSAEntry->stats.rejected++;
-		mvOsPrintf("%s: mvCesaAction failed %d\n", __func__, status);
-	}
-
-	return status;
-}
-
-inline MV_STATUS mvSecOutgoing(struct eth_pbuf *pkt, MV_PKT_INFO *pPktInfo,
-						MV_NFP_SEC_SA_ENTRY *pSAEntry, struct eth_port *new_pp,
-						int inPort, MV_U8 chan)
-{
-	MV_U8 *pTmp;
-	MV_U32 cryptoSize, encBlockMod, dSize;
-	MV_BUF_INFO *pBuf = pPktInfo->pFrags;
-	/* CESA Q is full drop. */
-	if (cesaReqResources[chan] <= 1) {
-		counterNoResources[inPort]++;
-		return MV_DROPPED;
-	}
-	cryptoSize = pBuf->dataSize - sizeof(MV_802_3_HEADER);
-
-	/* Align buffer address to beginning of new packet - TBD handle VLAN tag, LLC */
-	dSize = pSAEntry->ivSize + sizeof(MV_ESP_HEADER) + sizeof(MV_IP_HEADER);
-	pBuf->bufVirtPtr -= dSize;
-	pBuf->bufPhysAddr -= dSize;
-	pBuf->dataSize += dSize;
-	pBuf->bufAddrShift += dSize;
-
-	encBlockMod = (cryptoSize % MV_NFP_SEC_ENC_BLOCK_SIZE);
-	/* leave space for padLen + Protocol */
-	if (encBlockMod > 14) {
-		encBlockMod =  MV_NFP_SEC_ENC_BLOCK_SIZE - encBlockMod;
-		encBlockMod += MV_NFP_SEC_ENC_BLOCK_SIZE;
-	} else
-		encBlockMod =  MV_NFP_SEC_ENC_BLOCK_SIZE - encBlockMod;
-	/* expected frame size */
-	dSize = pBuf->dataSize + encBlockMod + pSAEntry->digestSize;
-
-	pBuf->dataSize += encBlockMod;
-	pTmp = pBuf->bufVirtPtr + pBuf->dataSize;
-	memset(pTmp - encBlockMod, 0, encBlockMod - 2);
-	*((MV_U8 *)(pTmp-2)) = (MV_U8)(encBlockMod-2);
-	*((MV_U8 *)(pTmp-1)) = (MV_U8)4;
-
-	pBuf->dataSize += pSAEntry->digestSize;
-
-	mvNfpSecBuildEspHdr(pPktInfo, pSAEntry);
-	mvNfpSecBuildIPTunnel(pPktInfo, pSAEntry);
-	mvNfpSecBuildMac(pPktInfo, pSAEntry);
-
-	/* flush & invalidate new MAC, IP, & ESP headers + old ip*/
-	dSize = pBuf->bufAddrShift + sizeof(MV_IP_HEADER) + sizeof(MV_802_3_HEADER);
-
-	if (chan == 0)
-	  return mvSecEspProcess_0(pkt, pPktInfo, pSAEntry, new_pp, chan, inPort);
-	else
-	  return mvSecEspProcess_1(pkt, pPktInfo, pSAEntry, new_pp, chan, inPort);
-}
-
-inline MV_STATUS handleEsp(struct eth_pbuf *pkt, struct neta_rx_desc *rx_desc,
-							struct eth_port  *new_pp, int inPort)
-{
-	MV_STATUS res;
-	int chan = 	cesaChanPort[inPort];
-
-	spin_lock(&cesa_lock[chan]);
-
-	if (chan == 0) {
-		pBufInfoArray_0[cesaCmdIndx_0].bufAddrShift = 0;
-		pBufInfoArray_0[cesaCmdIndx_0].dataSize    = pkt->bytes;
-
-		pBufInfoArray_0[cesaCmdIndx_0].bufSize     = pkt->bytes;
-		pBufInfoArray_0[cesaCmdIndx_0].bufVirtPtr  = pkt->pBuf + pkt->offset + MV_ETH_MH_SIZE;
-
-		pBufInfoArray_0[cesaCmdIndx_0].bufPhysAddr = mvOsIoVirtToPhy(NULL, pkt->pBuf + pkt->offset + MV_ETH_MH_SIZE);
-		pBufInfoArray_0[cesaCmdIndx_0].memHandle   = 0;
-
-		pPktInfoNewArray_0[cesaCmdIndx_0].pFrags = &pBufInfoArray_0[cesaCmdIndx_0];
-		pPktInfoNewArray_0[cesaCmdIndx_0].numFrags = 1;
-	} else {
-		pBufInfoArray_1[cesaCmdIndx_1].bufAddrShift = 0;
-		pBufInfoArray_1[cesaCmdIndx_1].dataSize    = pkt->bytes;
-
-		pBufInfoArray_1[cesaCmdIndx_1].bufSize     = pkt->bytes;
-		pBufInfoArray_1[cesaCmdIndx_1].bufVirtPtr  = pkt->pBuf + pkt->offset + MV_ETH_MH_SIZE;
-
-		pBufInfoArray_1[cesaCmdIndx_1].bufPhysAddr = mvOsIoVirtToPhy(NULL, pkt->pBuf + pkt->offset + MV_ETH_MH_SIZE);
-		pBufInfoArray_1[cesaCmdIndx_1].memHandle   = 0;
-
-		pPktInfoNewArray_1[cesaCmdIndx_1].pFrags = &pBufInfoArray_1[cesaCmdIndx_1];
-		pPktInfoNewArray_1[cesaCmdIndx_1].numFrags = 1;
-	}
-
-	if (chan == 0)
-		res = mvSecOutgoing(pkt, &pPktInfoNewArray_0[cesaCmdIndx_0], &sa, new_pp, inPort, chan);
-	else
-		res = mvSecOutgoing(pkt, &pPktInfoNewArray_1[cesaCmdIndx_1], &sa, new_pp, inPort, chan);
-
-	spin_unlock(&cesa_lock[chan]);
-	return res;
-}
-
-void l2fw_stats(void)
-{
-	int i;
-	for (i = 0; i < 4; i++) {
-		mvOsPrintf("number of Cesa No Resources error is port[%d]=%d \n", i, counterNoResources[i]);
-		counterNoResources[i] = 0;
-	}
-}
-
-#endif
+MV_STATUS mv_l2sec_handle_esp(struct eth_pbuf *pkt, struct neta_rx_desc *rx_desc, struct eth_port  *new_pp, int inPort);
+int mv_l2sec_cesa_init(void);
+void mv_l2sec_stats(void);
+int mv_l2sec_set_cesa_chan(int port, int cesaChan);
+#endif /*L2SEC_MV_ETH_L2SEC_H*/
-- 
1.7.9.5

