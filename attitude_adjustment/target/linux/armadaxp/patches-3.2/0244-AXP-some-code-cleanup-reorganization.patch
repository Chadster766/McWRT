From b09cdfac6b86421072044feeaaea332511240d79 Mon Sep 17 00:00:00 2001
From: Seif Mazareeb <seif@marvell.com>
Date: Wed, 25 Jul 2012 18:58:18 +0300
Subject: [PATCH 244/609] AXP some code cleanup / reorganization

Signed-off-by: Nadav Haklai <nadavh@marvell.com>
Signed-off-by: Seif Mazareeb <seif@marvell.com>
---
 arch/arm/mach-armadaxp/irq.c |  276 +++++++++++++++++++++---------------------
 1 file changed, 135 insertions(+), 141 deletions(-)

diff --git a/arch/arm/mach-armadaxp/irq.c b/arch/arm/mach-armadaxp/irq.c
index 09fb924..d625871 100644
--- a/arch/arm/mach-armadaxp/irq.c
+++ b/arch/arm/mach-armadaxp/irq.c
@@ -37,27 +37,27 @@ __setup("per_cpu_irq_enable", per_cpu_irq_setup);
 
 static void axp_unmask_fabric_interrupt(int cpu)
 {
-u32 val;
-val = MV_REG_READ(CPU_CF_LOCAL_MASK_REG(cpu));
-val |=  (1 << cpu);
-MV_REG_WRITE(CPU_CF_LOCAL_MASK_REG(cpu), val);
+	u32 val;
+	val = MV_REG_READ(CPU_CF_LOCAL_MASK_REG(cpu));
+	val |=  (1 << cpu);
+	MV_REG_WRITE(CPU_CF_LOCAL_MASK_REG(cpu), val);
 
 #ifdef CONFIG_SMP
-if (cpu > 0) { /*enabled for both cpu */
-	val = MV_REG_READ(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_MP));
-	/* FIXME: assuming all 4 cpus */
-	val |= 0xf;
-	MV_REG_WRITE(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_MP), val);
-}
+	if (cpu > 0) { /*enabled for both cpu */
+		val = MV_REG_READ(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_MP));
+		/* FIXME: assuming all 4 cpus */
+		val |= 0xf;
+		MV_REG_WRITE(CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_MP), val);
+	}
 #endif
 }
 
 static void axp_mask_fabric_interrupt(int cpu)
 {
-u32 val;
-val = MV_REG_READ(CPU_CF_LOCAL_MASK_REG(cpu));
-val &=  ~(1 << cpu);
-MV_REG_WRITE(CPU_CF_LOCAL_MASK_REG(cpu), val);
+	u32 val;
+	val = MV_REG_READ(CPU_CF_LOCAL_MASK_REG(cpu));
+	val &=  ~(1 << cpu);
+	MV_REG_WRITE(CPU_CF_LOCAL_MASK_REG(cpu), val);
 
 #ifdef CONFIG_SMP
 if (cpu > 0) { /*disabled for both cpu */
@@ -73,7 +73,6 @@ if (cpu > 0) { /*disabled for both cpu */
 void axp_irq_mask(struct irq_data *d)
 {	
 	u32 irq=d->irq;
-	int i;
 	if (irq < 8){ // per CPU; treat giga as shared interrupt
 		MV_REG_WRITE(CPU_INT_SET_MASK_LOCAL_REG, irq);
 #if defined(CONFIG_PERF_EVENTS) && defined(CONFIG_HW_PERF_EVENTS)
@@ -84,8 +83,8 @@ void axp_irq_mask(struct irq_data *d)
 		}
 #endif
 	}
-else
-	MV_REG_WRITE(CPU_INT_CLEAR_ENABLE_REG, irq);
+	else
+		MV_REG_WRITE(CPU_INT_CLEAR_ENABLE_REG, irq);
 }
 
 void axp_irq_unmask(struct irq_data *d)
@@ -101,7 +100,7 @@ void axp_irq_unmask(struct irq_data *d)
 		}
 #endif
 	}else
-	MV_REG_WRITE(CPU_INT_SET_ENABLE_REG, d->irq);
+		MV_REG_WRITE(CPU_INT_SET_ENABLE_REG, d->irq);
 }
 
 void axp_irq_disable(struct irq_data *d)
@@ -121,7 +120,7 @@ void axp_irq_enable(struct irq_data *d)
 	int i;
 	MV_REG_WRITE(CPU_INT_SET_ENABLE_REG, irq);
 #if defined(CONFIG_PERF_EVENTS) && defined(CONFIG_HW_PERF_EVENTS)
-	if(irq==IRQ_AURORA_MP){
+	if(irq == IRQ_AURORA_MP){
 		for_each_online_cpu(i) {
 			axp_unmask_fabric_interrupt(i);
 		}
@@ -132,18 +131,18 @@ void axp_irq_enable(struct irq_data *d)
 #ifdef CONFIG_SMP
 int axp_set_affinity(struct irq_data *d, const struct cpumask *mask_val,bool force)
 {
-MV_U32 addr, temp;
-u32 irq=d->irq;
-addr = (CPU_INT_SOURCE_CONTROL_REG(irq));
-
-spin_lock(&irq_controller_lock);
-cpumask_copy(d->affinity, mask_val);
-d->node = cpumask_first(mask_val);
-temp = MV_REG_READ(addr);
-temp &= ~0xf;
-temp |= *cpus_addr(*mask_val);
-MV_REG_WRITE(addr, temp);
-spin_unlock(&irq_controller_lock);
+	MV_U32 addr, temp;
+	u32 irq=d->irq;
+	addr = (CPU_INT_SOURCE_CONTROL_REG(irq));
+
+	spin_lock(&irq_controller_lock);
+	cpumask_copy(d->affinity, mask_val);
+	d->node = cpumask_first(mask_val);
+	temp = MV_REG_READ(addr);
+	temp &= ~0xf;
+	temp |= *cpus_addr(*mask_val);
+	MV_REG_WRITE(addr, temp);
+	spin_unlock(&irq_controller_lock);
 
 return 0;
 }
@@ -153,47 +152,44 @@ return 0;
 void axp_irq_mask(struct irq_data *d)
 {	
 	int i;
-u32 irq = d->irq;
-MV_U32 addr, temp, gpio_indx;
-if ((irq >= IRQ_AURORA_GPIO_START) && (irq < IRQ_AURORA_MSI_START)) {
-	/* GPIO Interrupts */
-	/* calculate index in main interrupt */
-	gpio_indx = IRQ_AURORA_GPIO_0_7 + ((irq - IRQ_AURORA_GPIO_START) >> 3);
-	/* add 1 because there is a gap between IRQ_AURORA_GPIO_24_31
-	   and IRQ_AURORA_GPIO_32_39 */
-	if (gpio_indx > IRQ_AURORA_GPIO_24_31)
-		gpio_indx++;
-	addr = (CPU_INT_SOURCE_CONTROL_REG(gpio_indx));
-} else if (irq >= IRQ_AURORA_MSI_START) {
-	/* Per CPU MSI Interrupts */
-	if ((irq - IRQ_AURORA_MSI_START) < NR_PRIVATE_MSI_GROUP)
-		addr = CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_IN_DRBL_LOW);
-	else
-		addr = CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_IN_DRBL_HIGH);
-} else
-	addr = CPU_INT_SOURCE_CONTROL_REG(irq);
-
+	u32 irq = d->irq;
+	MV_U32 addr, temp, gpio_indx;
+	if ((irq >= IRQ_AURORA_GPIO_START) && (irq < IRQ_AURORA_MSI_START)) {
+		/* GPIO Interrupts */
+		/* calculate index in main interrupt */
+		gpio_indx = IRQ_AURORA_GPIO_0_7 + ((irq - IRQ_AURORA_GPIO_START) >> 3);
+		/* add 1 because there is a gap between IRQ_AURORA_GPIO_24_31
+		   and IRQ_AURORA_GPIO_32_39 */
+		if (gpio_indx > IRQ_AURORA_GPIO_24_31)
+			gpio_indx++;
+		addr = (CPU_INT_SOURCE_CONTROL_REG(gpio_indx));
+	} else if (irq >= IRQ_AURORA_MSI_START) {
+		/* Per CPU MSI Interrupts */
+		if ((irq - IRQ_AURORA_MSI_START) < NR_PRIVATE_MSI_GROUP)
+			addr = CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_IN_DRBL_LOW);
+		else
+			addr = CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_IN_DRBL_HIGH);
+	} else
+		addr = CPU_INT_SOURCE_CONTROL_REG(irq);
 #ifdef CONFIG_MV_AMP_ENABLE
-       mvSemaLock(MV_SEMA_IRQ);
+	 mvSemaLock(MV_SEMA_IRQ);
 #else
 	spin_lock(&irq_controller_lock);
 #endif
+	temp = MV_REG_READ(addr);
+	if ((irq >= IRQ_AURORA_GPIO_START) && (irq < IRQ_AURORA_MSI_START)) {
+		MV_U32 bitmask = 1 << (irq & (32-1));
+		MV_U32 reg = (irq - IRQ_AURORA_GPIO_START) >> 5;
+		MV_REG_BIT_RESET(GPP_INT_LVL_REG(reg), bitmask);
+	}
 
-temp = MV_REG_READ(addr);
-
-if ((irq >= IRQ_AURORA_GPIO_START) && (irq < IRQ_AURORA_MSI_START)) {
-	MV_U32 bitmask = 1 << (irq & (32-1));
-	MV_U32 reg = (irq - IRQ_AURORA_GPIO_START) >> 5;
-	MV_REG_BIT_RESET(GPP_INT_LVL_REG(reg), bitmask);
-}
-
-if (irq <= max_per_cpu_irq) // per CPU
-	temp &= ~(1 << hard_smp_processor_id());
-/* for GPIO IRQs , don't disable INTS , they will be disabled in the units mask */
-else if (irq < IRQ_MAIN_INTS_NUM)
-	temp &= ~0xf;
+	if (irq <= max_per_cpu_irq) // per CPU
+		temp &= ~(1 << hard_smp_processor_id());
+	/* for GPIO IRQs , don't disable INTS , they will be disabled in the units mask */
+	else if (irq < IRQ_MAIN_INTS_NUM)
+		temp &= ~0xf;
 
-MV_REG_WRITE(addr, temp);
+	MV_REG_WRITE(addr, temp);
 #if defined(CONFIG_PERF_EVENTS) && defined(CONFIG_HW_PERF_EVENTS)
 	 if(irq==IRQ_AURORA_MP){
 		for_each_online_cpu(i) {
@@ -204,53 +200,53 @@ MV_REG_WRITE(addr, temp);
 #ifdef CONFIG_MV_AMP_ENABLE
 	mvSemaUnlock(MV_SEMA_IRQ);
 #else
-spin_unlock(&irq_controller_lock);
+	spin_unlock(&irq_controller_lock);
 #endif
 }
 
 void axp_irq_unmask(struct irq_data *d)
 {	
-u32 irq=d->irq;
-MV_U32 addr, temp, gpio_indx;
-unsigned int map = 0x1;
-if ((irq >= IRQ_AURORA_GPIO_START) && (irq < IRQ_AURORA_MSI_START)) {
-	/* GPIO Interrupts */
-	/* calculate index in main interrupt */
-	gpio_indx = IRQ_AURORA_GPIO_0_7 + ((irq - IRQ_AURORA_GPIO_START) >> 3);
-	/* add 1 because there is a gap between IRQ_AURORA_GPIO_24_31
-	   and IRQ_AURORA_GPIO_32_39 */
-	if (gpio_indx > IRQ_AURORA_GPIO_24_31)
-		gpio_indx++;
-	addr = (CPU_INT_SOURCE_CONTROL_REG(gpio_indx));
-} else if (irq >= IRQ_AURORA_MSI_START) {
-	/* Per CPU MSI Interrupts */
-	if ((irq - IRQ_AURORA_MSI_START) < NR_PRIVATE_MSI_GROUP)
-		addr = CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_IN_DRBL_LOW);
-	else
-		addr = CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_IN_DRBL_HIGH);
-} else
-	addr = CPU_INT_SOURCE_CONTROL_REG(irq);
+	u32 irq=d->irq;
+	MV_U32 addr, temp, gpio_indx;
+	unsigned int map = 0x1;
+	if ((irq >= IRQ_AURORA_GPIO_START) && (irq < IRQ_AURORA_MSI_START)) {
+		/* GPIO Interrupts */
+		/* calculate index in main interrupt */
+		gpio_indx = IRQ_AURORA_GPIO_0_7 + ((irq - IRQ_AURORA_GPIO_START) >> 3);
+		/* add 1 because there is a gap between IRQ_AURORA_GPIO_24_31
+		   and IRQ_AURORA_GPIO_32_39 */
+		if (gpio_indx > IRQ_AURORA_GPIO_24_31)
+			gpio_indx++;
+		addr = (CPU_INT_SOURCE_CONTROL_REG(gpio_indx));
+	} else if (irq >= IRQ_AURORA_MSI_START) {
+		/* Per CPU MSI Interrupts */
+		if ((irq - IRQ_AURORA_MSI_START) < NR_PRIVATE_MSI_GROUP)
+			addr = CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_IN_DRBL_LOW);
+		else
+			addr = CPU_INT_SOURCE_CONTROL_REG(IRQ_AURORA_IN_DRBL_HIGH);
+	} else
+		addr = CPU_INT_SOURCE_CONTROL_REG(irq);
 #ifdef CONFIG_MV_AMP_ENABLE
 	mvSemaLock(MV_SEMA_IRQ);
 #else
 	spin_lock(&irq_controller_lock);
 #endif
-temp = MV_REG_READ(addr);
+	temp = MV_REG_READ(addr);
 
-if (irq >= IRQ_AURORA_GPIO_START) {
-	MV_U32 bitmask = 1 << (irq & (32-1));
-	MV_U32 reg = (irq - IRQ_AURORA_GPIO_START) >> 5;
-	MV_REG_BIT_SET(GPP_INT_LVL_REG(reg), bitmask);
-}
+	if (irq >= IRQ_AURORA_GPIO_START) {
+		MV_U32 bitmask = 1 << (irq & (32-1));
+		MV_U32 reg = (irq - IRQ_AURORA_GPIO_START) >> 5;
+		MV_REG_BIT_SET(GPP_INT_LVL_REG(reg), bitmask);
+	}
 #ifdef CONFIG_SMP
 	else{
 		map = get_hw_cpu_mask(*cpus_addr(*(d->affinity)));
        }
 #endif
 //temp &= ~0xf;
-temp |= map;
-temp |= (0x1 << 28); /* Set IntEn for this source */
-MV_REG_WRITE(addr, temp);
+	temp |= map;
+	temp |= (0x1 << 28); /* Set IntEn for this source */
+	MV_REG_WRITE(addr, temp);
 #ifdef CONFIG_MV_AMP_ENABLE
 	mvSemaUnlock(MV_SEMA_IRQ);
 #else
@@ -262,12 +258,12 @@ MV_REG_WRITE(addr, temp);
 #ifdef CONFIG_SMP
 int axp_set_affinity(struct irq_data *d, const struct cpumask *mask_val,bool force)
 {
-cpumask_copy((*d).affinity, mask_val);
-spin_lock(&irq_controller_lock);
-(*d).node = cpumask_first(mask_val);
-spin_unlock(&irq_controller_lock);
-axp_irq_unmask(d);
-return 0;
+	cpumask_copy((*d).affinity, mask_val);
+	spin_lock(&irq_controller_lock);
+	(*d).node = cpumask_first(mask_val);
+	spin_unlock(&irq_controller_lock);
+	axp_irq_unmask(d);
+	return 0;
 }
 #endif
 #endif /* CONFIG_ARMADAXP_USE_IRQ_INDIRECT_MODE */
@@ -275,69 +271,67 @@ return 0;
 #ifdef CONFIG_SMP
 void second_cpu_init(void)
 {
+	struct irq_data *d = irq_get_irq_data(IRQ_AURORA_IN_DRBL_LOW);
+	unsigned long temp;
+	/* open IPI mask */
+	temp = MV_REG_READ(AXP_IN_DRBEL_MSK) | 0xff;
+	MV_REG_WRITE(AXP_IN_DRBEL_MSK, temp);
 
-struct irq_data *d = irq_get_irq_data(IRQ_AURORA_IN_DRBL_LOW);
-unsigned long temp;
-/* open IPI mask */
-temp = MV_REG_READ(AXP_IN_DRBEL_MSK) | 0xff;
-MV_REG_WRITE(AXP_IN_DRBEL_MSK, temp);
-
-axp_irq_unmask(d);
+	axp_irq_unmask(d);
 }
 #endif
 
 static struct irq_chip axp_irq_chip = {
-.name		= "axp_irq",
-.irq_mask		= axp_irq_mask,
-.irq_mask_ack	= axp_irq_mask,
-.irq_unmask		= axp_irq_unmask,
+	.name		= "axp_irq",
+	.irq_mask	= axp_irq_mask,
+	.irq_mask_ack	= axp_irq_mask,
+	.irq_unmask	= axp_irq_unmask,
 #ifdef CONFIG_ARMADAXP_USE_IRQ_INDIRECT_MODE
-.irq_disable	= axp_irq_disable,
-.irq_enable		= axp_irq_enable,
+	.irq_disable	= axp_irq_disable,
+	.irq_enable	= axp_irq_enable,
 #else
-.irq_disable	= axp_irq_mask,
-.irq_enable		= axp_irq_unmask,
+	.irq_disable	= axp_irq_mask,
+	.irq_enable	= axp_irq_unmask,
 #endif
 #ifdef CONFIG_SMP
-.irq_set_affinity   = axp_set_affinity,
+	.irq_set_affinity   = axp_set_affinity,
 #endif
 };
 
 
 void __init axp_init_irq(void)
 {
-u32 irq;
-
-/* MASK all interrupts */
-/* Enable IRQ in control register */
-for (irq = 0; irq < IRQ_MAIN_INTS_NUM; irq++) {
-	axp_irq_mask(irq_get_irq_data(irq));
+	u32 irq;
+	/* MASK all interrupts */
+	/* Enable IRQ in control register */
+	for (irq = 0; irq < IRQ_MAIN_INTS_NUM; irq++) {
+		axp_irq_mask(irq_get_irq_data(irq));
 #ifndef CONFIG_SMP
 #ifdef CONFIG_ARMADAXP_USE_IRQ_INDIRECT_MODE
-	MV_REG_WRITE(CPU_INT_CLEAR_MASK_LOCAL_REG, irq);
+		MV_REG_WRITE(CPU_INT_CLEAR_MASK_LOCAL_REG, irq);
 #endif
 #endif
 
-}
+	}
 /*
  * Register IRQ sources
  */
-for (irq = 0; irq < IRQ_AURORA_MSI_START ; irq++) {
-	irq_set_chip(irq, &axp_irq_chip);
-	irq_set_chip_data(irq, 0);
-	irq_set_handler(irq, handle_level_irq);
-	irq_set_status_flags(irq,IRQ_LEVEL);
+	for (irq = 0; irq < IRQ_AURORA_MSI_START ; irq++) {
+		irq_set_chip(irq, &axp_irq_chip);
+		irq_set_chip_data(irq, 0);
+		irq_set_handler(irq, handle_level_irq);
+		irq_set_status_flags(irq,IRQ_LEVEL);
 #ifdef CONFIG_SMP
-	/*Warninig  - Seif Mazreeb, in Linux 3.2 you must declare that an
-	interrupt is a percpu .....without doing this timer interrupt won't happen.
-	If we declare network interrupt in the same way ( which I think we should),
-	we crash duing boot, keep this for timers for now.
-	This is a  TODO at a second stage, evalute perfrmance and fix as needed
-	*/
-	if( irq < MAX_PER_CPU_IRQ_NUMBER && irq != IRQ_AURORA_MP) {
-			irq_set_chip_and_handler(irq, &axp_irq_chip,
-						 handle_percpu_devid_irq);
-			irq_set_percpu_devid(irq);
+		/*Warninig  - Seif Mazreeb, in Linux 3.2 you must declare that an
+		interrupt is a percpu .....without doing this timer interrupt won't happen.
+		If we declare network interrupt in the same way ( which I think we should),
+		we crash duing boot, keep this for timers for now.
+		This is a  TODO at a second stage, evalute perfrmance and fix as needed
+		*/
+		if( irq < MAX_PER_CPU_IRQ_NUMBER && irq != IRQ_AURORA_MP) {
+				irq_set_chip_and_handler(irq, &axp_irq_chip,
+							 handle_percpu_devid_irq);
+				irq_set_percpu_devid(irq);
 		}
 #endif
 		set_irq_flags(irq, IRQF_VALID);
-- 
1.7.9.5

