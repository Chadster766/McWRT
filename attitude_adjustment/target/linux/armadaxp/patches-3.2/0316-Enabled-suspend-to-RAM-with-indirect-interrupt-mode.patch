From 5113b788027071a4f7f69c5ad11a7f8b0f9f8892 Mon Sep 17 00:00:00 2001
From: Yehuda Yitschak <yehuday@marvell.com>
Date: Thu, 11 Oct 2012 08:44:00 +0200
Subject: [PATCH 316/609] Enabled suspend to RAM with indirect interrupt mode

	1. Removed irq_enable and irq_disable hooks
	2. Modified irq_unamsk to always turn global
	   enable bit on (bit 28)
	3. Modified unmask and mask to handle per cpu
	   and global interrupts equaly (as in mainline)
	4. Cleaned warnings

Signed-off-by: Yehuda Yitschak <yehuday@marvell.com>
Signed-off-by: Seif Mazareeb <seif@marvell.com>
---
 arch/arm/mach-armadaxp/irq.c |   66 +++++++++---------------------------------
 1 file changed, 14 insertions(+), 52 deletions(-)

diff --git a/arch/arm/mach-armadaxp/irq.c b/arch/arm/mach-armadaxp/irq.c
index ee2597f..e914ba0 100644
--- a/arch/arm/mach-armadaxp/irq.c
+++ b/arch/arm/mach-armadaxp/irq.c
@@ -35,6 +35,7 @@ return 1;
 
 __setup("per_cpu_irq_enable", per_cpu_irq_setup);
 
+#if (defined(CONFIG_PERF_EVENTS) && defined(CONFIG_HW_PERF_EVENTS)) || defined(CONFIG_ERROR_HANDLING)
 static void axp_unmask_fabric_interrupt(int cpu)
 {
 	u32 val;
@@ -68,62 +69,31 @@ if (cpu > 0) { /*disabled for both cpu */
 }
 #endif	
 }
+#endif /* (CONFIG_PERF_EVENTS && CONFIG_HW_PERF_EVENTS) || CONFIG_ERROR_HANDLING */
 
 #ifdef CONFIG_ARMADAXP_USE_IRQ_INDIRECT_MODE
 void axp_irq_mask(struct irq_data *d)
 {	
-	int i;
-	u32 irq=d->irq;
-	if (irq < 8){ // per CPU; treat giga as shared interrupt
-		MV_REG_WRITE(CPU_INT_SET_MASK_LOCAL_REG, irq);
+	MV_REG_WRITE(CPU_INT_SET_MASK_LOCAL_REG, d->irq);
 #if (defined(CONFIG_PERF_EVENTS) && defined(CONFIG_HW_PERF_EVENTS)) || defined(CONFIG_ERROR_HANDLING)
-		if(irq==IRQ_AURORA_MP){
-			for_each_online_cpu(i) {
-                        axp_mask_fabric_interrupt(i);
-			}
+	int cpu;
+	if(d->irq == IRQ_AURORA_MP){
+		for_each_online_cpu(cpu) {
+			axp_mask_fabric_interrupt(cpu);
 		}
-#endif
 	}
-	else
-		MV_REG_WRITE(CPU_INT_CLEAR_ENABLE_REG, irq);
-}
-
-void axp_irq_unmask(struct irq_data *d)
-{	
-	int i;
-	if (d->irq < 8){ // per CPU
-		MV_REG_WRITE(CPU_INT_CLEAR_MASK_LOCAL_REG, d->irq);
-#if (defined(CONFIG_PERF_EVENTS) && defined(CONFIG_HW_PERF_EVENTS)) || defined(CONFIG_ERROR_HANDLING)
-		if(d->irq==IRQ_AURORA_MP){
-			for_each_online_cpu(i) {
-				axp_unmask_fabric_interrupt(i);
-			}
-		}
 #endif
-	}else
-		MV_REG_WRITE(CPU_INT_SET_ENABLE_REG, d->irq);
-}
-
-void axp_irq_disable(struct irq_data *d)
-{	
-	int i;
-	u32 irq=d->irq;
-	MV_REG_WRITE(CPU_INT_CLEAR_ENABLE_REG, irq);
-	for_each_online_cpu(i) {
-                axp_mask_fabric_interrupt(i);
-        }
-
 }
 
-void axp_irq_enable(struct irq_data *d)
+void axp_irq_unmask(struct irq_data *d)
 {	
-	u32 irq=d->irq;
-	int i;
-	MV_REG_WRITE(CPU_INT_SET_ENABLE_REG, irq);
+	MV_REG_WRITE(CPU_INT_CLEAR_MASK_LOCAL_REG, d->irq);
+	MV_REG_WRITE(CPU_INT_SET_ENABLE_REG, d->irq);
 #if (defined(CONFIG_PERF_EVENTS) && defined(CONFIG_HW_PERF_EVENTS)) || defined(CONFIG_ERROR_HANDLING)
-	if(irq == IRQ_AURORA_MP){
-		for_each_online_cpu(i) {
-			axp_unmask_fabric_interrupt(i);
+	int cpu;
+	if(d->irq == IRQ_AURORA_MP){
+		for_each_online_cpu(cpu) {
+			axp_unmask_fabric_interrupt(cpu);
 		}
 	}
 #endif
@@ -287,13 +257,6 @@ static struct irq_chip axp_irq_chip = {
 	.irq_mask	= axp_irq_mask,
 	.irq_mask_ack	= axp_irq_mask,
 	.irq_unmask	= axp_irq_unmask,
-#ifdef CONFIG_ARMADAXP_USE_IRQ_INDIRECT_MODE
-	.irq_disable	= axp_irq_disable,
-	.irq_enable	= axp_irq_enable,
-#else
-	.irq_disable	= axp_irq_mask,
-	.irq_enable	= axp_irq_unmask,
-#endif
 #ifdef CONFIG_SMP
 	.irq_set_affinity   = axp_set_affinity,
 #endif
@@ -312,7 +275,6 @@ void __init axp_init_irq(void)
 		MV_REG_WRITE(CPU_INT_CLEAR_MASK_LOCAL_REG, irq);
 #endif
 #endif
-
 	}
 /*
  * Register IRQ sources
-- 
1.7.9.5

