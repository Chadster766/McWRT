From 9558b4ab63ab7b7bfc14c9b794588fe17aa86c18 Mon Sep 17 00:00:00 2001
From: Dmitri Epshtein <dima@marvell.com>
Date: Mon, 12 Mar 2012 04:28:59 -0400
Subject: [PATCH 151/609] OSS: fix multi-line operations align address and
 size from KW2

Signed-off-by: Seif Mazareeb <seif@marvell.com>
---
 arch/arm/plat-armada/linux_oss/mvOs.h |   30 +++++++++++++++++++++++++++++-
 1 file changed, 29 insertions(+), 1 deletion(-)

diff --git a/arch/arm/plat-armada/linux_oss/mvOs.h b/arch/arm/plat-armada/linux_oss/mvOs.h
index 46c7ac1..f61b516 100755
--- a/arch/arm/plat-armada/linux_oss/mvOs.h
+++ b/arch/arm/plat-armada/linux_oss/mvOs.h
@@ -380,13 +380,22 @@ static inline void mvOsBridgeReorderWA(void)
 	__asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 1" : : "r" (addr));\
 #endif
 	__asm__ __volatile__ ("mcr p15, 0, %0, c7, c10, 4" : : "r" (addr)); \
- }
+}
 #endif
 
 #define MV_OS_CACHE_MULTI_THRESH	256
+
+/* Flush multiple cache lines using mvOsCacheLineFlush to improve performance.              */
+/* addr is the pointer to start the flush operation from. It will be aligned to             */
+/* the beginning of the cache line automatically and the size will be adjusted accordingly. */
 static inline void mvOsCacheMultiLineFlush(void *handle, void *addr, int size)
 {
 	if (size <= MV_OS_CACHE_MULTI_THRESH) {
+		int shift = ((MV_ULONG)(addr) & (CPU_D_CACHE_LINE_SIZE - 1));
+		if (shift) {
+			addr -= shift; /* align address back to the beginning of a cache line */
+			size += shift;
+		}
 #if defined(CONFIG_CACHE_AURORA_L2)
 		DSBWA_4611(addr);
 		while (size > 0) {
@@ -412,9 +421,20 @@ static inline void mvOsCacheMultiLineFlush(void *handle, void *addr, int size)
 		pci_map_single(handle, addr, size, PCI_DMA_TODEVICE);
 }
 
+/* Invalidate multiple cache lines using mvOsCacheLineInv to improve performance.           */
+/* addr is the pointer to start the invalidate operation from. It will be aligned to        */
+/* the beginning of the cache line automatically and the size will be adjusted accordingly. */
+/* IMPORTANT: this function assumes the invalidate operation on partial lines does not      */
+/* interfere with the data written there.                                                   */
+/* DO NOT USE this function unless you are certain of this!                                 */
 static inline void mvOsCacheMultiLineInv(void *handle, void *addr, int size)
 {
 	if (size <= MV_OS_CACHE_MULTI_THRESH) {
+		int shift = ((MV_ULONG)(addr) & (CPU_D_CACHE_LINE_SIZE - 1));
+		if (shift) {
+			addr -= shift; /* align address back to the beginning of a cache line */
+			size += shift;
+		}
 #if defined(CONFIG_CACHE_AURORA_L2)
 		DSBWA_4413(addr);
 		while (size > 0) {
@@ -436,9 +456,17 @@ static inline void mvOsCacheMultiLineInv(void *handle, void *addr, int size)
 		pci_map_single(handle, addr, size, PCI_DMA_FROMDEVICE);
 }
 
+/* Flush and invalidate multiple cache lines using mvOsCacheLineFlushInv to improve performance. */
+/* addr is the pointer to start the flush and invalidate operation from. It will be aligned to   */
+/* the beginning of the cache line automatically and the size will be adjusted accordingly.      */
 static inline void mvOsCacheMultiLineFlushInv(void *handle, void *addr, int size)
 {
 	if (size <= MV_OS_CACHE_MULTI_THRESH) {
+		int shift = ((MV_ULONG)(addr) & (CPU_D_CACHE_LINE_SIZE - 1));
+		if (shift) {
+			addr -= shift; /* align address back to the beginning of a cache line */
+			size += shift;
+		}
 #if defined(CONFIG_CACHE_AURORA_L2)
 		DSBWA_4611(addr);
 		while (size > 0) {
-- 
1.7.9.5

