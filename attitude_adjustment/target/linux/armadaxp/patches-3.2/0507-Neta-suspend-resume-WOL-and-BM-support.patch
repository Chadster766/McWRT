From d7d09f3df72de62fb29905a30c4211bca2e87734 Mon Sep 17 00:00:00 2001
From: Uri Eliyahu <uriel@marvell.com>
Date: Wed, 16 Jan 2013 18:58:55 +0200
Subject: [PATCH 507/609] Neta suspend resume WOL and BM support

Change-Id: I3e49ab877e1f77226afffd19aa5796682b236e37
Signed-off-by: Uri Eliyahu <uriel@marvell.com>
Reviewed-on: http://vgitil04.il.marvell.com:8080/958
Reviewed-by: Tawfik Bayouk <tawfik@marvell.com>
Tested-by: Tawfik Bayouk <tawfik@marvell.com>
Signed-off-by: Seif Mazareeb <seif@marvell.com>
---
 .../mv_drivers_lsp/mv_neta/net_dev/mv_eth_sysfs.c  |   18 +-
 .../mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c     |  681 +++++++++++---------
 .../mv_drivers_lsp/mv_neta/net_dev/mv_netdev.h     |   30 +-
 arch/arm/plat-armada/mv_hal/neta/bm/mvBm.c         |   19 +-
 arch/arm/plat-armada/mv_hal/neta/bm/mvBm.h         |    1 +
 5 files changed, 433 insertions(+), 316 deletions(-)

diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_sysfs.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_sysfs.c
index 147e484..5584bb0 100644
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_sysfs.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_eth_sysfs.c
@@ -97,7 +97,9 @@ static ssize_t mv_eth_help(char *buf)
 	off += sprintf(buf+off, "echo p d           > rx_weight     - set weight for the poll function; <d> - new weight, max val: 255\n");
 	off += sprintf(buf+off, "echo p cpu mask    > txq_mask      - set cpu <cpu> accessible txq bitmap <mask>.\n");
 	off += sprintf(buf+off, "echo p txp txq d   > txq_shared    - set/reset shared bit for <port/txp/txq>. <d> - 1/0 for set/reset.\n");
-	off += sprintf(buf+off, "echo p {0|1|2}     > pm_mode       - set port <p> pm mode. 0 wol, 1 clock, 2 disabled.\n");
+#ifdef CONFIG_MV_ETH_PNC_WOL
+	off += sprintf(buf+off, "echo p wol         > wol_mode      - set port <p> pm mode. 0 wol, 1 suspend.\n");
+#endif
 	return off;
 }
 
@@ -234,8 +236,6 @@ static ssize_t mv_eth_port_store(struct device *dev,
 		printk(KERN_INFO "\n");
 		mvEthPortRegs(p);
 		mvNetaPortRegs(p);
-	} else if (!strcmp(name, "pm_mode")) {
-		err = mv_eth_pm_mode_set(p, v);
 #ifdef MV_ETH_GMAC_NEW
 	} else if (!strcmp(name, "gmac_regs")) {
 		mvNetaGmacRegs(p);
@@ -244,6 +244,10 @@ static ssize_t mv_eth_port_store(struct device *dev,
 	} else if (!strcmp(name, "pnc")) {
 		mv_eth_ctrl_pnc(p);
 #endif /* CONFIG_MV_ETH_PNC */
+#ifdef CONFIG_MV_ETH_PNC_WOL
+	} else if (!strcmp(name, "wol_mode")) {
+		err = mv_eth_wol_mode_set(p, v);
+#endif /* CONFIG_MV_ETH_PNC_WOL */
 	} else if (!strcmp(name, "napi")) {
 		mv_eth_napi_group_show(p);
 	} else {
@@ -485,12 +489,14 @@ static DEVICE_ATTR(tx_done,     S_IWUSR, mv_eth_show, mv_eth_3_store);
 #ifdef CONFIG_MV_ETH_PNC
 static DEVICE_ATTR(pnc,         S_IWUSR, NULL, mv_eth_port_store);
 #endif /* CONFIG_MV_ETH_PNC */
+#ifdef CONFIG_MV_ETH_PNC_WOL
+static DEVICE_ATTR(wol_mode,	S_IWUSR, mv_eth_show, mv_eth_port_store);
+#endif /* CONFIG_MV_ETH_PNC_WOL */
 static DEVICE_ATTR(cpu_group,   S_IWUSR, mv_eth_show, mv_eth_3_hex_store);
 static DEVICE_ATTR(rxq_group,   S_IWUSR, mv_eth_show, mv_eth_3_hex_store);
 static DEVICE_ATTR(napi,        S_IWUSR, mv_eth_show, mv_eth_port_store);
 static DEVICE_ATTR(txq_mask,    S_IWUSR, mv_eth_show, mv_eth_3_hex_store);
 static DEVICE_ATTR(txq_shared,  S_IWUSR, mv_eth_show, mv_eth_4_store);
-static DEVICE_ATTR(pm_mode,	S_IWUSR, mv_eth_show, mv_eth_port_store);
 
 static struct attribute *mv_eth_attrs[] = {
 
@@ -541,12 +547,14 @@ static struct attribute *mv_eth_attrs[] = {
 #ifdef CONFIG_MV_ETH_PNC
     &dev_attr_pnc.attr,
 #endif /* CONFIG_MV_ETH_PNC */
+#ifdef CONFIG_MV_ETH_PNC_WOL
+	&dev_attr_wol_mode.attr,
+#endif
 	&dev_attr_cpu_group.attr,
 	&dev_attr_rxq_group.attr,
 	&dev_attr_napi.attr,
 	&dev_attr_txq_mask.attr,
 	&dev_attr_txq_shared.attr,
-	&dev_attr_pm_mode.attr,
 	NULL
 };
 
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c
index 994a35e..579bc12 100755
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.c
@@ -78,14 +78,16 @@ static inline int mv_eth_tx_policy(struct eth_port *pp, struct sk_buff *skb);
 /* uncomment if you want to debug the SKB recycle feature */
 /* #define ETH_SKB_DEBUG */
 
+static int pm_flag = 0;
+static int wol_ports_bmp = 0;
+
 #ifdef CONFIG_MV_ETH_PNC
 unsigned int mv_eth_pnc_ctrl_en = 1;
-static int pnc_resume_flag = 0;
 
 int mv_eth_ctrl_pnc(int en)
 {
 	mv_eth_pnc_ctrl_en = en;
-	return 0;
+	return MV_OK;
 }
 #endif /* CONFIG_MV_ETH_PNC */
 
@@ -96,7 +98,7 @@ EXPORT_SYMBOL(mv_ctrl_recycle);
 int mv_eth_ctrl_recycle(int en)
 {
 	mv_ctrl_recycle = en;
-	return 0;
+	return MV_OK;
 }
 #else
 int mv_eth_ctrl_recycle(int en)
@@ -134,6 +136,7 @@ static void mv_eth_txq_delete(struct eth_port *pp, struct tx_queue *txq_ctrl);
 static void mv_eth_tx_timeout(struct net_device *dev);
 static int  mv_eth_tx(struct sk_buff *skb, struct net_device *dev);
 static void mv_eth_tx_frag_process(struct eth_port *pp, struct sk_buff *skb, struct tx_queue *txq_ctrl, u16 flags);
+static int mv_eth_rxq_fill(struct eth_port *pp, int rxq, int num);
 
 static void mv_eth_config_show(void);
 static int  mv_eth_priv_init(struct eth_port *pp, int port);
@@ -246,7 +249,7 @@ int group_has_cpus(struct eth_port *pp, int group)
 	}
 
 	/* the group contains no CPU */
-	return 0;
+	return MV_OK;
 }
 
 void set_rxq_affinity(struct eth_port *pp, MV_U32 rxqAffinity, int group)
@@ -308,7 +311,7 @@ static int mv_eth_port_config_parse(struct eth_port *pp)
 	printk(KERN_ERR "\n");
 	if (pp == NULL) {
 		printk(KERN_ERR "  o mv_eth_port_config_parse: got NULL pp\n");
-		return -1;
+		return MV_ERROR;
 	}
 
 	switch (pp->port) {
@@ -326,20 +329,20 @@ static int mv_eth_port_config_parse(struct eth_port *pp)
 		break;
 	default:
 		printk(KERN_ERR "  o mv_eth_port_config_parse: got unknown port %d\n", pp->port);
-		return -1;
+		return MV_ERROR;
 	}
 
 	if (str != NULL) {
 		if ((!strcmp(str, "disconnected")) || (!strcmp(str, "Disconnected"))) {
 			printk(KERN_ERR "  o Port %d is disconnected from Linux netdevice\n", pp->port);
 			clear_bit(MV_ETH_F_CONNECT_LINUX_BIT, &(pp->flags));
-			return 0;
+			return MV_OK;
 		}
 	}
 
 	printk(KERN_ERR "  o Port %d is connected to Linux netdevice\n", pp->port);
 	set_bit(MV_ETH_F_CONNECT_LINUX_BIT, &(pp->flags));
-	return 0;
+	return MV_OK;
 }
 
 #ifdef ETH_SKB_DEBUG
@@ -431,7 +434,7 @@ static inline int mv_eth_skb_mh_add(struct sk_buff *skb, u16 mh)
 	skb->data -= MV_ETH_MH_SIZE;
 	*((u16 *) skb->data) = mh;
 
-	return 0;
+	return MV_OK;
 }
 
 void mv_eth_ctrl_txdone(int num)
@@ -460,7 +463,7 @@ int mv_eth_ctrl_flag(int port, u32 flag, u32 val)
 	if (flag == MV_ETH_F_MH)
 		mvNetaMhSet(pp->port, val ? MV_NETA_MH : MV_NETA_MH_NONE);
 
-	return 0;
+	return MV_OK;
 }
 
 int mv_eth_ctrl_port_buf_num_set(int port, int long_num, int short_num)
@@ -496,7 +499,7 @@ int mv_eth_ctrl_port_buf_num_set(int port, int long_num, int short_num)
 	pp->pool_short_num = short_num;
 #endif /* CONFIG_MV_ETH_BM_CPU */
 
-	return 0;
+	return MV_OK;
 }
 
 #ifdef CONFIG_MV_ETH_BM
@@ -553,7 +556,7 @@ int mv_eth_ctrl_pool_size_set(int pool, int pkt_size)
 	else
 		mvBmPoolBufSizeSet(pool, RX_BUF_SIZE(pkt_size));
 
-	return 0;
+	return MV_OK;
 }
 #endif /* CONFIG_MV_ETH_BM */
 
@@ -583,7 +586,7 @@ int mv_eth_ctrl_set_poll_rx_weight(int port, u32 weight)
 			cpuCtrl->napi->weight = pp->weight;
 	}
 
-	return 0;
+	return MV_OK;
 }
 
 int mv_eth_ctrl_rxq_size_set(int port, int rxq, int value)
@@ -611,7 +614,7 @@ int mv_eth_ctrl_rxq_size_set(int port, int rxq, int value)
 	pp->rxq_ctrl[rxq].rxq_size = value;
 
 	/* New RXQ will be created during mv_eth_start_internals */
-	return 0;
+	return MV_OK;
 }
 
 int mv_eth_ctrl_txq_size_set(int port, int txp, int txq, int value)
@@ -637,7 +640,7 @@ int mv_eth_ctrl_txq_size_set(int port, int txp, int txq, int value)
 	txq_ctrl->txq_size = value;
 
 	/* New TXQ will be created during mv_eth_start_internals */
-	return 0;
+	return MV_OK;
 }
 
 int mv_eth_ctrl_txq_mode_get(int port, int txp, int txq, int *value)
@@ -694,7 +697,7 @@ int mv_eth_ctrl_txq_cpu_own(int port, int txp, int txq, int add, int cpu)
 
 	mv_eth_txq_update_shared(txq_ctrl, pp);
 
-	return 0;
+	return MV_OK;
 }
 
 /* Set TXQ ownership to HWF from the RX port.  rxp=-1 - free TXQ ownership */
@@ -722,7 +725,7 @@ int mv_eth_ctrl_txq_hwf_own(int port, int txp, int txq, int rxp)
 
 	txq_ctrl->hwf_rxp = (MV_U8) rxp;
 
-	return 0;
+	return MV_OK;
 }
 
 /* set or clear shared bit for this txq, txp=1 for pon , 0 for gbe */
@@ -797,7 +800,7 @@ int mv_eth_ctrl_txq_cpu_def(int port, int txp, int txq, int cpu)
 	pp->txp = txp;
 	cpuCtrl->txq = txq;
 
-	return 0;
+	return MV_OK;
 }
 
 
@@ -874,7 +877,7 @@ int mv_eth_ctrl_tx_cmd(int port, u32 tx_cmd)
 
 	pp->hw_cmd = tx_cmd;
 
-	return 0;
+	return MV_OK;
 }
 
 int mv_eth_ctrl_tx_mh(int port, u16 mh)
@@ -886,7 +889,7 @@ int mv_eth_ctrl_tx_mh(int port, u16 mh)
 
 	pp->tx_mh = mh;
 
-	return 0;
+	return MV_OK;
 }
 
 #ifdef CONFIG_MV_ETH_TX_SPECIAL
@@ -937,7 +940,7 @@ static int mv_eth_set_features(struct net_device *dev, u32 features)
 			mvPncLbModeL4(LB_DISABLE_VALUE);
 		}
 	}
-	return 0;
+	return MV_OK;
 }
 #endif
 
@@ -1312,7 +1315,7 @@ int mv_eth_skb_recycle(struct sk_buff *skb)
 			mv_eth_skb_save(skb, "recycle");
 #endif /* ETH_SKB_DEBUG */
 
-		return 0;
+		return MV_OK;
 	}
 	STAT_DBG(pool->stats.skb_recycled_err++);
 
@@ -1473,7 +1476,7 @@ inline int mv_eth_refill(struct eth_port *pp, int rxq,
 	}
 	mv_eth_rxq_refill(pp, rxq, pkt, pool, rx_desc);
 
-	return 0;
+	return MV_OK;
 }
 EXPORT_SYMBOL(mv_eth_refill);
 
@@ -1872,8 +1875,8 @@ static int mv_eth_tx(struct sk_buff *skb, struct net_device *dev)
 	if (pp->flags & MV_ETH_F_DBG_TX) {
 		printk(KERN_ERR "\n");
 		printk(KERN_ERR "%s - eth_tx_%lu: cpu=%d, in_intr=0x%lx, port=%d, txp=%d, txq=%d\n",
-			dev->name, dev->stats.tx_packets, smp_processor_id(), in_interrupt(),
-			pp->port, tx_spec.txp, tx_spec.txq);
+		       dev->name, dev->stats.tx_packets, smp_processor_id(),
+			in_interrupt(), pp->port, tx_spec.txp, tx_spec.txq);
 		printk(KERN_ERR "\t skb=%p, head=%p, data=%p, size=%d\n", skb, skb->head, skb->data, skb->len);
 		mv_eth_tx_desc_print(tx_desc);
 		/*mv_eth_skb_print(skb);*/
@@ -1950,7 +1953,7 @@ static inline int mv_eth_tso_validate(struct sk_buff *skb, struct net_device *de
 		printk(KERN_ERR "***** ERROR: Protocol is not TCP over IP\n");
 		return 1;
 	}
-	return 0;
+	return MV_OK;
 }
 
 static inline int mv_eth_tso_build_hdr_desc(struct neta_tx_desc *tx_desc, struct eth_port *priv, struct sk_buff *skb,
@@ -1964,7 +1967,7 @@ static inline int mv_eth_tso_build_hdr_desc(struct neta_tx_desc *tx_desc, struct
 
 	data = mv_eth_extra_pool_get(priv);
 	if (!data)
-		return 0;
+		return MV_OK;
 
 	txq_ctrl->shadow_txq[txq_ctrl->shadow_txq_put_i] = ((MV_ULONG)data | MV_ETH_SHADOW_EXT);
 
@@ -2066,7 +2069,7 @@ int mv_eth_tx_tso(struct sk_buff *skb, struct net_device *dev,
 	printk(KERN_ERR "mv_eth_tx_tso_%d ENTER: skb=%p, total_len=%d\n", priv->stats.tx_tso, skb, skb->len);
 */
 	if (mv_eth_tso_validate(skb, dev))
-		return 0;
+		return MV_OK;
 
 	/* Calculate expected number of TX descriptors */
 	totalDescNum = skb_shinfo(skb)->gso_segs * 2 + skb_shinfo(skb)->nr_frags;
@@ -2078,7 +2081,7 @@ int mv_eth_tx_tso(struct sk_buff *skb, struct net_device *dev,
 					skb_shinfo(skb)->gso_segs);
 */
 		STAT_ERR(txq_ctrl->stats.txq_err++);
-		return 0;
+		return MV_OK;
 	}
 
 	total_len = skb->len;
@@ -2093,7 +2096,7 @@ int mv_eth_tx_tso(struct sk_buff *skb, struct net_device *dev,
 
 	if (frag_size < hdr_len) {
 		printk(KERN_ERR "***** ERROR: frag_size=%d, hdr_len=%d\n", frag_size, hdr_len);
-		return 0;
+		return MV_OK;
 	}
 
 	frag_size -= hdr_len;
@@ -2196,7 +2199,7 @@ outNoTxDesc:
 		mv_eth_shadow_dec_put(txq_ctrl);
 		mvNetaTxqPrevDescGet(txq_ctrl->q);
 	}
-	return 0;
+	return MV_OK;
 }
 #endif /* CONFIG_MV_ETH_TSO */
 
@@ -2361,6 +2364,37 @@ static void mv_eth_tx_frag_process(struct eth_port *pp, struct sk_buff *skb, str
 	}
 }
 
+/***********************************************************
+ * mv_eth_port_pools_free                                  *
+ *   per port - free all the buffers from pools		   *
+ *   disable pool if empty				   *
+ ***********************************************************/
+static int mv_eth_port_pools_free(int port)
+{
+	struct eth_port *pp;
+
+	pp = mv_eth_port_by_id(port);
+	if (!pp)
+		return MV_OK;
+
+	if (pp->pool_long) {
+		mv_eth_pool_free(pp->pool_long->pool, pp->pool_long_num);
+#ifndef CONFIG_MV_ETH_BM_CPU
+	}
+#else
+		if (pp->pool_long->buf_num == 0)
+			mvBmPoolDisable(pp->pool_long->pool);
+
+		/*empty pools*/
+		if (pp->pool_short && (pp->pool_long->pool != pp->pool_short->pool)) {
+			mv_eth_pool_free(pp->pool_short->pool, pp->pool_short_num);
+			if (pp->pool_short->buf_num == 0)
+				mvBmPoolDisable(pp->pool_short->pool);
+		}
+	}
+#endif /*CONFIG_MV_ETH_BM_CPU*/
+	return MV_OK;
+}
 
 /* Free "num" buffers from the pool */
 static int mv_eth_pool_free(int pool, int num)
@@ -2485,7 +2519,7 @@ static int mv_eth_pool_add(int pool, int buf_num)
 
 	if ((pool < 0) || (pool >= MV_ETH_BM_POOLS)) {
 		printk(KERN_ERR "%s: invalid pool number %d\n", __func__, pool);
-		return 0;
+		return MV_OK;
 	}
 
 	bm_pool = &mv_eth_pool[pool];
@@ -2494,7 +2528,7 @@ static int mv_eth_pool_add(int pool, int buf_num)
 	if (bm_pool->pkt_size == 0) {
 		printk(KERN_ERR "%s: invalid pool #%d state: pkt_size=%d, buf_size=%d, buf_num=%d\n",
 		       __func__, pool, bm_pool->pkt_size, RX_BUF_SIZE(bm_pool->pkt_size), bm_pool->buf_num);
-		return 0;
+		return MV_OK;
 	}
 
 	/* Insure buf_num is smaller than capacity */
@@ -2502,7 +2536,7 @@ static int mv_eth_pool_add(int pool, int buf_num)
 
 		printk(KERN_ERR "%s: can't add %d buffers into bm_pool=%d: capacity=%d, buf_num=%d\n",
 		       __func__, buf_num, pool, bm_pool->capacity, bm_pool->buf_num);
-		return 0;
+		return MV_OK;
 	}
 
 	MV_ETH_LOCK(&bm_pool->lock, flags);
@@ -2590,6 +2624,7 @@ void	*mv_eth_bm_pool_create(int pool, int capacity, MV_ULONG *pPhysAddr)
 static MV_STATUS mv_eth_pool_create(int pool, int capacity)
 {
 	struct bm_pool *bm_pool;
+	MV_ULONG    physAddr;
 
 	if ((pool < 0) || (pool >= MV_ETH_BM_POOLS)) {
 		printk(KERN_ERR "%s: pool=%d is out of range\n", __func__, pool);
@@ -2600,7 +2635,7 @@ static MV_STATUS mv_eth_pool_create(int pool, int capacity)
 	memset(bm_pool, 0, sizeof(struct bm_pool));
 
 #ifdef CONFIG_MV_ETH_BM_CPU
-	bm_pool->bm_pool = mv_eth_bm_pool_create(pool, capacity, NULL);
+	bm_pool->bm_pool = mv_eth_bm_pool_create(pool, capacity, &physAddr/*NULL*/);
 	if (bm_pool->bm_pool == NULL)
 		return MV_FAIL;
 #endif /* CONFIG_MV_ETH_BM_CPU */
@@ -2617,6 +2652,7 @@ static MV_STATUS mv_eth_pool_create(int pool, int capacity)
 	bm_pool->capacity = capacity;
 	bm_pool->pkt_size = 0;
 	bm_pool->buf_num = 0;
+	bm_pool->physAddr = physAddr;
 	spin_lock_init(&bm_pool->lock);
 
 	return MV_OK;
@@ -2932,7 +2968,7 @@ static MV_STATUS mv_eth_bm_pools_init(void)
 		mv_eth_pool[i].pkt_size = 0;
 #endif /* CONFIG_MV_ETH_BM */
 	}
-	return 0;
+	return MV_OK;
 }
 
 /* Note: call this function only after mv_eth_ports_num is initialized */
@@ -3051,7 +3087,7 @@ static int mv_eth_load_network_interfaces(MV_U32 portMask, MV_U32 cpuMask,
 
 	mv_net_devs_num = dev_i;
 
-	return 0;
+	return MV_OK;
 }
 
 
@@ -3085,8 +3121,173 @@ int mv_eth_resume_network_interfaces(struct eth_port *pp)
 		mvNetaTxqCpuMaskSet(pp->port, pp->cpu_config[cpu]->cpuTxqMask, cpu);
 	}
 
-	return 0;
+	return MV_OK;
+}
+
+#ifdef CONFIG_MV_ETH_BM
+int     mv_eth_bm_pool_restore(struct bm_pool *bm_pool)
+{
+		MV_UNIT_WIN_INFO        winInfo;
+		MV_STATUS               status;
+		int pool = bm_pool->pool;
+
+		mvBmPoolInit(bm_pool->pool, bm_pool->bm_pool, bm_pool->physAddr, bm_pool->capacity);
+		status = mvCtrlAddrWinInfoGet(&winInfo, bm_pool->physAddr);
+
+		if (status != MV_OK) {
+			printk(KERN_ERR "%s: Can't map BM pool #%d. phys_addr=0x%x, status=%d\n",
+				__func__, bm_pool->pool, (unsigned)bm_pool->physAddr, status);
+			mvOsIoCachedFree(NULL, sizeof(MV_U32) *  bm_pool->capacity, bm_pool->physAddr, bm_pool->bm_pool, 0);
+			return MV_ERROR;
+		}
+		mvBmPoolTargetSet(pool, winInfo.targetId, winInfo.attrib);
+		mvBmPoolEnable(pool);
+
+		return MV_OK;
+}
+#endif /*CONFIG_MV_ETH_BM*/
+
+
+/* Refill port pools */
+static int mv_eth_resume_port_pools(struct eth_port *pp)
+{
+	int num;
+
+	if (!pp)
+		return -ENODEV;
+
+
+	/* fill long pool */
+	if (pp->pool_long) {
+		num = mv_eth_pool_add(pp->pool_long->pool, pp->pool_long_num);
+
+		if (num != pp->pool_long_num) {
+			printk(KERN_ERR "%s FAILED long: pool=%d, pkt_size=%d, only %d of %d allocated\n",
+			       __func__, pp->pool_long->pool, pp->pool_long->pkt_size, num, pp->pool_long_num);
+			return MV_ERROR;
+		}
+
+#ifndef CONFIG_MV_ETH_BM_CPU
+	} /*fill long pool */
+#else
+		mvNetaBmPoolBufSizeSet(pp->port, pp->pool_long->pool, RX_BUF_SIZE(pp->pool_long->pkt_size));
+	}
+
+	if (pp->pool_short) {
+		if (pp->pool_short->pool != pp->pool_long->pool) {
+				/* fill short pool */
+				num = mv_eth_pool_add(pp->pool_short->pool, pp->pool_short_num);
+				if (num != pp->pool_short_num) {
+					printk(KERN_ERR "%s FAILED short: pool=%d, pkt_size=%d - %d of %d buffers added\n",
+					   __func__, pp->pool_short->pool, pp->pool_short->pkt_size, num, pp->pool_short_num);
+					return MV_ERROR;
+				}
+
+				mvNetaBmPoolBufSizeSet(pp->port, pp->pool_short->pool, RX_BUF_SIZE(pp->pool_short->pkt_size));
+
+		} else {
+
+			int dummy_short_pool = (pp->pool_short->pool + 1) % MV_BM_POOLS;
+			/* To disable short pool we choose unused pool and set pkt size to 0 (buffer size = pkt offset) */
+			mvNetaBmPoolBufSizeSet(pp->port, dummy_short_pool, NET_SKB_PAD);
+
+		}
+	}
+
+#endif /* CONFIG_MV_ETH_BM_CPU */
+
+	return MV_OK;
+}
+
+static int mv_eth_resume_rxq_txq(struct eth_port *pp, int mtu)
+{
+	int rxq, txp, txq = 0;
+
+
+	if (mvBoardIsPortInSgmii(pp->port))
+		MV_REG_WRITE(SGMII_SERDES_CFG_REG(pp->port), pp->sgmii_serdes);
+
+	for (txp = 0; txp < pp->txp_num; txp++)
+		mvNetaTxpReset(pp->port, txp);
+
+	mvNetaRxReset(pp->port);
+
+	for (rxq = 0; rxq < CONFIG_MV_ETH_RXQ; rxq++) {
+
+		if (pp->rxq_ctrl[rxq].q) {
+			/* Set Rx descriptors queue starting address */
+			mvNetaRxqAddrSet(pp->port, rxq,  pp->rxq_ctrl[rxq].rxq_size);
+
+			/* Set Offset */
+			mvNetaRxqOffsetSet(pp->port, rxq, NET_SKB_PAD);
+
+			/* Set coalescing pkts and time */
+			mv_eth_rx_ptks_coal_set(pp->port, rxq, pp->rxq_ctrl[rxq].rxq_pkts_coal);
+			mv_eth_rx_time_coal_set(pp->port, rxq, pp->rxq_ctrl[rxq].rxq_time_coal);
+
+
+#if defined(CONFIG_MV_ETH_BM_CPU)
+			/* Enable / Disable - BM support */
+			if (pp->pool_long && pp->pool_short) {
+
+				if (pp->pool_short->pool == pp->pool_long->pool) {
+					int dummy_short_pool = (pp->pool_short->pool + 1) % MV_BM_POOLS;
+
+					/* To disable short pool we choose unused pool and set pkt size to 0 (buffer size = pkt offset) */
+					mvNetaRxqBmEnable(pp->port, rxq, dummy_short_pool, pp->pool_long->pool);
+				} else
+					mvNetaRxqBmEnable(pp->port, rxq, pp->pool_short->pool, pp->pool_long->pool);
+			}
+#else
+			/* Fill RXQ with buffers from RX pool */
+			mvNetaRxqBufSizeSet(pp->port, rxq, RX_BUF_SIZE(pp->pool_long->pkt_size));
+			mvNetaRxqBmDisable(pp->port, rxq);
+#endif /* CONFIG_MV_ETH_BM_CPU */
+			if (mvNetaRxqFreeDescNumGet(pp->port, rxq) == 0)
+				mv_eth_rxq_fill(pp, rxq, pp->rxq_ctrl[rxq].rxq_size);
+		}
+	}
+
+	for (txp = 0; txp < pp->txp_num; txp++) {
+		for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++) {
+			struct tx_queue *txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
+
+			if (txq_ctrl->q != NULL) {
+				mvNetaTxqAddrSet(pp->port, txq_ctrl->txp, txq_ctrl->txq, txq_ctrl->txq_size);
+				mv_eth_tx_done_ptks_coal_set(pp->port, txp, txq,
+							pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq].txq_done_pkts_coal);
+			}
+			mvNetaTxqBandwidthSet(pp->port, txp, txq);
+
+		}
+		mvNetaTxpMaxTxSizeSet(pp->port, txp, RX_PKT_SIZE(mtu));
+	}
+
+	return MV_OK;
+}
+
+/**********************************************************
+ * mv_eth_pnc_resume                                      *
+ **********************************************************/
+#ifdef CONFIG_MV_ETH_PNC
+static void mv_eth_pnc_resume(void)
+{
+	/* TODO - in clock standby ,DO we want to keep old pnc TCAM/SRAM entries ? */
+	if (wol_ports_bmp != 0)
+		return;
+
+	/* Not in WOL, clock standby or suspend to ram mode*/
+	tcam_hw_init();
+
+	if (pnc_default_init())
+		printk(KERN_ERR "%s: Warning PNC init failed\n", __func__);
+
+	/* TODO: load balancing resume */
+#if defined(MV_ETH_PNC_LB)
+	/*mv_eth_set_features(pp->dev, u32 features)*/
+#endif
 }
+#endif /* CONFIG_MV_ETH_PNC */
 
 /***********************************************************
  * mv_eth_port_resume                                      *
@@ -3101,28 +3302,50 @@ int mv_eth_port_resume(int port)
 
 	if (pp == NULL) {
 		printk(KERN_ERR "%s: pp == NULL, port=%d\n", __func__, port);
-		return -1;
+		return  MV_ERROR;
 	}
 
 	if (!(pp->flags & MV_ETH_F_SUSPEND)) {
 		printk(KERN_ERR "%s: port %d is not suspend.\n", __func__, port);
-		return -1;
+		return MV_ERROR;
 	}
-	mvNetaPortPowerUp(port, mvBoardIsPortInSgmii(port), mvBoardIsPortInRgmii(port));
-
+	/*13q1 TODO: mvNetaPortPowerUp(port, mvBoardIsPortInSgmii(port), mvBoardIsPortInRgmii(port));*/
+#if !defined(CONFIG_ARCH_ARMADA370)
+	mvNetaPortPowerUp(port, mvBoardIsPortInSgmii(port), !mvBoardIsPortInGmii(port));
+#endif
 	mv_eth_win_init(port);
 
 	mv_eth_resume_network_interfaces(pp);
 
+	/* only once for all ports*/
+	if (pm_flag == 0) {
+
+#ifdef CONFIG_MV_ETH_BM
+	{
+		struct bm_pool *ppool;
+		int pool;
+
+		mvBmControl(MV_START);
+
+		mvBmRegsInit();
+
+		for (pool = 0; pool < MV_ETH_BM_POOLS; pool++) {
+			ppool = &mv_eth_pool[pool];
+			if (mv_eth_bm_pool_restore(ppool)) {
+				printk(KERN_ERR "%s: port #%d pool #%d resrote failed.\n", __func__, port, pool);
+				return MV_ERROR;
+			}
+		}
+	}
+#endif /*CONFIG_MV_ETH_BM*/
+
 #ifdef CONFIG_MV_ETH_PNC
-	if (!pnc_resume_flag) {
-		if (tcam_hw_init())
-			printk(KERN_ERR "%s: Warning PNC tcam init failed\n", __func__);
-		if (pnc_default_init())
-			printk(KERN_ERR "%s: Warning PNC init failed\n", __func__);
-		pnc_resume_flag = 1;
+		mv_eth_pnc_resume();
+#endif /* CONFIG_MV_ETH_PNC */
+
+		pm_flag = 1;
 	}
-#endif /*CONFIG_MV_ETH_PNC*/
+
 	if (pp->flags & MV_ETH_F_STARTED_OLD)
 		(*pp->dev->netdev_ops->ndo_set_rx_mode)(pp->dev);
 
@@ -3131,7 +3354,9 @@ int mv_eth_port_resume(int port)
 
 	set_bit(MV_ETH_F_STARTED_BIT, &(pp->flags));
 
-	mv_eth_restore_registers(pp, pp->dev->mtu);
+	mv_eth_resume_port_pools(pp);
+
+	mv_eth_resume_rxq_txq(pp, pp->dev->mtu);
 
 	if (pp->flags & MV_ETH_F_STARTED_OLD) {
 		mv_eth_resume_internals(pp, pp->dev->mtu);
@@ -3145,11 +3370,14 @@ int mv_eth_port_resume(int port)
 
 
 	clear_bit(MV_ETH_F_SUSPEND_BIT, &(pp->flags));
-	printk(KERN_NOTICE "port %d resumed.\n", port);
 
-	return 0;
+	printk(KERN_NOTICE "Exit suspend mode on port #%d\n", port);
+
+	return MV_OK;
 }
 
+
+
 /***********************************************************
  * mv_eth_win_init --                                      *
  *   Win initilization                                     *
@@ -3190,15 +3418,14 @@ int mv_eth_port_suspend(int port)
 {
 	struct eth_port *pp;
 
-	/* NAPI DEBUG */
 
 	pp = mv_eth_port_by_id(port);
 	if (!pp)
-		return 0;
+		return MV_OK;
 
 	if (pp->flags & MV_ETH_F_SUSPEND) {
 		printk(KERN_ERR "%s: port %d is allready suspend.\n", __func__, port);
-		return -1;
+		return MV_ERROR;
 	}
 
 	if (mvBoardIsPortInSgmii(pp->port))
@@ -3211,19 +3438,34 @@ int mv_eth_port_suspend(int port)
 	} else
 		clear_bit(MV_ETH_F_STARTED_OLD_BIT, &(pp->flags));
 
+
+#ifdef CONFIG_MV_ETH_HWF
+	mvNetaHwfEnable(pp->port, 0);
+#else
+	{
+		int txp;
+		/* Reset TX port, transmit all pending packets */
+		for (txp = 0; txp < pp->txp_num; txp++)
+			mv_eth_txp_reset(pp->port, txp);
+	}
+#endif  /* !CONFIG_MV_ETH_HWF */
+
 	/* Reset RX port, free the empty buffers form queue */
-	mv_eth_rx_reset(port);
+	mv_eth_rx_reset(pp->port);
+
+	mv_eth_port_pools_free(port);
 
 	set_bit(MV_ETH_F_SUSPEND_BIT, &(pp->flags));
-	printk(KERN_NOTICE "port %d suspend.\n", port);
-	return 0;
+
+	printk(KERN_NOTICE "Enter suspend mode on port #%d\n", port);
+	return MV_OK;
 }
 
 /***********************************************************
- * mv_eth_pm_mode_set --                                   *
- *   set pm_mode. (power menegment mod)			   *
+ * mv_eth_wol_mode_set --                                   *
+ *   set wol_mode. (power menegment mod)		    *
  ***********************************************************/
-int	mv_eth_pm_mode_set(int port, int mode)
+int	mv_eth_wol_mode_set(int port, int mode)
 {
 	struct eth_port *pp = mv_eth_port_by_id(port);
 
@@ -3232,7 +3474,7 @@ int	mv_eth_pm_mode_set(int port, int mode)
 		return -EINVAL;
 	}
 
-	if ((mode < MV_ETH_PM_WOL) || (mode > MV_ETH_PM_LAST)) {
+	if ((mode < 0) || (mode > 1)) {
 		printk(KERN_ERR "%s: mode = %d, Invalid value.\n", __func__, mode);
 		return -EINVAL;
 	}
@@ -3241,9 +3483,14 @@ int	mv_eth_pm_mode_set(int port, int mode)
 		printk(KERN_ERR "Port %d must resumed before\n", port);
 		return -EINVAL;
 	}
-	pp->pm_mode = mode;
+	pp->wol_mode = mode;
+
+	if (mode)
+		wol_ports_bmp |= (1 << port);
+	else
+		wol_ports_bmp &= ~(1 << port);
 
-	return 0;
+	return MV_OK;
 }
 
 /***********************************************************
@@ -3355,7 +3602,7 @@ static int mv_eth_probe(struct platform_device *pdev)
 
 	mv_eth_initialized = 1;
 
-	return 0;
+	return MV_OK;
 oom:
 	if (mv_eth_ports)
 		mvOsFree(mv_eth_ports);
@@ -3438,7 +3685,7 @@ static int mv_eth_config_get(struct eth_port *pp, MV_U8 *mac_addr)
 
 	default:
 		printk(KERN_ERR "eth_get_config: Unexpected port number %d\n", pp->port);
-		return -1;
+		return MV_ERROR;
 	}
 	if ((mac_str != NULL) && (mac_addr != NULL))
 		mvMacStrToHex(mac_str, mac_addr);
@@ -3703,7 +3950,7 @@ int mv_eth_hal_init(struct eth_port *pp)
 	pp->advertise_cfg = 0x2f;
 #endif /* CONFIG_MV_ETH_TOOL */
 
-	return 0;
+	return MV_OK;
 oom:
 	printk(KERN_ERR "%s: port=%d: out of memory\n", __func__, pp->port);
 	return -ENODEV;
@@ -3862,19 +4109,19 @@ int mv_eth_napi_set_cpu_affinity(int port, int group, int affinity)
 	struct eth_port *pp = mv_eth_port_by_id(port);
 	if (pp == NULL) {
 		printk(KERN_ERR "%s: pp == NULL, port=%d\n", __func__, port);
-		return -1;
+		return MV_ERROR;
 	}
 
 	if (group >= CONFIG_MV_ETH_NAPI_GROUPS) {
 		printk(KERN_ERR "%s: group number is higher than %d\n", __func__, CONFIG_MV_ETH_NAPI_GROUPS-1);
-		return -1;
+		return MV_ERROR;
 		}
 	if (pp->flags & MV_ETH_F_STARTED) {
 		printk(KERN_ERR "Port %d must be stopped before\n", port);
 		return -EINVAL;
 	}
 	set_cpu_affinity(pp, affinity, group);
-	return 0;
+	return MV_OK;
 
 }
 void handle_group_affinity(int port)
@@ -3923,7 +4170,7 @@ int	mv_eth_napi_set_rxq_affinity(int port, int group, int rxqAffinity)
 	}
 	if (group >= CONFIG_MV_ETH_NAPI_GROUPS) {
 		printk(KERN_ERR "%s: group number is higher than %d\n", __func__, CONFIG_MV_ETH_NAPI_GROUPS-1);
-		return -1;
+		return MV_ERROR;
 		}
 	if (pp->flags & MV_ETH_F_STARTED) {
 		printk(KERN_ERR "Port %d must be stopped before\n", port);
@@ -4023,7 +4270,7 @@ static int mv_eth_rxq_fill(struct eth_port *pp, int rxq, int num)
 	rx_ctrl = pp->rxq_ctrl[rxq].q;
 	if (!rx_ctrl) {
 		printk(KERN_ERR "%s: rxq %d is not initialized\n", __func__, rxq);
-		return 0;
+		return MV_OK;
 	}
 
 	for (i = 0; i < num; i++) {
@@ -4069,7 +4316,7 @@ static int mv_eth_txq_create(struct eth_port *pp, struct tx_queue *txq_ctrl)
 	mvNetaHwfTxqInit(pp->port, txq_ctrl->txp, txq_ctrl->txq);
 #endif /* CONFIG_MV_ETH_HWF */
 
-	return 0;
+	return MV_OK;
 
 no_mem:
 	mv_eth_txq_delete(pp, txq_ctrl);
@@ -4106,7 +4353,7 @@ static int mv_force_port_link_speed_fc(int port, MV_ETH_PORT_SPEED port_speed, i
 			return -EIO;
 		}
 	}
-	return 0;
+	return MV_OK;
 }
 
 static void mv_eth_txq_delete(struct eth_port *pp, struct tx_queue *txq_ctrl)
@@ -4141,7 +4388,7 @@ int mv_eth_txp_reset(int port, int txp)
 			mv_eth_txq_done_force(pp, txq_ctrl);
 	}
 	mvNetaTxpReset(port, txp);
-	return 0;
+	return MV_OK;
 }
 
 /* Free received packets from all RXQs and reset RX of the port */
@@ -4187,7 +4434,7 @@ int mv_eth_rx_reset(int port)
 #endif /* CONFIG_MV_ETH_BM_CPU */
 
 	mvNetaRxReset(port);
-	return 0;
+	return MV_OK;
 }
 
 /***********************************************************
@@ -4476,111 +4723,26 @@ int mv_eth_resume_internals(struct eth_port *pp, int mtu)
 	}
 #endif /* CONFIG_MV_PON */
 
-	return 0;
-
-}
-
-
-int mv_eth_restore_registers(struct eth_port *pp, int mtu)
-{
-	int rxq, txp, txq = 0;
-
-
-	if (mvBoardIsPortInSgmii(pp->port))
-		MV_REG_WRITE(SGMII_SERDES_CFG_REG(pp->port), pp->sgmii_serdes);
-
-	for (txp = 0; txp < pp->txp_num; txp++) {
-		MV_REG_WRITE(NETA_PORT_TX_RESET_REG(pp->port, txp), NETA_PORT_TX_DMA_RESET_MASK);
-		MV_REG_WRITE(NETA_PORT_TX_RESET_REG(pp->port, txp), 0);
-	}
-
-	MV_REG_WRITE(NETA_PORT_RX_RESET_REG(pp->port), NETA_PORT_RX_DMA_RESET_MASK);
-	MV_REG_WRITE(NETA_PORT_RX_RESET_REG(pp->port), 0);
-
-#ifdef CONFIG_MV_ETH_BM_CPU
-	if (pp->pool_long != NULL) {
-		mvNetaBmPoolBufSizeSet(pp->port, pp->pool_long->pool, RX_BUF_SIZE(pp->pool_long->pkt_size));
-		if (pp->pool_short != NULL) {
-			if (pp->pool_short->pool != pp->pool_long->pool)
-				mvNetaBmPoolBufSizeSet(pp->port, pp->pool_short->pool, RX_BUF_SIZE(pp->pool_short->pkt_size));
-			else {
-				int dummy_short_pool = (pp->pool_short->pool + 1) % MV_BM_POOLS;
-
-				/* To disable short pool we choose unused pool and set pkt size to 0 (buffer size = pkt offset) */
-				mvNetaBmPoolBufSizeSet(pp->port, dummy_short_pool, NET_SKB_PAD);
-			}
-		}
-	}
-#endif /* CONFIG_MV_ETH_BM_CPU */
-
-	for (rxq = 0; rxq < CONFIG_MV_ETH_RXQ; rxq++) {
-		if (pp->rxq_ctrl[rxq].q) {
-			/* Set Rx descriptors queue starting address */
-			mvNetaRxqAddrSet(pp->port, rxq,  pp->rxq_ctrl[rxq].rxq_size);
-
-			/* Set Offset */
-			mvNetaRxqOffsetSet(pp->port, rxq, NET_SKB_PAD);
-
-			/* Set coalescing pkts and time */
-			mv_eth_rx_ptks_coal_set(pp->port, rxq, pp->rxq_ctrl[rxq].rxq_pkts_coal);
-			mv_eth_rx_time_coal_set(pp->port, rxq, pp->rxq_ctrl[rxq].rxq_time_coal);
-
-#if defined(CONFIG_MV_ETH_BM_CPU)
-			/* Enable / Disable - BM support */
-			if (pp->pool_long && pp->pool_short) {
-
-				if (pp->pool_short->pool == pp->pool_long->pool) {
-					int dummy_short_pool = (pp->pool_short->pool + 1) % MV_BM_POOLS;
-
-					/* To disable short pool we choose unused pool and set pkt size to 0 (buffer size = pkt offset) */
-					mvNetaRxqBmEnable(pp->port, rxq, dummy_short_pool, pp->pool_long->pool);
-				} else
-					mvNetaRxqBmEnable(pp->port, rxq, pp->pool_short->pool, pp->pool_long->pool);
-			}
-#else
-			/* Fill RXQ with buffers from RX pool */
-			mvNetaRxqBufSizeSet(pp->port, rxq, RX_BUF_SIZE(pp->pool_long->pkt_size));
-			mvNetaRxqBmDisable(pp->port, rxq);
-#endif /* CONFIG_MV_ETH_BM_CPU */
-			if (mvNetaRxqFreeDescNumGet(pp->port, rxq) == 0)
-				mv_eth_rxq_fill(pp, rxq, pp->rxq_ctrl[rxq].rxq_size);
-		}
-	}
-
-	for (txp = 0; txp < pp->txp_num; txp++) {
-		for (txq = 0; txq < CONFIG_MV_ETH_TXQ; txq++) {
-			struct tx_queue *txq_ctrl = &pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq];
-
-			if (txq_ctrl->q != NULL) {
-				mvNetaTxqAddrSet(pp->port, txq_ctrl->txp, txq_ctrl->txq, txq_ctrl->txq_size);
-				mv_eth_tx_done_ptks_coal_set(pp->port, txp, txq,
-							pp->txq_ctrl[txp * CONFIG_MV_ETH_TXQ + txq].txq_done_pkts_coal);
-			}
-			mvNetaTxqBandwidthSet(pp->port, txp, txq);
-
-		}
-		mvNetaTxpMaxTxSizeSet(pp->port, txp, RX_PKT_SIZE(mtu));
-	}
+	return MV_OK;
 
-	return 0;
 }
 
 
 /***********************************************************
- * mv_eth_suspend_internals --                                *
+ * mv_eth_suspend_internals --                             *
  *   stop port rx/tx activity. free skb's from rx/tx rings.*
  ***********************************************************/
 int mv_eth_suspend_internals(struct eth_port *pp)
 {
-	int queue;
-	int txp, cpu;
+	int cpu;
 
-	/* stop the port activity, mask all interrupts */
+	/* stop the port activity*/
 	if (mvNetaPortDisable(pp->port) != MV_OK) {
-		printk(KERN_ERR "GbE port %d: ethPortDisable failed\n", pp->port);
-		goto error;
+		printk(KERN_ERR "%s: GbE port %d: mvNetaPortDisable failed\n", __func__, pp->port);
+		return MV_ERROR;
 	}
 
+	/* mask all interrupts */
 	mv_eth_interrupts_mask(pp);
 	smp_call_function_many(cpu_online_mask, (smp_call_func_t)mv_eth_interrupts_mask, (void *)pp, 1);
 
@@ -4594,22 +4756,7 @@ int mv_eth_suspend_internals(struct eth_port *pp)
 
 	mdelay(10);
 
-#ifdef CONFIG_MV_ETH_HWF
-	mvNetaHwfEnable(pp->port, 0);
-#endif /* !CONFIG_MV_ETH_HWF */
-
-	/* Reset TX port here. If HWF is supported reset must be called externally */
-	for (txp = 0; txp < pp->txp_num; txp++)
-		mv_eth_txp_reset(pp->port, txp);
-
-	/* free the skb's in the hal rx ring */
-	for (queue = 0; queue < CONFIG_MV_ETH_RXQ; queue++)
-		mv_eth_rxq_drop_pkts(pp, queue);
-
-	return 0;
-error:
-	printk(KERN_ERR "GbE port %d: suspend internals failed\n", pp->port);
-	return -1;
+	return MV_OK;
 }
 
 
@@ -4664,11 +4811,11 @@ int mv_eth_stop_internals(struct eth_port *pp)
 	for (queue = 0; queue < CONFIG_MV_ETH_RXQ; queue++)
 		mv_eth_rxq_drop_pkts(pp, queue);
 
-	return 0;
+	return MV_OK;
 
 error:
 	printk(KERN_ERR "GbE port %d: stop internals failed\n", pp->port);
-	return -1;
+	return MV_ERROR;
 }
 
 /* return positive if MTU is valid */
@@ -4721,7 +4868,7 @@ int mv_eth_check_mtu_internals(struct net_device *dev, int mtu)
 		}
 	}
 #endif /* CONFIG_MV_ETH_BM_CPU */
-	return 0;
+	return MV_OK;
 }
 
 /***********************************************************
@@ -4740,7 +4887,7 @@ int mv_eth_change_mtu_internals(struct net_device *dev, int mtu)
 		STAT_ERR(pp->stats.state_err++);
 		if (pp->flags & MV_ETH_F_DBG_RX)
 			printk(KERN_ERR "%s: port %d, STARTED_BIT = 0, Invalid value.\n", __func__, pp->port);
-		return -1;
+		return MV_ERROR;
 	}
 
 	if ((mtu != dev->mtu) && (pp->pool_long)) {
@@ -4782,7 +4929,7 @@ int mv_eth_change_mtu_internals(struct net_device *dev, int mtu)
 
 		/* DIMA debug; Free all buffers from short pool */
 /*
-		if(pp->pool_short) {
+		if (pp->pool_short) {
 			mv_eth_pool_free(pp->pool_short->pool, pp->pool_short_num);
 			pp->pool_short = NULL;
 		}
@@ -4792,7 +4939,7 @@ int mv_eth_change_mtu_internals(struct net_device *dev, int mtu)
 
 	mv_eth_netdev_update_features(dev);
 
-	return 0;
+	return MV_OK;
 }
 
 /***********************************************************
@@ -5033,7 +5180,7 @@ int mv_eth_txq_tos_map_set(int port, int txq, int cpu, unsigned int tos)
 
 	/* The same txq - do nothing */
 	if (old_txq == (MV_U8) txq)
-		return 0;
+		return MV_OK;
 
 	if (txq == -1) {
 		/* delete tos to txq mapping - free TXQ */
@@ -5042,7 +5189,7 @@ int mv_eth_txq_tos_map_set(int port, int txq, int cpu, unsigned int tos)
 
 		cpuCtrl->txq_tos_map[tos] = MV_ETH_TXQ_INVALID;
 		printk(KERN_ERR "Successfully deleted\n");
-		return 0;
+		return MV_OK;
 	}
 
 	if (mvNetaMaxCheck(txq, CONFIG_MV_ETH_TXQ))
@@ -5059,7 +5206,7 @@ int mv_eth_txq_tos_map_set(int port, int txq, int cpu, unsigned int tos)
 
 	cpuCtrl->txq_tos_map[tos] = (MV_U8) txq;
 	printk(KERN_ERR "Successfully added\n");
-	return 0;
+	return MV_OK;
 }
 
 static int mv_eth_priv_init(struct eth_port *pp, int port)
@@ -5079,7 +5226,7 @@ static int mv_eth_priv_init(struct eth_port *pp, int port)
 	pp->port = port;
 	pp->txp_num = 1;
 	pp->txp = 0;
-	pp->pm_mode = MV_ETH_PM_DISABLE;
+	pp->wol_mode = 0;
 	for_each_possible_cpu(cpu) {
 		cpuCtrl = pp->cpu_config[cpu];
 		cpuCtrl->txq = CONFIG_MV_ETH_TXQ_DEF;
@@ -5184,7 +5331,7 @@ static int mv_eth_priv_init(struct eth_port *pp, int port)
 		       pp->port, sizeof(u32) * (pp->txp_num * CONFIG_MV_ETH_TXQ * CONFIG_MV_ETH_TXQ_DESC + 1));
 #endif /* CONFIG_MV_ETH_STAT_DIST */
 
-	return 0;
+	return MV_OK;
 }
 
 /***********************************************************************************
@@ -5313,12 +5460,10 @@ void mv_eth_port_status_print(unsigned int port)
 	else
 		printk(KERN_CONT "Disabled\n");
 #endif /* CONFIG_MV_ETH_NFP */
-	if (pp->pm_mode == MV_ETH_PM_WOL)
+	if (pp->wol_mode == 1)
 		printk(KERN_CONT "pm - wol\n");
-	else if (pp->pm_mode == MV_ETH_PM_CLOCK)
-		printk(KERN_CONT "pm - clock\n");
 	else
-		printk(KERN_CONT "pm - disabled\n");
+		printk(KERN_CONT "pm - suspend\n");
 
 	printk(KERN_ERR "rxq_coal(pkts)[ q]   = ");
 	for (q = 0; q < CONFIG_MV_ETH_RXQ; q++)
@@ -5389,10 +5534,9 @@ void mv_eth_port_status_print(unsigned int port)
 			cpuCtrl = pp->cpu_config[cpu];
 			if (MV_BIT_CHECK(pp->cpuMask, cpu))
 				printk(KERN_ERR "  %d:   %d   0x%08x   %d    0x%02x    0x%02x    0x%02x    %d\n",
-					cpu, cpuCtrl->txq, cpuCtrl->causeRxTx,
-					test_bit(NAPI_STATE_SCHED, &cpuCtrl->napi->state),
-					cpuCtrl->cpuTxqMask, cpuCtrl->cpuTxqOwner, (unsigned)cpuCtrl->flags,
-					timer_pending(&cpuCtrl->tx_done_timer));
+					cpu, cpuCtrl->txq, cpuCtrl->causeRxTx, test_bit(NAPI_STATE_SCHED, &cpuCtrl->napi->state),
+					cpuCtrl->cpuTxqMask, cpuCtrl->cpuTxqOwner,
+					(unsigned)cpuCtrl->flags, timer_pending(&cpuCtrl->tx_done_timer));
 		}
 	}
 
@@ -5629,11 +5773,11 @@ static int mv_eth_port_cleanup(int port)
 	pp = mv_eth_port_by_id(port);
 
 	if (pp == NULL)
-		return -1;
+		return MV_ERROR;
 
 	if (pp->flags & MV_ETH_F_STARTED) {
 		printk(KERN_ERR "%s: port %d is started, cannot cleanup\n", __func__, port);
-		return -1;
+		return MV_ERROR;
 	}
 
 	/* Reset Tx ports */
@@ -5703,7 +5847,7 @@ static int mv_eth_port_cleanup(int port)
 		for (i = 0; i < CONFIG_MV_ETH_NAPI_GROUPS; i++)
 			netif_napi_del(pp->napiGroup[i]);
 
-	return 0;
+	return MV_OK;
 }
 
 
@@ -5730,7 +5874,7 @@ int mv_eth_all_ports_cleanup(void)
 	memset(mv_eth_ports, 0, (mv_eth_ports_num * sizeof(struct eth_port *)));
 	/* Note: not freeing mv_eth_ports - we will reuse them */
 
-	return 0;
+	return MV_OK;
 }
 
 #ifdef CONFIG_MV_ETH_PNC_WOL
@@ -5801,13 +5945,14 @@ int mv_eth_wol_pkts_check(int port)
 			return 1;
 		}
 	}
-	return 0;
+	return MV_OK;
 }
 
 void mv_eth_wol_wakeup(int port)
 {
 	int rxq;
 
+
 	/* Restore RXQ coalescing */
 	for (rxq = 0; rxq < CONFIG_MV_ETH_RXQ; rxq++) {
 		mvNetaRxqPktsCoalSet(port, rxq, CONFIG_MV_ETH_RX_COAL_PKTS);
@@ -5860,7 +6005,7 @@ int mv_eth_wol_sleep(int port)
 
 	mv_eth_interrupts_unmask(pp);
 
-	return 0;
+	return MV_OK;
 }
 #endif /* CONFIG_MV_ETH_PNC_WOL */
 
@@ -5895,87 +6040,44 @@ MV_BOOL mv_pon_link_status(void)
 
 #ifdef CONFIG_CPU_IDLE
 
-
-int mv_eth_suspend_clock(int port)
-{
-	/* TODO remove define , add to reg h file */
-	#define PM_CLOCK_GATING_REG	0x18220
-	#define PM_CLOCK_GATING_MASK(port)  (1 << (4-(port)))
-
-	int regVal;
-
-	if (mv_eth_port_suspend(port)) {
-		printk(KERN_ERR "%s: Error, can not suspend port=%d \n", __func__, port);
-		return -1;
-	}
-
-	/* TODO - remove clock_gating reg write to pm.c */
-	regVal = MV_REG_READ(PM_CLOCK_GATING_REG);
-	regVal &= ~PM_CLOCK_GATING_MASK(port);
-	MV_REG_WRITE(PM_CLOCK_GATING_REG, regVal);
-
-
-	return 0;
-}
-
-
 int mv_eth_suspend(struct platform_device *pdev, pm_message_t state)
 {
-
 	struct eth_port *pp;
 	int port;
 
+	pm_flag = 0;
+
 	for (port = 0 ; port < CONFIG_MV_ETH_PORTS_NUM ; port++) {
 		pp = mv_eth_port_by_id(port);
 		if (!pp)
 			continue;
-
-		if (state.event & PM_EVENT_SUSPEND)
-			pp->pm_mode = MV_ETH_PM_CLOCK;
-		else
-			pp->pm_mode = MV_ETH_PM_WOL;
-
-		if (pp->pm_mode == MV_ETH_PM_CLOCK) {
-			if (mv_eth_suspend_clock(pp->port)) {
-				printk(KERN_ERR "%s: Error, port %d clock suspend failed.\n", __func__, port);
-				return -1;
+		if (pp->wol_mode == 0) {
+			if (mv_eth_port_suspend(port)) {
+				printk(KERN_ERR "%s: port #%d suspend failed.\n", __func__, port);
+				return MV_ERROR;
 			}
-		}
-#ifdef CONFIG_MV_ETH_PNC_WOL
-		else if (pp->pm_mode == MV_ETH_PM_WOL) {
 
-			/*Configure ETH port to be in WoL mode*/
-			if (mv_eth_wol_sleep(port)) {
-				printk(KERN_ERR "%s: Error, port %d wol suspend failed.\n", __func__, port);
-				return -1;
-			}
+			/* BUG WA - if port 0 clock is down, we cant interrupt by magic packet */
+			if ((port != 0) || (wol_ports_bmp == 0))
+				/* Set Port Power State to 0 */
+				mvCtrlPwrClckSet(ETH_GIG_UNIT_ID, port, 0);
 		}
-#endif	/*CONFIG_MV_ETH_PNC_WOL*/
-		else
-			printk(KERN_INFO "Port %d power manegment mode is disabled.\n", port);
 
-	}
-
-	return 0;
-}
-
-
-int mv_eth_resume_clock(int port)
-{
-	int regVal;
+		else {
 
-	/* TODO - remove clock_gating reg write to pm.c */
-	regVal = MV_REG_READ(PM_CLOCK_GATING_REG);
-	regVal |= PM_CLOCK_GATING_MASK(port);
-	MV_REG_WRITE(PM_CLOCK_GATING_REG, regVal);
-
-	mdelay(10);
+#ifdef CONFIG_MV_ETH_PNC_WOL
+			if (pp->flags & MV_ETH_F_STARTED)
+				if (mv_eth_wol_sleep(port)) {
+					printk(KERN_ERR "%s: port #%d  WOL failed.\n", __func__, port);
+					return MV_ERROR;
+				}
+#else
+			printk(KERN_INFO "%s:WARNING port #%d in WOL mode but PNC WOL is not defined.\n", __func__, port);
 
-	if (mv_eth_port_resume(port)) {
-		printk(KERN_ERR "%s: Error, port %d resume failed.\n", __func__, port);
-		return -1;
+#endif /*CONFIG_MV_ETH_PNC_WOL*/
+		}
 	}
-	return 0;
+	return MV_OK;
 }
 
 
@@ -5984,41 +6086,40 @@ int mv_eth_resume(struct platform_device *pdev)
 	struct eth_port *pp;
 	int port;
 
-#ifdef CONFIG_MV_ETH_PNC
-	pnc_resume_flag = 0;
-#endif
+	pm_flag = 0;
 
 	for (port = 0 ; port < CONFIG_MV_ETH_PORTS_NUM ; port++) {
 		pp = mv_eth_port_by_id(port);
 		if (!pp)
 			continue;
 
-		if (pp->pm_mode == MV_ETH_PM_CLOCK) {
-			if (mv_eth_resume_clock(pp->port)) {
-				printk(KERN_ERR "%s: Error, port %d clock resume failed.\n", __func__, port);
-				return -1;
+		if (pp->wol_mode == 0) {
+			/* Set Port Power State to 1 */
+			mvCtrlPwrClckSet(ETH_GIG_UNIT_ID, port, 1);
+			mdelay(10);
+			if (mv_eth_port_resume(port)) {
+				printk(KERN_ERR "%s: port #%d resume failed.\n", __func__, port);
+				return MV_ERROR;
 			}
-		}
-
+		} else
 #ifdef CONFIG_MV_ETH_PNC_WOL
-		else if (pp->pm_mode == MV_ETH_PM_WOL)
 			mv_eth_wol_wakeup(port);
+#else
+			printk(KERN_ERR "%s:WARNING port #%d in WOL mode but PNC WOL is not defined.\n", __func__, port);
+#endif /*CONFIG_MV_ETH_PNC_WOL*/
 
-#endif	/*CONFIG_MV_ETH_PNC_WOL*/
-
-		else
-			printk(KERN_INFO "Port %d power manegment mode is disabled.\n", port);
 	}
 
-	return 0;
+	return MV_OK;
 }
 
+
 #endif	/*CONFIG_CPU_IDLE*/
 
 static int mv_eth_remove(struct platform_device *pdev)
 {
     printk(KERN_INFO "Removing Marvell Ethernet Driver\n");
-    return 0;
+    return MV_OK;
 }
 
 static void mv_eth_shutdown(struct platform_device *pdev)
diff --git a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.h b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.h
index 25499be..36ae9e9 100755
--- a/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.h
+++ b/arch/arm/plat-armada/mv_drivers_lsp/mv_neta/net_dev/mv_netdev.h
@@ -140,17 +140,21 @@ int mv_eth_skb_recycle(struct sk_buff *skb);
 		local_irq_restore(flags);
 
 
-#define mv_eth_lock(txq_ctrl, flags)    		     \
+#define mv_eth_lock(txq_ctrl, flags)			     \
+{							     \
 	if (txq_ctrl->flags & MV_ETH_F_TX_SHARED)	     \
 		MV_ETH_LOCK(&txq_ctrl->queue_lock, flags)    \
 	else                                                 \
-		MV_ETH_LIGHT_LOCK(flags)
+		MV_ETH_LIGHT_LOCK(flags)		     \
+}
 
-#define mv_eth_unlock(txq_ctrl, flags)    		     \
-	if (txq_ctrl->flags & MV_ETH_F_TX_SHARED)	     \
-		MV_ETH_UNLOCK(&txq_ctrl->queue_lock, flags)  \
-	else                                                 \
-		MV_ETH_LIGHT_UNLOCK(flags)
+#define mv_eth_unlock(txq_ctrl, flags)    	              \
+{							      \
+	if (txq_ctrl->flags & MV_ETH_F_TX_SHARED)	      \
+		MV_ETH_UNLOCK(&txq_ctrl->queue_lock, flags)   \
+	else                                                  \
+		MV_ETH_LIGHT_UNLOCK(flags)		      \
+}
 
 
 /******************************************************
@@ -392,14 +396,7 @@ struct eth_port {
 	MV_U32 rx_indir_table[256];
 	struct cpu_ctrl	*cpu_config[CONFIG_NR_CPUS];
 	MV_U32  sgmii_serdes;
-	int	pm_mode;
-};
-
-enum eth_pm_mode {
-	MV_ETH_PM_WOL = 0,
-	MV_ETH_PM_CLOCK,
-	MV_ETH_PM_DISABLE,
-	MV_ETH_PM_LAST
+	int	wol_mode;
 };
 
 struct eth_netdev {
@@ -449,6 +446,7 @@ struct bm_pool {
 	int         capacity;
 	int         buf_num;
 	int         pkt_size;
+	MV_ULONG    physAddr;
 	u32         *bm_pool;
 	MV_STACK    *stack;
 	spinlock_t  lock;
@@ -733,7 +731,7 @@ int         mv_eth_restore_registers(struct eth_port *pp, int mtu);
 
 void        mv_eth_win_init(int port);
 int         mv_eth_resume_network_interfaces(struct eth_port *pp);
-int         mv_eth_pm_mode_set(int port, int mode);
+int         mv_eth_wol_mode_set(int port, int mode);
 
 int	    mv_eth_cpu_txq_mask_set(int port, int cpu, int txqMask);
 
diff --git a/arch/arm/plat-armada/mv_hal/neta/bm/mvBm.c b/arch/arm/plat-armada/mv_hal/neta/bm/mvBm.c
index d7168bf..07bf3c0 100755
--- a/arch/arm/plat-armada/mv_hal/neta/bm/mvBm.c
+++ b/arch/arm/plat-armada/mv_hal/neta/bm/mvBm.c
@@ -78,10 +78,20 @@ static MV_BM_POOL	mvBmPools[MV_BM_POOLS];
 /* Initialize Hardware Buffer management unit */
 MV_STATUS mvBmInit(MV_U8 *virtBase)
 {
-	MV_U32 regVal;
 
 	mvBmVirtBase = virtBase;
 
+	mvBmRegsInit();
+
+	memset(mvBmPools, 0, sizeof(mvBmPools));
+
+	return MV_OK;
+}
+
+void mvBmRegsInit(void)
+{
+	MV_U32 regVal;
+
 	/* Mask BM all interrupts */
 	MV_REG_WRITE(MV_BM_INTR_MASK_REG, 0);
 
@@ -96,9 +106,7 @@ MV_STATUS mvBmInit(MV_U8 *virtBase)
 	regVal |= MV_BM_MAX_IN_BURST_SIZE_16BP;
 	MV_REG_WRITE(MV_BM_CONFIG_REG, regVal);
 
-	memset(mvBmPools, 0, sizeof(mvBmPools));
-
-	return MV_OK;
+	return;
 }
 
 MV_STATUS mvBmControl(MV_COMMAND cmd)
@@ -260,7 +268,8 @@ MV_STATUS mvBmPoolInit(int pool, void *virtPoolBase, MV_ULONG physPoolBase, int
 	pBmPool = &mvBmPools[pool];
 	if (pBmPool->pVirt != NULL) {
 		mvOsPrintf("bmPool = %d is already busy\n", pool);
-		return MV_BUSY;
+		/* necessary for power managemaent resume process*/
+		/*return MV_BUSY;*/
 	}
 
 	pBmPool->pool = pool;
diff --git a/arch/arm/plat-armada/mv_hal/neta/bm/mvBm.h b/arch/arm/plat-armada/mv_hal/neta/bm/mvBm.h
index fddc413..caf48da 100755
--- a/arch/arm/plat-armada/mv_hal/neta/bm/mvBm.h
+++ b/arch/arm/plat-armada/mv_hal/neta/bm/mvBm.h
@@ -112,6 +112,7 @@ static INLINE MV_ULONG mvBmPoolGet(int poolId)
 
 /* prototypes */
 MV_STATUS mvBmInit(MV_U8 *virtBase);
+void      mvBmRegsInit(void);
 void      mvBmConfigSet(MV_U32 mask);
 void      mvBmConfigClear(MV_U32 mask);
 MV_STATUS mvBmControl(MV_COMMAND cmd);
-- 
1.7.9.5

